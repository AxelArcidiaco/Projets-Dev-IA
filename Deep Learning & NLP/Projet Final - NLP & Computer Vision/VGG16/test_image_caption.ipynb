{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.utils import load_img, img_to_array, to_categorical, plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import add\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from os import listdir\n",
    "from joblib import dump, load\n",
    "import string\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Téléchargement des données de NLTK if required\n",
    "nltk.download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparer les données photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des features des photos\n",
    "def extract_features(directory):\n",
    "\t# Chargement du modèle VGG (Visual Geometry Group) depuis Keras\n",
    "\tmodel = VGG16()\n",
    "\t# re-structure the model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\t# summarize\n",
    "\tprint(model.summary())\n",
    "\t# extract features from each photo\n",
    "\tfeatures = dict()\n",
    "\tfor name in listdir(directory):\n",
    "\t\t# load an image from file\n",
    "\t\tfilename = directory + '/' + name\n",
    "\t\timg = load_img(filename, target_size=(224, 224))\n",
    "\t\t# convert the image pixels to a numpy array\n",
    "\t\timg = img_to_array(img)\n",
    "\t\t# reshape data for the model\n",
    "\t\timg = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "\t\t# prepare the image for the VGG model\n",
    "\t\timg = preprocess_input(img)\n",
    "\t\t# get features\n",
    "\t\tfeature = model.predict(img, verbose=0)\n",
    "\t\t# get image id\n",
    "\t\timg_id = name.split('.')[0]\n",
    "\t\t# store feature\n",
    "\t\tfeatures[img_id] = feature\n",
    "\t\tprint('>%s' % name)\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">1000268201_693b08cb0e.jpg\n",
      ">1001773457_577c3a7d70.jpg\n",
      ">1002674143_1b742ab4b8.jpg\n",
      ">1003163366_44323f5815.jpg\n",
      ">1007129816_e794419615.jpg\n",
      ">1007320043_627395c3d8.jpg\n",
      ">1009434119_febe49276a.jpg\n",
      ">1012212859_01547e3f17.jpg\n",
      ">1015118661_980735411b.jpg\n",
      ">1015584366_dfcec3c85a.jpg\n",
      ">101654506_8eb26cfb60.jpg\n",
      ">101669240_b2d3e7f17b.jpg\n",
      ">1016887272_03199f49c4.jpg\n",
      ">1019077836_6fc9b15408.jpg\n",
      ">1019604187_d087bf9a5f.jpg\n",
      ">1020651753_06077ec457.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# extract features from all images\u001b[39;00m\n\u001b[0;32m      2\u001b[0m directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../Flicker8k_Dataset\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m features \u001b[39m=\u001b[39m extract_features(directory)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mExtracted Features: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m \u001b[39mlen\u001b[39m(features))\n\u001b[0;32m      5\u001b[0m \u001b[39m# save to file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     20\u001b[0m img \u001b[39m=\u001b[39m preprocess_input(img)\n\u001b[0;32m     21\u001b[0m \u001b[39m# get features\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m feature \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(img, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     23\u001b[0m \u001b[39m# get image id\u001b[39;00m\n\u001b[0;32m     24\u001b[0m img_id \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\keras\\engine\\training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   2252\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[0;32m   2254\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   2255\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# extract features from all images\n",
    "directory = '../Flicker8k_Dataset'\n",
    "features = extract_features(directory)\n",
    "print('Extracted Features: %d' % len(features))\n",
    "# save to file\n",
    "dump(features, 'features.joblib')\n",
    "\n",
    "# Last execution time: 93m 22.5s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparer les données texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "filename = '../Flickr8k_text/Flickr8k.token.txt'\n",
    "# load descriptions\n",
    "doc = load_doc(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 8092 \n"
     ]
    }
   ],
   "source": [
    "# extract descriptions for images\n",
    "def load_descriptions(doc):\n",
    "\tmapping = dict()\n",
    "\t# process lines\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# split line by white space\n",
    "\t\ttokens = line.split()\n",
    "\t\tif len(line) < 2:\n",
    "\t\t\tcontinue\n",
    "\t\t# take the first token as the image id, the rest as the description\n",
    "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
    "\t\t# remove filename from image id\n",
    "\t\timage_id = image_id.split('.')[0]\n",
    "\t\t# convert description tokens back to string\n",
    "\t\timage_desc = ' '.join(image_desc)\n",
    "\t\t# create the list if needed\n",
    "\t\tif image_id not in mapping:\n",
    "\t\t\tmapping[image_id] = list()\n",
    "\t\t# store description\n",
    "\t\tmapping[image_id].append(image_desc)\n",
    "\treturn mapping\n",
    "\n",
    "# parse descriptions\n",
    "descriptions = load_descriptions(doc)\n",
    "print('Loaded: %d ' % len(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_descriptions(descriptions):\n",
    "\t# prepare translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor key, desc_list in descriptions.items():\n",
    "\t\tfor i in range(len(desc_list)):\n",
    "\t\t\tdesc = desc_list[i]\n",
    "\t\t\t# tokenize\n",
    "\t\t\tdesc = desc.split()\n",
    "\t\t\t# convert to lower case\n",
    "\t\t\tdesc = [word.lower() for word in desc]\n",
    "\t\t\t# remove punctuation from each token\n",
    "\t\t\tdesc = [w.translate(table) for w in desc]\n",
    "\t\t\t# remove hanging 's' and 'a'\n",
    "\t\t\tdesc = [word for word in desc if len(word)>1]\n",
    "\t\t\t# remove tokens with numbers in them\n",
    "\t\t\tdesc = [word for word in desc if word.isalpha()]\n",
    "\t\t\t# store as string\n",
    "\t\t\tdesc_list[i] =  ' '.join(desc)\n",
    "\n",
    "# clean descriptions\n",
    "clean_descriptions(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 8763\n"
     ]
    }
   ],
   "source": [
    "# convert the loaded descriptions into a vocabulary of words\n",
    "def to_vocabulary(descriptions):\n",
    "    # build a list of all description strings\n",
    "    all_desc = set()\n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.update(d.split()) for d in descriptions[key]]\n",
    "    return all_desc\n",
    " \n",
    "# summarize vocabulary\n",
    "vocabulary = to_vocabulary(descriptions)\n",
    "print('Vocabulary Size: %d' % len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save descriptions to file, one per line\n",
    "def save_descriptions(descriptions, filename):\n",
    "\tlines = list()\n",
    "\tfor key, desc_list in descriptions.items():\n",
    "\t\tfor desc in desc_list:\n",
    "\t\t\tlines.append(key + ' ' + desc)\n",
    "\tdata = '\\n'.join(lines)\n",
    "\tfile = open(filename, 'w')\n",
    "\tfile.write(data)\n",
    "\tfile.close()\n",
    "\n",
    "# save descriptions\n",
    "save_descriptions(descriptions, 'descriptions.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Développer un modèle d'apprentissage en profondeur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pre-defined list of photo identifiers\n",
    "def load_set(filename):\n",
    "    doc = load_doc(filename)\n",
    "    dataset = list()\n",
    "    # process line by line\n",
    "    for line in doc.split('\\n'):\n",
    "        # skip empty lines\n",
    "        if len(line) < 1:\n",
    "            continue\n",
    "        # get the image identifier\n",
    "        identifier = line.split('.')[0]\n",
    "        dataset.append(identifier)\n",
    "    return set(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean descriptions into memory\n",
    "def load_clean_descriptions(filename, dataset):\n",
    "    # load document\n",
    "    doc = load_doc(filename)\n",
    "    descriptions = dict()\n",
    "    for line in doc.split('\\n'):\n",
    "        # split line by white space\n",
    "        tokens = line.split()\n",
    "        # split id from description\n",
    "        image_id, image_desc = tokens[0], tokens[1:]\n",
    "        # skip images not in the set\n",
    "        if image_id in dataset:\n",
    "            # create list\n",
    "            if image_id not in descriptions:\n",
    "                descriptions[image_id] = list()\n",
    "            # wrap description in tokens\n",
    "            desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
    "            # store\n",
    "            descriptions[image_id].append(desc)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load photo features\n",
    "def load_photo_features(filename, dataset):\n",
    "    # load all features\n",
    "    all_features = load(filename)\n",
    "    # filter features\n",
    "    features = {k: all_features[k] for k in dataset}\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 6000\n",
      "Descriptions: train=6000\n",
      "Photos: train=6000\n"
     ]
    }
   ],
   "source": [
    "# load training dataset (6K)\n",
    "filename = '../Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "train = load_set(filename)\n",
    "print('Dataset: %d' % len(train))\n",
    "\n",
    "# descriptions\n",
    "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
    "print('Descriptions: train=%d' % len(train_descriptions))\n",
    "\n",
    "# photo features\n",
    "train_features = load_photo_features('features.joblib', train)\n",
    "print('Photos: train=%d' % len(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a dictionary of clean descriptions to a list of descriptions\n",
    "def to_lines(descriptions):\n",
    "    all_desc = list()\n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.append(d) for d in descriptions[key]]\n",
    "    return all_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a tokenizer given caption descriptions\n",
    "def create_tokenizer(descriptions):\n",
    "    lines = to_lines(descriptions)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 7579\n"
     ]
    }
   ],
   "source": [
    "# prepare tokenizer\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sequences of images, input sequences and output words for an image\n",
    "def create_sequences(tokenizer, max_length, descriptions, photos, vocab_size):\n",
    "\tX1, X2, y = list(), list(), list()\n",
    "\t# walk through each image identifier\n",
    "\tfor key, desc_list in descriptions.items():\n",
    "\t\t# walk through each description for the image\n",
    "\t\tfor desc in desc_list:\n",
    "\t\t\t# encode the sequence\n",
    "\t\t\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
    "\t\t\t# split one sequence into multiple X,y pairs\n",
    "\t\t\tfor i in range(1, len(seq)):\n",
    "\t\t\t\t# split into input and output pair\n",
    "\t\t\t\tin_seq, out_seq = seq[:i], seq[i]\n",
    "\t\t\t\t# pad input sequence\n",
    "\t\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "\t\t\t\t# encode output sequence\n",
    "\t\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\t\t\t\t# store\n",
    "\t\t\t\tX1.append(photos[key][0])\n",
    "\t\t\t\tX2.append(in_seq)\n",
    "\t\t\t\ty.append(out_seq)\n",
    "\treturn array(X1), array(X2), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the length of the description with the most words\n",
    "def max_length(descriptions):\n",
    "\tlines = to_lines(descriptions)\n",
    "\treturn max(len(d.split()) for d in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 6000\n",
      "Descriptions: train=6000\n",
      "Photos: train=6000\n",
      "Vocabulary Size: 7579\n",
      "Description Length: 34\n"
     ]
    }
   ],
   "source": [
    "# train dataset\n",
    "\n",
    "# load training dataset (6K)\n",
    "filename = '../Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "train = load_set(filename)\n",
    "print('Dataset: %d' % len(train))\n",
    "\n",
    "# descriptions\n",
    "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
    "print('Descriptions: train=%d' % len(train_descriptions))\n",
    "\n",
    "# photo features\n",
    "train_features = load_photo_features('features.joblib', train)\n",
    "print('Photos: train=%d' % len(train_features))\n",
    "\n",
    "# prepare tokenizer\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "\n",
    "# determine the maximum sequence length\n",
    "max_length = max_length(train_descriptions)\n",
    "print('Description Length: %d' % max_length)\n",
    "\n",
    "# prepare sequences\n",
    "X1train, X2train, ytrain = create_sequences(tokenizer, max_length, train_descriptions, train_features, vocab_size)\n",
    "\n",
    "# Execution time = 6m 11.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1000\n",
      "Descriptions: test=1000\n",
      "Photos: test=1000\n"
     ]
    }
   ],
   "source": [
    "# load test set\n",
    "filename = '../Flickr8k_text/Flickr_8k.devImages.txt'\n",
    "test = load_set(filename)\n",
    "print('Dataset: %d' % len(test))\n",
    "\n",
    "# descriptions\n",
    "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
    "print('Descriptions: test=%d' % len(test_descriptions))\n",
    "\n",
    "# photo features\n",
    "test_features = load_photo_features('features.joblib', test)\n",
    "print('Photos: test=%d' % len(test_features))\n",
    "\n",
    "# prepare sequences\n",
    "X1test, X2test, ytest = create_sequences(tokenizer, max_length, test_descriptions, test_features, vocab_size)\n",
    "\n",
    "# Execution time = 17.6s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the captioning model\n",
    "def define_model(vocab_size, max_length):\n",
    "\t# feature extractor model\n",
    "\tinputs1 = Input(shape=(4096,))\n",
    "\tfe1 = Dropout(0.5)(inputs1)\n",
    "\tfe2 = Dense(256, activation='relu')(fe1)\n",
    "\t# sequence model\n",
    "\tinputs2 = Input(shape=(max_length,))\n",
    "\tse1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "\tse2 = Dropout(0.5)(se1)\n",
    "\tse3 = LSTM(256)(se2)\n",
    "\t# decoder model\n",
    "\tdecoder1 = add([fe2, se3])\n",
    "\tdecoder2 = Dense(256, activation='relu')(decoder1)\n",
    "\toutputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\t# tie it together [image, seq] [word]\n",
    "\tmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\t# summarize model\n",
    "\tprint(model.summary())\n",
    "\tplot_model(model, to_file='model.png', show_shapes=True)\n",
    "\treturn model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 34)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 34, 256)      1940224     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4096)         0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 34, 256)      0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          1048832     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 256)          525312      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 256)          0           ['dense[0][0]',                  \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          65792       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 7579)         1947803     ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,527,963\n",
      "Trainable params: 5,527,963\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = define_model(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define checkpoint callback\n",
    "filepath = './models/model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# initial fit model\n",
    "model.fit([X1train, X2train], ytrain, epochs=20, verbose=2, callbacks=[checkpoint, early_stopping], validation_data=([X1test, X2test], ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 3.93679, saving model to model-ep001-loss3.703-val_loss3.937.h5\n",
      "9576/9576 - 1634s - loss: 3.7029 - val_loss: 3.9368 - 1634s/epoch - 171ms/step\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 2: val_loss improved from 3.93679 to 3.93383, saving model to model-ep002-loss3.610-val_loss3.934.h5\n",
      "9576/9576 - 1400s - loss: 3.6096 - val_loss: 3.9338 - 1400s/epoch - 146ms/step\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 3: val_loss improved from 3.93383 to 3.93289, saving model to model-ep003-loss3.546-val_loss3.933.h5\n",
      "9576/9576 - 2145s - loss: 3.5457 - val_loss: 3.9329 - 2145s/epoch - 224ms/step\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 4: val_loss did not improve from 3.93289\n",
      "9576/9576 - 1625s - loss: 3.4956 - val_loss: 3.9394 - 1625s/epoch - 170ms/step\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 5: val_loss did not improve from 3.93289\n",
      "9576/9576 - 2148s - loss: 3.4559 - val_loss: 3.9350 - 2148s/epoch - 224ms/step\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 6: val_loss did not improve from 3.93289\n",
      "9576/9576 - 1496s - loss: 3.4240 - val_loss: 3.9764 - 1496s/epoch - 156ms/step\n",
      "Epoch 7/16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[39m.\u001b[39mload_weights(\u001b[39m'\u001b[39m\u001b[39m./model-ep004-loss3.690-val_loss3.911.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Restart fit model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m model\u001b[39m.\u001b[39;49mfit([X1train, X2train], ytrain, epochs\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[checkpoint], validation_data\u001b[39m=\u001b[39;49m([X1test, X2test], ytest))\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit model from checkpoint file\n",
    "from keras.models import load_model\n",
    "\n",
    "# Loading last saved checkpoint file (.h5 files)\n",
    "model = load_model('./model-ep004-loss3.690-val_loss3.911.h5')\n",
    "\n",
    "# Compiling model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Loading weights\n",
    "model.load_weights('./model-ep004-loss3.690-val_loss3.911.h5')\n",
    "\n",
    "# Restart fit model\n",
    "model.fit([X1train, X2train], ytrain, epochs=16, verbose=2, callbacks=[checkpoint, early_stopping], validation_data=([X1test, X2test], ytest))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop fitting/training model process at epoch 10 due to time requirement (~30 mins per epoch) and the fact that the model didn't improve."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "from joblib import load\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    " \n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# load a pre-defined list of photo identifiers\n",
    "def load_set(filename):\n",
    "\tdoc = load_doc(filename)\n",
    "\tdataset = list()\n",
    "\t# process line by line\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# skip empty lines\n",
    "\t\tif len(line) < 1:\n",
    "\t\t\tcontinue\n",
    "\t\t# get the image identifier\n",
    "\t\tidentifier = line.split('.')[0]\n",
    "\t\tdataset.append(identifier)\n",
    "\treturn set(dataset)\n",
    "\n",
    "# load clean descriptions into memory\n",
    "def load_clean_descriptions(filename, dataset):\n",
    "\t# load document\n",
    "\tdoc = load_doc(filename)\n",
    "\tdescriptions = dict()\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# split line by white space\n",
    "\t\ttokens = line.split()\n",
    "\t\t# split id from description\n",
    "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
    "\t\t# skip images not in the set\n",
    "\t\tif image_id in dataset:\n",
    "\t\t\t# create list\n",
    "\t\t\tif image_id not in descriptions:\n",
    "\t\t\t\tdescriptions[image_id] = list()\n",
    "\t\t\t# wrap description in tokens\n",
    "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
    "\t\t\t# store\n",
    "\t\t\tdescriptions[image_id].append(desc)\n",
    "\treturn descriptions\n",
    "\n",
    "# load photo features\n",
    "def load_photo_features(filename, dataset):\n",
    "\t# load all features\n",
    "\tall_features = load(open(filename, 'rb'))\n",
    "\t# filter features\n",
    "\tfeatures = {k: all_features[k] for k in dataset}\n",
    "\treturn features\n",
    "\n",
    "# covert a dictionary of clean descriptions to a list of descriptions\n",
    "def to_lines(descriptions):\n",
    "\tall_desc = list()\n",
    "\tfor key in descriptions.keys():\n",
    "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
    "\treturn all_desc\n",
    "\n",
    "# fit a tokenizer given caption descriptions\n",
    "def create_tokenizer(descriptions):\n",
    "\tlines = to_lines(descriptions)\n",
    "\ttokenizer = Tokenizer()\n",
    "\ttokenizer.fit_on_texts(lines)\n",
    "\treturn tokenizer\n",
    "\n",
    "# calculate the length of the description with the most words\n",
    "def max_length(descriptions):\n",
    "\tlines = to_lines(descriptions)\n",
    "\treturn max(len(d.split()) for d in lines)\n",
    "\n",
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == integer:\n",
    "\t\t\treturn word\n",
    "\treturn None\n",
    " \n",
    "# generate a description for an image\n",
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "\t# seed the generation process\n",
    "\tin_text = 'startseq'\n",
    "\t# iterate over the whole length of the sequence\n",
    "\tfor i in range(max_length):\n",
    "\t\t# integer encode input sequence\n",
    "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# pad input\n",
    "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
    "\t\t# predict next word\n",
    "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
    "\t\t# convert probability to integer\n",
    "\t\tyhat = argmax(yhat)\n",
    "\t\t# map integer to word\n",
    "\t\tword = word_for_id(yhat, tokenizer)\n",
    "\t\t# stop if we cannot map the word\n",
    "\t\tif word is None:\n",
    "\t\t\tbreak\n",
    "\t\t# append as input for generating the next word\n",
    "\t\tin_text += ' ' + word\n",
    "\t\t# stop if we predict the end of the sequence\n",
    "\t\tif word == 'endseq':\n",
    "\t\t\tbreak\n",
    "\treturn in_text\n",
    " \n",
    "# evaluate the skill of the model\n",
    "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
    "    actual, predicted = list(), list()\n",
    "    # step over the whole set\n",
    "    for key, desc_list in descriptions.items():\n",
    "        # generate description\n",
    "        yhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
    "        # store actual and predicted\n",
    "        references = [d.split() for d in desc_list]\n",
    "        actual.append(references)\n",
    "        predicted.append(yhat.split())\n",
    "        # calculate BLEU score\n",
    "        print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "        print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "        print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "        print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 6000\n",
      "Descriptions: train=6000\n"
     ]
    }
   ],
   "source": [
    "# prepare tokenizer on train set\n",
    " \n",
    "# load training dataset (6K)\n",
    "filename = '../Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "train = load_set(filename)\n",
    "print('Dataset: %d' % len(train))\n",
    "# descriptions\n",
    "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
    "print('Descriptions: train=%d' % len(train_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 7579\n"
     ]
    }
   ],
   "source": [
    "# prepare tokenizer\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description Length: 34\n"
     ]
    }
   ],
   "source": [
    "# determine the maximum sequence length\n",
    "max_length = max_length(train_descriptions)\n",
    "print('Description Length: %d' % max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1000\n"
     ]
    }
   ],
   "source": [
    "# prepare test set\n",
    " \n",
    "# load test set\n",
    "filename = '../Flickr8k_text/Flickr_8k.testImages.txt'\n",
    "test = load_set(filename)\n",
    "print('Dataset: %d' % len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions: test=1000\n"
     ]
    }
   ],
   "source": [
    "# descriptions\n",
    "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
    "print('Descriptions: test=%d' % len(test_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photos: test=1000\n"
     ]
    }
   ],
   "source": [
    "# photo features\n",
    "test_features = load_photo_features('features.joblib', test)\n",
    "print('Photos: test=%d' % len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at ./model-ep007-loss3.546-val_loss3.933.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# load the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./model-ep007-loss3.546-val_loss3.933.h5\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m load_model(filename)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\keras\\saving\\save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    231\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[0;32m    232\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[0;32m    233\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at ./model-ep007-loss3.546-val_loss3.933.h5"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "filename = './model-ep007-loss3.546-val_loss3.933.h5'\n",
    "model = load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\AxelArcidiaco\\anaconda3\\envs\\ProjetFinalNLP\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.538462\n",
      "BLEU-2: 0.211830\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.538462\n",
      "BLEU-2: 0.211830\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.461538\n",
      "BLEU-2: 0.196116\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.489362\n",
      "BLEU-2: 0.213359\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.483333\n",
      "BLEU-2: 0.229624\n",
      "BLEU-3: 0.127914\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.500000\n",
      "BLEU-2: 0.237595\n",
      "BLEU-3: 0.126196\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.539474\n",
      "BLEU-2: 0.293263\n",
      "BLEU-3: 0.210501\n",
      "BLEU-4: 0.119182\n",
      "BLEU-1: 0.505618\n",
      "BLEU-2: 0.262038\n",
      "BLEU-3: 0.187344\n",
      "BLEU-4: 0.103728\n",
      "BLEU-1: 0.515464\n",
      "BLEU-2: 0.275949\n",
      "BLEU-3: 0.201790\n",
      "BLEU-4: 0.108326\n",
      "BLEU-1: 0.500000\n",
      "BLEU-2: 0.254951\n",
      "BLEU-3: 0.185051\n",
      "BLEU-4: 0.097475\n",
      "BLEU-1: 0.487805\n",
      "BLEU-2: 0.237950\n",
      "BLEU-3: 0.171509\n",
      "BLEU-4: 0.088839\n",
      "BLEU-1: 0.507353\n",
      "BLEU-2: 0.255861\n",
      "BLEU-3: 0.173671\n",
      "BLEU-4: 0.087437\n",
      "BLEU-1: 0.503356\n",
      "BLEU-2: 0.250838\n",
      "BLEU-3: 0.166861\n",
      "BLEU-4: 0.082579\n",
      "BLEU-1: 0.506173\n",
      "BLEU-2: 0.254915\n",
      "BLEU-3: 0.173441\n",
      "BLEU-4: 0.083449\n",
      "BLEU-1: 0.508571\n",
      "BLEU-2: 0.258360\n",
      "BLEU-3: 0.178836\n",
      "BLEU-4: 0.083911\n",
      "BLEU-1: 0.505319\n",
      "BLEU-2: 0.248387\n",
      "BLEU-3: 0.170871\n",
      "BLEU-4: 0.079302\n",
      "BLEU-1: 0.497512\n",
      "BLEU-2: 0.238288\n",
      "BLEU-3: 0.163296\n",
      "BLEU-4: 0.075055\n",
      "BLEU-1: 0.490654\n",
      "BLEU-2: 0.229282\n",
      "BLEU-3: 0.156540\n",
      "BLEU-4: 0.071299\n",
      "BLEU-1: 0.493392\n",
      "BLEU-2: 0.223190\n",
      "BLEU-3: 0.151285\n",
      "BLEU-4: 0.068256\n",
      "BLEU-1: 0.487500\n",
      "BLEU-2: 0.215718\n",
      "BLEU-3: 0.145731\n",
      "BLEU-4: 0.065223\n",
      "BLEU-1: 0.486166\n",
      "BLEU-2: 0.219539\n",
      "BLEU-3: 0.150851\n",
      "BLEU-4: 0.066226\n",
      "BLEU-1: 0.492481\n",
      "BLEU-2: 0.224631\n",
      "BLEU-3: 0.156045\n",
      "BLEU-4: 0.067252\n",
      "BLEU-1: 0.500000\n",
      "BLEU-2: 0.236171\n",
      "BLEU-3: 0.159525\n",
      "BLEU-4: 0.068078\n",
      "BLEU-1: 0.508711\n",
      "BLEU-2: 0.244872\n",
      "BLEU-3: 0.170711\n",
      "BLEU-4: 0.078775\n",
      "BLEU-1: 0.506667\n",
      "BLEU-2: 0.238988\n",
      "BLEU-3: 0.165982\n",
      "BLEU-4: 0.076083\n",
      "BLEU-1: 0.501597\n",
      "BLEU-2: 0.240156\n",
      "BLEU-3: 0.168678\n",
      "BLEU-4: 0.076277\n",
      "BLEU-1: 0.503067\n",
      "BLEU-2: 0.235632\n",
      "BLEU-3: 0.164712\n",
      "BLEU-4: 0.074005\n",
      "BLEU-1: 0.505988\n",
      "BLEU-2: 0.237109\n",
      "BLEU-3: 0.164252\n",
      "BLEU-4: 0.073460\n",
      "BLEU-1: 0.507246\n",
      "BLEU-2: 0.240390\n",
      "BLEU-3: 0.168023\n",
      "BLEU-4: 0.074276\n",
      "BLEU-1: 0.502793\n",
      "BLEU-2: 0.234914\n",
      "BLEU-3: 0.163856\n",
      "BLEU-4: 0.072050\n",
      "BLEU-1: 0.498652\n",
      "BLEU-2: 0.236076\n",
      "BLEU-3: 0.166219\n",
      "BLEU-4: 0.072250\n",
      "BLEU-1: 0.500000\n",
      "BLEU-2: 0.232330\n",
      "BLEU-3: 0.162913\n",
      "BLEU-4: 0.070425\n",
      "BLEU-1: 0.496222\n",
      "BLEU-2: 0.233516\n",
      "BLEU-3: 0.161763\n",
      "BLEU-4: 0.069416\n",
      "BLEU-1: 0.497561\n",
      "BLEU-2: 0.238541\n",
      "BLEU-3: 0.165637\n",
      "BLEU-4: 0.070217\n",
      "BLEU-1: 0.494090\n",
      "BLEU-2: 0.234003\n",
      "BLEU-3: 0.162191\n",
      "BLEU-4: 0.068448\n",
      "BLEU-1: 0.488532\n",
      "BLEU-2: 0.229166\n",
      "BLEU-3: 0.158704\n",
      "BLEU-4: 0.066701\n",
      "BLEU-1: 0.489978\n",
      "BLEU-2: 0.226138\n",
      "BLEU-3: 0.156042\n",
      "BLEU-4: 0.065276\n",
      "BLEU-1: 0.484848\n",
      "BLEU-2: 0.221745\n",
      "BLEU-3: 0.152885\n",
      "BLEU-4: 0.063707\n",
      "BLEU-1: 0.486316\n",
      "BLEU-2: 0.224038\n",
      "BLEU-3: 0.155522\n",
      "BLEU-4: 0.064166\n",
      "BLEU-1: 0.481557\n",
      "BLEU-2: 0.219933\n",
      "BLEU-3: 0.152550\n",
      "BLEU-4: 0.062709\n",
      "BLEU-1: 0.479042\n",
      "BLEU-2: 0.218870\n",
      "BLEU-3: 0.150898\n",
      "BLEU-4: 0.061727\n",
      "BLEU-1: 0.474708\n",
      "BLEU-2: 0.215091\n",
      "BLEU-3: 0.148173\n",
      "BLEU-4: 0.060401\n",
      "BLEU-1: 0.475096\n",
      "BLEU-2: 0.215910\n",
      "BLEU-3: 0.147895\n",
      "BLEU-4: 0.060114\n",
      "BLEU-1: 0.478505\n",
      "BLEU-2: 0.216283\n",
      "BLEU-3: 0.146946\n",
      "BLEU-4: 0.059418\n",
      "BLEU-1: 0.478102\n",
      "BLEU-2: 0.213598\n",
      "BLEU-3: 0.144789\n",
      "BLEU-4: 0.058332\n",
      "BLEU-1: 0.477718\n",
      "BLEU-2: 0.211010\n",
      "BLEU-3: 0.142714\n",
      "BLEU-4: 0.057291\n",
      "BLEU-1: 0.477352\n",
      "BLEU-2: 0.208514\n",
      "BLEU-3: 0.140716\n",
      "BLEU-4: 0.056292\n",
      "BLEU-1: 0.482818\n",
      "BLEU-2: 0.216832\n",
      "BLEU-3: 0.148684\n",
      "BLEU-4: 0.063149\n",
      "BLEU-1: 0.484034\n",
      "BLEU-2: 0.216760\n",
      "BLEU-3: 0.147660\n",
      "BLEU-4: 0.062433\n",
      "BLEU-1: 0.485197\n",
      "BLEU-2: 0.216690\n",
      "BLEU-3: 0.146665\n",
      "BLEU-4: 0.061741\n",
      "BLEU-1: 0.486312\n",
      "BLEU-2: 0.218582\n",
      "BLEU-3: 0.148883\n",
      "BLEU-4: 0.062181\n",
      "BLEU-1: 0.485804\n",
      "BLEU-2: 0.216204\n",
      "BLEU-3: 0.146981\n",
      "BLEU-4: 0.061194\n",
      "BLEU-1: 0.488408\n",
      "BLEU-2: 0.220254\n",
      "BLEU-3: 0.152216\n",
      "BLEU-4: 0.066276\n",
      "BLEU-1: 0.486364\n",
      "BLEU-2: 0.217606\n",
      "BLEU-3: 0.150206\n",
      "BLEU-4: 0.065214\n",
      "BLEU-1: 0.485884\n",
      "BLEU-2: 0.215376\n",
      "BLEU-3: 0.148399\n",
      "BLEU-4: 0.064240\n",
      "BLEU-1: 0.489796\n",
      "BLEU-2: 0.214172\n",
      "BLEU-3: 0.147045\n",
      "BLEU-4: 0.063441\n",
      "BLEU-1: 0.489270\n",
      "BLEU-2: 0.215611\n",
      "BLEU-3: 0.148862\n",
      "BLEU-4: 0.063788\n",
      "BLEU-1: 0.487360\n",
      "BLEU-2: 0.214947\n",
      "BLEU-3: 0.147758\n",
      "BLEU-4: 0.063097\n",
      "BLEU-1: 0.488276\n",
      "BLEU-2: 0.216613\n",
      "BLEU-3: 0.149614\n",
      "BLEU-4: 0.063464\n",
      "BLEU-1: 0.492517\n",
      "BLEU-2: 0.219448\n",
      "BLEU-3: 0.150195\n",
      "BLEU-4: 0.063467\n",
      "BLEU-1: 0.487968\n",
      "BLEU-2: 0.216516\n",
      "BLEU-3: 0.148197\n",
      "BLEU-4: 0.062483\n",
      "BLEU-1: 0.486202\n",
      "BLEU-2: 0.217483\n",
      "BLEU-3: 0.149719\n",
      "BLEU-4: 0.062742\n",
      "BLEU-1: 0.485788\n",
      "BLEU-2: 0.215548\n",
      "BLEU-3: 0.148155\n",
      "BLEU-4: 0.061928\n",
      "BLEU-1: 0.485934\n",
      "BLEU-2: 0.216098\n",
      "BLEU-3: 0.147972\n",
      "BLEU-4: 0.061732\n",
      "BLEU-1: 0.484277\n",
      "BLEU-2: 0.213949\n",
      "BLEU-3: 0.146353\n",
      "BLEU-4: 0.060913\n",
      "BLEU-1: 0.486318\n",
      "BLEU-2: 0.214774\n",
      "BLEU-3: 0.146232\n",
      "BLEU-4: 0.060719\n",
      "BLEU-1: 0.483476\n",
      "BLEU-2: 0.212425\n",
      "BLEU-3: 0.144564\n",
      "BLEU-4: 0.059896\n",
      "BLEU-1: 0.483133\n",
      "BLEU-2: 0.212170\n",
      "BLEU-3: 0.143769\n",
      "BLEU-4: 0.059382\n",
      "BLEU-1: 0.483986\n",
      "BLEU-2: 0.212184\n",
      "BLEU-3: 0.143098\n",
      "BLEU-4: 0.058917\n",
      "BLEU-1: 0.487150\n",
      "BLEU-2: 0.215601\n",
      "BLEU-3: 0.143807\n",
      "BLEU-4: 0.058930\n",
      "BLEU-1: 0.489583\n",
      "BLEU-2: 0.219444\n",
      "BLEU-3: 0.146763\n",
      "BLEU-4: 0.059822\n",
      "BLEU-1: 0.493119\n",
      "BLEU-2: 0.226188\n",
      "BLEU-3: 0.154238\n",
      "BLEU-4: 0.065133\n",
      "BLEU-1: 0.491525\n",
      "BLEU-2: 0.224148\n",
      "BLEU-3: 0.152712\n",
      "BLEU-4: 0.064352\n",
      "BLEU-1: 0.488864\n",
      "BLEU-2: 0.221906\n",
      "BLEU-3: 0.151123\n",
      "BLEU-4: 0.063557\n",
      "BLEU-1: 0.487377\n",
      "BLEU-2: 0.219972\n",
      "BLEU-3: 0.149676\n",
      "BLEU-4: 0.062818\n",
      "BLEU-1: 0.485870\n",
      "BLEU-2: 0.218589\n",
      "BLEU-3: 0.148702\n",
      "BLEU-4: 0.062341\n",
      "BLEU-1: 0.483387\n",
      "BLEU-2: 0.216496\n",
      "BLEU-3: 0.147216\n",
      "BLEU-4: 0.061600\n",
      "BLEU-1: 0.483528\n",
      "BLEU-2: 0.215648\n",
      "BLEU-3: 0.146532\n",
      "BLEU-4: 0.061253\n",
      "BLEU-1: 0.483229\n",
      "BLEU-2: 0.215383\n",
      "BLEU-3: 0.145814\n",
      "BLEU-4: 0.060789\n",
      "BLEU-1: 0.485005\n",
      "BLEU-2: 0.220600\n",
      "BLEU-3: 0.151883\n",
      "BLEU-4: 0.065135\n",
      "BLEU-1: 0.485128\n",
      "BLEU-2: 0.222218\n",
      "BLEU-3: 0.152212\n",
      "BLEU-4: 0.065141\n",
      "BLEU-1: 0.485772\n",
      "BLEU-2: 0.222591\n",
      "BLEU-3: 0.151974\n",
      "BLEU-4: 0.064923\n",
      "BLEU-1: 0.484453\n",
      "BLEU-2: 0.220824\n",
      "BLEU-3: 0.150646\n",
      "BLEU-4: 0.064234\n",
      "BLEU-1: 0.484095\n",
      "BLEU-2: 0.222159\n",
      "BLEU-3: 0.152255\n",
      "BLEU-4: 0.064676\n",
      "BLEU-1: 0.482826\n",
      "BLEU-2: 0.220438\n",
      "BLEU-3: 0.150954\n",
      "BLEU-4: 0.064004\n",
      "BLEU-1: 0.483527\n",
      "BLEU-2: 0.219194\n",
      "BLEU-3: 0.149862\n",
      "BLEU-4: 0.063411\n",
      "BLEU-1: 0.481340\n",
      "BLEU-2: 0.217324\n",
      "BLEU-3: 0.148526\n",
      "BLEU-4: 0.062738\n",
      "BLEU-1: 0.482042\n",
      "BLEU-2: 0.218420\n",
      "BLEU-3: 0.148416\n",
      "BLEU-4: 0.062501\n",
      "BLEU-1: 0.482176\n",
      "BLEU-2: 0.217666\n",
      "BLEU-3: 0.147807\n",
      "BLEU-4: 0.062190\n",
      "BLEU-1: 0.484171\n",
      "BLEU-2: 0.219591\n",
      "BLEU-3: 0.148290\n",
      "BLEU-4: 0.062262\n",
      "BLEU-1: 0.485741\n",
      "BLEU-2: 0.219730\n",
      "BLEU-3: 0.147803\n",
      "BLEU-4: 0.061900\n",
      "BLEU-1: 0.487671\n",
      "BLEU-2: 0.223785\n",
      "BLEU-3: 0.151875\n",
      "BLEU-4: 0.065367\n",
      "BLEU-1: 0.487365\n",
      "BLEU-2: 0.224537\n",
      "BLEU-3: 0.152959\n",
      "BLEU-4: 0.065556\n",
      "BLEU-1: 0.486124\n",
      "BLEU-2: 0.223373\n",
      "BLEU-3: 0.152137\n",
      "BLEU-4: 0.065145\n",
      "BLEU-1: 0.484956\n",
      "BLEU-2: 0.223910\n",
      "BLEU-3: 0.153107\n",
      "BLEU-4: 0.065296\n",
      "BLEU-1: 0.482940\n",
      "BLEU-2: 0.222160\n",
      "BLEU-3: 0.151857\n",
      "BLEU-4: 0.064661\n",
      "BLEU-1: 0.483927\n",
      "BLEU-2: 0.223709\n",
      "BLEU-3: 0.152204\n",
      "BLEU-4: 0.064690\n",
      "BLEU-1: 0.483677\n",
      "BLEU-2: 0.223406\n",
      "BLEU-3: 0.151560\n",
      "BLEU-4: 0.064276\n",
      "BLEU-1: 0.483788\n",
      "BLEU-2: 0.222702\n",
      "BLEU-3: 0.150993\n",
      "BLEU-4: 0.063984\n",
      "BLEU-1: 0.485232\n",
      "BLEU-2: 0.225794\n",
      "BLEU-3: 0.152988\n",
      "BLEU-4: 0.064504\n",
      "BLEU-1: 0.484140\n",
      "BLEU-2: 0.225284\n",
      "BLEU-3: 0.152272\n",
      "BLEU-4: 0.064072\n",
      "BLEU-1: 0.482246\n",
      "BLEU-2: 0.223624\n",
      "BLEU-3: 0.151099\n",
      "BLEU-4: 0.063484\n",
      "BLEU-1: 0.483660\n",
      "BLEU-2: 0.225636\n",
      "BLEU-3: 0.153830\n",
      "BLEU-4: 0.066182\n",
      "BLEU-1: 0.482619\n",
      "BLEU-2: 0.224196\n",
      "BLEU-3: 0.152747\n",
      "BLEU-4: 0.065615\n",
      "BLEU-1: 0.480800\n",
      "BLEU-2: 0.222598\n",
      "BLEU-3: 0.151608\n",
      "BLEU-4: 0.065032\n",
      "BLEU-1: 0.481394\n",
      "BLEU-2: 0.223447\n",
      "BLEU-3: 0.152631\n",
      "BLEU-4: 0.065223\n",
      "BLEU-1: 0.483871\n",
      "BLEU-2: 0.226121\n",
      "BLEU-3: 0.155724\n",
      "BLEU-4: 0.068004\n",
      "BLEU-1: 0.482866\n",
      "BLEU-2: 0.225642\n",
      "BLEU-3: 0.155044\n",
      "BLEU-4: 0.067579\n",
      "BLEU-1: 0.482652\n",
      "BLEU-2: 0.224450\n",
      "BLEU-3: 0.154078\n",
      "BLEU-4: 0.067054\n",
      "BLEU-1: 0.482443\n",
      "BLEU-2: 0.224175\n",
      "BLEU-3: 0.153497\n",
      "BLEU-4: 0.066672\n",
      "BLEU-1: 0.482237\n",
      "BLEU-2: 0.223015\n",
      "BLEU-3: 0.152559\n",
      "BLEU-4: 0.066164\n",
      "BLEU-1: 0.481231\n",
      "BLEU-2: 0.222051\n",
      "BLEU-3: 0.151874\n",
      "BLEU-4: 0.065817\n",
      "BLEU-1: 0.481784\n",
      "BLEU-2: 0.223731\n",
      "BLEU-3: 0.153189\n",
      "BLEU-4: 0.066126\n",
      "BLEU-1: 0.480118\n",
      "BLEU-2: 0.223130\n",
      "BLEU-3: 0.152494\n",
      "BLEU-4: 0.065713\n",
      "BLEU-1: 0.480671\n",
      "BLEU-2: 0.223049\n",
      "BLEU-3: 0.152018\n",
      "BLEU-4: 0.065382\n",
      "BLEU-1: 0.481214\n",
      "BLEU-2: 0.223819\n",
      "BLEU-3: 0.152946\n",
      "BLEU-4: 0.065555\n",
      "BLEU-1: 0.480315\n",
      "BLEU-2: 0.222559\n",
      "BLEU-3: 0.151995\n",
      "BLEU-4: 0.065059\n",
      "BLEU-1: 0.480142\n",
      "BLEU-2: 0.223155\n",
      "BLEU-3: 0.152836\n",
      "BLEU-4: 0.065204\n",
      "BLEU-1: 0.481377\n",
      "BLEU-2: 0.225706\n",
      "BLEU-3: 0.154468\n",
      "BLEU-4: 0.065628\n",
      "BLEU-1: 0.479805\n",
      "BLEU-2: 0.224308\n",
      "BLEU-3: 0.153467\n",
      "BLEU-4: 0.065122\n",
      "BLEU-1: 0.478951\n",
      "BLEU-2: 0.223093\n",
      "BLEU-3: 0.152548\n",
      "BLEU-4: 0.064647\n",
      "BLEU-1: 0.477428\n",
      "BLEU-2: 0.221739\n",
      "BLEU-3: 0.151579\n",
      "BLEU-4: 0.064157\n",
      "BLEU-1: 0.477966\n",
      "BLEU-2: 0.220877\n",
      "BLEU-3: 0.150817\n",
      "BLEU-4: 0.063744\n",
      "BLEU-1: 0.476478\n",
      "BLEU-2: 0.219560\n",
      "BLEU-3: 0.149876\n",
      "BLEU-4: 0.063270\n",
      "BLEU-1: 0.477015\n",
      "BLEU-2: 0.220303\n",
      "BLEU-3: 0.149783\n",
      "BLEU-4: 0.063096\n",
      "BLEU-1: 0.476222\n",
      "BLEU-2: 0.220726\n",
      "BLEU-3: 0.150530\n",
      "BLEU-4: 0.063218\n",
      "BLEU-1: 0.477347\n",
      "BLEU-2: 0.221899\n",
      "BLEU-3: 0.150759\n",
      "BLEU-4: 0.063215\n",
      "BLEU-1: 0.477865\n",
      "BLEU-2: 0.221838\n",
      "BLEU-3: 0.150344\n",
      "BLEU-4: 0.062933\n",
      "BLEU-1: 0.480259\n",
      "BLEU-2: 0.223288\n",
      "BLEU-3: 0.150687\n",
      "BLEU-4: 0.062970\n",
      "BLEU-1: 0.479461\n",
      "BLEU-2: 0.222163\n",
      "BLEU-3: 0.149848\n",
      "BLEU-4: 0.062543\n",
      "BLEU-1: 0.479313\n",
      "BLEU-2: 0.221952\n",
      "BLEU-3: 0.149384\n",
      "BLEU-4: 0.062249\n",
      "BLEU-1: 0.480429\n",
      "BLEU-2: 0.222780\n",
      "BLEU-3: 0.150289\n",
      "BLEU-4: 0.062431\n",
      "BLEU-1: 0.480902\n",
      "BLEU-2: 0.221975\n",
      "BLEU-3: 0.149589\n",
      "BLEU-4: 0.062059\n",
      "BLEU-1: 0.481943\n",
      "BLEU-2: 0.223815\n",
      "BLEU-3: 0.151946\n",
      "BLEU-4: 0.064308\n",
      "BLEU-1: 0.482397\n",
      "BLEU-2: 0.223741\n",
      "BLEU-3: 0.151543\n",
      "BLEU-4: 0.064033\n",
      "BLEU-1: 0.481005\n",
      "BLEU-2: 0.222520\n",
      "BLEU-3: 0.150678\n",
      "BLEU-4: 0.063598\n",
      "BLEU-1: 0.480851\n",
      "BLEU-2: 0.221598\n",
      "BLEU-3: 0.149940\n",
      "BLEU-4: 0.063210\n",
      "BLEU-1: 0.483071\n",
      "BLEU-2: 0.225089\n",
      "BLEU-3: 0.153787\n",
      "BLEU-4: 0.065898\n",
      "BLEU-1: 0.483153\n",
      "BLEU-2: 0.225295\n",
      "BLEU-3: 0.153671\n",
      "BLEU-4: 0.065791\n",
      "BLEU-1: 0.482985\n",
      "BLEU-2: 0.224374\n",
      "BLEU-3: 0.152930\n",
      "BLEU-4: 0.065395\n",
      "BLEU-1: 0.485172\n",
      "BLEU-2: 0.228317\n",
      "BLEU-3: 0.155963\n",
      "BLEU-4: 0.067710\n",
      "BLEU-1: 0.486757\n",
      "BLEU-2: 0.230535\n",
      "BLEU-3: 0.158189\n",
      "BLEU-4: 0.068380\n",
      "BLEU-1: 0.486534\n",
      "BLEU-2: 0.231240\n",
      "BLEU-3: 0.159073\n",
      "BLEU-4: 0.068617\n",
      "BLEU-1: 0.486345\n",
      "BLEU-2: 0.230314\n",
      "BLEU-3: 0.158324\n",
      "BLEU-4: 0.068215\n",
      "BLEU-1: 0.486159\n",
      "BLEU-2: 0.229399\n",
      "BLEU-3: 0.157584\n",
      "BLEU-4: 0.067818\n",
      "BLEU-1: 0.485387\n",
      "BLEU-2: 0.229162\n",
      "BLEU-3: 0.157193\n",
      "BLEU-4: 0.067574\n",
      "BLEU-1: 0.485454\n",
      "BLEU-2: 0.229338\n",
      "BLEU-3: 0.157071\n",
      "BLEU-4: 0.067466\n",
      "BLEU-1: 0.485844\n",
      "BLEU-2: 0.230540\n",
      "BLEU-3: 0.158817\n",
      "BLEU-4: 0.069232\n",
      "BLEU-1: 0.484542\n",
      "BLEU-2: 0.229382\n",
      "BLEU-3: 0.157984\n",
      "BLEU-4: 0.068799\n",
      "BLEU-1: 0.485730\n",
      "BLEU-2: 0.229818\n",
      "BLEU-3: 0.157973\n",
      "BLEU-4: 0.068731\n",
      "BLEU-1: 0.484444\n",
      "BLEU-2: 0.228677\n",
      "BLEU-3: 0.157154\n",
      "BLEU-4: 0.068306\n",
      "BLEU-1: 0.485619\n",
      "BLEU-2: 0.228469\n",
      "BLEU-3: 0.156880\n",
      "BLEU-4: 0.068144\n",
      "BLEU-1: 0.487095\n",
      "BLEU-2: 0.231172\n",
      "BLEU-3: 0.158429\n",
      "BLEU-4: 0.068578\n",
      "BLEU-1: 0.486914\n",
      "BLEU-2: 0.230930\n",
      "BLEU-3: 0.157987\n",
      "BLEU-4: 0.068293\n",
      "BLEU-1: 0.488599\n",
      "BLEU-2: 0.233345\n",
      "BLEU-3: 0.159565\n",
      "BLEU-4: 0.068799\n",
      "BLEU-1: 0.488410\n",
      "BLEU-2: 0.232474\n",
      "BLEU-3: 0.158867\n",
      "BLEU-4: 0.068424\n",
      "BLEU-1: 0.487687\n",
      "BLEU-2: 0.231486\n",
      "BLEU-3: 0.158124\n",
      "BLEU-4: 0.068035\n",
      "BLEU-1: 0.488806\n",
      "BLEU-2: 0.231893\n",
      "BLEU-3: 0.158108\n",
      "BLEU-4: 0.067968\n",
      "BLEU-1: 0.489148\n",
      "BLEU-2: 0.231779\n",
      "BLEU-3: 0.157728\n",
      "BLEU-4: 0.067712\n",
      "BLEU-1: 0.487907\n",
      "BLEU-2: 0.230686\n",
      "BLEU-3: 0.156953\n",
      "BLEU-4: 0.067315\n",
      "BLEU-1: 0.486684\n",
      "BLEU-2: 0.229607\n",
      "BLEU-3: 0.156187\n",
      "BLEU-4: 0.066924\n",
      "BLEU-1: 0.487033\n",
      "BLEU-2: 0.229509\n",
      "BLEU-3: 0.155825\n",
      "BLEU-4: 0.066679\n",
      "BLEU-1: 0.487868\n",
      "BLEU-2: 0.230980\n",
      "BLEU-3: 0.156971\n",
      "BLEU-4: 0.067018\n",
      "BLEU-1: 0.488205\n",
      "BLEU-2: 0.231467\n",
      "BLEU-3: 0.156848\n",
      "BLEU-4: 0.066859\n",
      "BLEU-1: 0.489047\n",
      "BLEU-2: 0.232652\n",
      "BLEU-3: 0.157755\n",
      "BLEU-4: 0.067066\n",
      "BLEU-1: 0.489879\n",
      "BLEU-2: 0.233819\n",
      "BLEU-3: 0.158647\n",
      "BLEU-4: 0.067268\n",
      "BLEU-1: 0.489191\n",
      "BLEU-2: 0.232884\n",
      "BLEU-3: 0.157950\n",
      "BLEU-4: 0.066908\n",
      "BLEU-1: 0.487512\n",
      "BLEU-2: 0.231723\n",
      "BLEU-3: 0.157164\n",
      "BLEU-4: 0.066519\n",
      "BLEU-1: 0.487345\n",
      "BLEU-2: 0.231500\n",
      "BLEU-3: 0.156763\n",
      "BLEU-4: 0.066268\n",
      "BLEU-1: 0.487889\n",
      "BLEU-2: 0.231191\n",
      "BLEU-3: 0.156470\n",
      "BLEU-4: 0.066110\n",
      "BLEU-1: 0.487721\n",
      "BLEU-2: 0.230406\n",
      "BLEU-3: 0.155846\n",
      "BLEU-4: 0.065782\n",
      "BLEU-1: 0.488509\n",
      "BLEU-2: 0.231230\n",
      "BLEU-3: 0.156703\n",
      "BLEU-4: 0.066018\n",
      "BLEU-1: 0.489796\n",
      "BLEU-2: 0.233594\n",
      "BLEU-3: 0.160160\n",
      "BLEU-4: 0.070458\n",
      "BLEU-1: 0.490319\n",
      "BLEU-2: 0.234394\n",
      "BLEU-3: 0.160321\n",
      "BLEU-4: 0.070460\n",
      "BLEU-1: 0.491101\n",
      "BLEU-2: 0.234941\n",
      "BLEU-3: 0.160238\n",
      "BLEU-4: 0.070316\n",
      "BLEU-1: 0.490665\n",
      "BLEU-2: 0.234284\n",
      "BLEU-3: 0.159748\n",
      "BLEU-4: 0.070058\n",
      "BLEU-1: 0.491429\n",
      "BLEU-2: 0.236031\n",
      "BLEU-3: 0.161573\n",
      "BLEU-4: 0.070634\n",
      "BLEU-1: 0.490771\n",
      "BLEU-2: 0.235679\n",
      "BLEU-3: 0.161124\n",
      "BLEU-4: 0.070359\n",
      "BLEU-1: 0.490584\n",
      "BLEU-2: 0.236098\n",
      "BLEU-3: 0.161717\n",
      "BLEU-4: 0.070485\n",
      "BLEU-1: 0.490628\n",
      "BLEU-2: 0.236097\n",
      "BLEU-3: 0.161497\n",
      "BLEU-4: 0.070328\n",
      "BLEU-1: 0.490918\n",
      "BLEU-2: 0.236503\n",
      "BLEU-3: 0.162024\n",
      "BLEU-4: 0.070409\n",
      "BLEU-1: 0.491651\n",
      "BLEU-2: 0.237252\n",
      "BLEU-3: 0.162796\n",
      "BLEU-4: 0.070622\n",
      "BLEU-1: 0.491455\n",
      "BLEU-2: 0.236725\n",
      "BLEU-3: 0.162389\n",
      "BLEU-4: 0.070410\n",
      "BLEU-1: 0.491276\n",
      "BLEU-2: 0.236490\n",
      "BLEU-3: 0.161995\n",
      "BLEU-4: 0.070159\n",
      "BLEU-1: 0.489731\n",
      "BLEU-2: 0.235411\n",
      "BLEU-3: 0.161258\n",
      "BLEU-4: 0.069786\n",
      "BLEU-1: 0.489564\n",
      "BLEU-2: 0.235186\n",
      "BLEU-3: 0.160875\n",
      "BLEU-4: 0.069542\n",
      "BLEU-1: 0.490054\n",
      "BLEU-2: 0.235411\n",
      "BLEU-3: 0.160809\n",
      "BLEU-4: 0.069465\n",
      "BLEU-1: 0.489888\n",
      "BLEU-2: 0.235700\n",
      "BLEU-3: 0.161279\n",
      "BLEU-4: 0.069529\n",
      "BLEU-1: 0.490170\n",
      "BLEU-2: 0.236091\n",
      "BLEU-3: 0.161153\n",
      "BLEU-4: 0.069380\n",
      "BLEU-1: 0.489987\n",
      "BLEU-2: 0.236597\n",
      "BLEU-3: 0.161811\n",
      "BLEU-4: 0.069554\n",
      "BLEU-1: 0.489597\n",
      "BLEU-2: 0.235873\n",
      "BLEU-3: 0.161256\n",
      "BLEU-4: 0.069262\n",
      "BLEU-1: 0.489418\n",
      "BLEU-2: 0.235375\n",
      "BLEU-3: 0.160871\n",
      "BLEU-4: 0.069063\n",
      "BLEU-1: 0.489698\n",
      "BLEU-2: 0.235264\n",
      "BLEU-3: 0.160545\n",
      "BLEU-4: 0.068845\n",
      "BLEU-1: 0.489974\n",
      "BLEU-2: 0.235649\n",
      "BLEU-3: 0.161046\n",
      "BLEU-4: 0.068923\n",
      "BLEU-1: 0.490664\n",
      "BLEU-2: 0.235861\n",
      "BLEU-3: 0.160956\n",
      "BLEU-4: 0.068830\n",
      "BLEU-1: 0.489637\n",
      "BLEU-2: 0.234946\n",
      "BLEU-3: 0.160305\n",
      "BLEU-4: 0.068499\n",
      "BLEU-1: 0.492057\n",
      "BLEU-2: 0.237306\n",
      "BLEU-3: 0.162827\n",
      "BLEU-4: 0.071249\n",
      "BLEU-1: 0.491887\n",
      "BLEU-2: 0.237085\n",
      "BLEU-3: 0.162459\n",
      "BLEU-4: 0.071013\n",
      "BLEU-1: 0.490870\n",
      "BLEU-2: 0.236179\n",
      "BLEU-3: 0.161813\n",
      "BLEU-4: 0.070677\n",
      "BLEU-1: 0.491554\n",
      "BLEU-2: 0.237127\n",
      "BLEU-3: 0.163119\n",
      "BLEU-4: 0.071968\n",
      "BLEU-1: 0.491803\n",
      "BLEU-2: 0.238069\n",
      "BLEU-3: 0.164455\n",
      "BLEU-4: 0.073265\n",
      "BLEU-1: 0.492475\n",
      "BLEU-2: 0.238523\n",
      "BLEU-3: 0.164369\n",
      "BLEU-4: 0.073131\n",
      "BLEU-1: 0.492295\n",
      "BLEU-2: 0.238045\n",
      "BLEU-3: 0.163998\n",
      "BLEU-4: 0.072932\n",
      "BLEU-1: 0.491715\n",
      "BLEU-2: 0.238194\n",
      "BLEU-3: 0.163789\n",
      "BLEU-4: 0.072753\n",
      "BLEU-1: 0.492155\n",
      "BLEU-2: 0.238855\n",
      "BLEU-3: 0.163915\n",
      "BLEU-4: 0.072750\n",
      "BLEU-1: 0.493224\n",
      "BLEU-2: 0.239396\n",
      "BLEU-3: 0.164445\n",
      "BLEU-4: 0.072845\n",
      "BLEU-1: 0.493464\n",
      "BLEU-2: 0.239733\n",
      "BLEU-3: 0.164887\n",
      "BLEU-4: 0.072908\n",
      "BLEU-1: 0.493295\n",
      "BLEU-2: 0.239052\n",
      "BLEU-3: 0.164340\n",
      "BLEU-4: 0.072607\n",
      "BLEU-1: 0.492724\n",
      "BLEU-2: 0.238280\n",
      "BLEU-3: 0.163758\n",
      "BLEU-4: 0.072295\n",
      "BLEU-1: 0.492159\n",
      "BLEU-2: 0.237515\n",
      "BLEU-3: 0.163181\n",
      "BLEU-4: 0.071985\n",
      "BLEU-1: 0.491987\n",
      "BLEU-2: 0.237964\n",
      "BLEU-3: 0.163761\n",
      "BLEU-4: 0.072140\n",
      "BLEU-1: 0.492817\n",
      "BLEU-2: 0.239049\n",
      "BLEU-3: 0.164575\n",
      "BLEU-4: 0.072371\n",
      "BLEU-1: 0.491465\n",
      "BLEU-2: 0.238099\n",
      "BLEU-3: 0.163923\n",
      "BLEU-4: 0.072036\n",
      "BLEU-1: 0.491888\n",
      "BLEU-2: 0.238733\n",
      "BLEU-3: 0.164595\n",
      "BLEU-4: 0.072234\n",
      "BLEU-1: 0.491732\n",
      "BLEU-2: 0.238079\n",
      "BLEU-3: 0.164067\n",
      "BLEU-4: 0.071945\n",
      "BLEU-1: 0.491970\n",
      "BLEU-2: 0.238409\n",
      "BLEU-3: 0.164491\n",
      "BLEU-4: 0.072006\n",
      "BLEU-1: 0.492595\n",
      "BLEU-2: 0.239268\n",
      "BLEU-3: 0.164591\n",
      "BLEU-4: 0.071948\n",
      "BLEU-1: 0.492433\n",
      "BLEU-2: 0.239594\n",
      "BLEU-3: 0.164518\n",
      "BLEU-4: 0.071846\n",
      "BLEU-1: 0.491892\n",
      "BLEU-2: 0.238856\n",
      "BLEU-3: 0.163961\n",
      "BLEU-4: 0.071551\n",
      "BLEU-1: 0.492503\n",
      "BLEU-2: 0.239799\n",
      "BLEU-3: 0.164683\n",
      "BLEU-4: 0.071739\n",
      "BLEU-1: 0.493497\n",
      "BLEU-2: 0.241582\n",
      "BLEU-3: 0.166762\n",
      "BLEU-4: 0.072400\n",
      "BLEU-1: 0.494472\n",
      "BLEU-2: 0.242693\n",
      "BLEU-3: 0.167586\n",
      "BLEU-4: 0.072642\n",
      "BLEU-1: 0.494310\n",
      "BLEU-2: 0.242472\n",
      "BLEU-3: 0.167242\n",
      "BLEU-4: 0.072425\n",
      "BLEU-1: 0.493953\n",
      "BLEU-2: 0.241934\n",
      "BLEU-3: 0.166837\n",
      "BLEU-4: 0.072215\n",
      "BLEU-1: 0.494352\n",
      "BLEU-2: 0.242843\n",
      "BLEU-3: 0.167550\n",
      "BLEU-4: 0.072408\n",
      "BLEU-1: 0.494374\n",
      "BLEU-2: 0.242399\n",
      "BLEU-3: 0.167185\n",
      "BLEU-4: 0.072213\n",
      "BLEU-1: 0.495142\n",
      "BLEU-2: 0.243391\n",
      "BLEU-3: 0.167930\n",
      "BLEU-4: 0.072417\n",
      "BLEU-1: 0.495723\n",
      "BLEU-2: 0.244180\n",
      "BLEU-3: 0.168519\n",
      "BLEU-4: 0.072538\n",
      "BLEU-1: 0.496299\n",
      "BLEU-2: 0.244550\n",
      "BLEU-3: 0.168424\n",
      "BLEU-4: 0.072414\n",
      "BLEU-1: 0.496679\n",
      "BLEU-2: 0.244708\n",
      "BLEU-3: 0.168354\n",
      "BLEU-4: 0.072344\n",
      "BLEU-1: 0.497980\n",
      "BLEU-2: 0.246067\n",
      "BLEU-3: 0.169683\n",
      "BLEU-4: 0.072730\n",
      "BLEU-1: 0.498352\n",
      "BLEU-2: 0.245814\n",
      "BLEU-3: 0.169443\n",
      "BLEU-4: 0.072600\n",
      "BLEU-1: 0.497813\n",
      "BLEU-2: 0.245093\n",
      "BLEU-3: 0.168900\n",
      "BLEU-4: 0.072317\n",
      "BLEU-1: 0.498005\n",
      "BLEU-2: 0.244960\n",
      "BLEU-3: 0.168601\n",
      "BLEU-4: 0.072122\n",
      "BLEU-1: 0.497834\n",
      "BLEU-2: 0.244337\n",
      "BLEU-3: 0.168102\n",
      "BLEU-4: 0.071857\n",
      "BLEU-1: 0.498024\n",
      "BLEU-2: 0.243808\n",
      "BLEU-3: 0.167643\n",
      "BLEU-4: 0.071607\n",
      "BLEU-1: 0.498212\n",
      "BLEU-2: 0.243281\n",
      "BLEU-3: 0.167187\n",
      "BLEU-4: 0.071359\n",
      "BLEU-1: 0.498398\n",
      "BLEU-2: 0.242758\n",
      "BLEU-3: 0.166735\n",
      "BLEU-4: 0.071113\n",
      "BLEU-1: 0.498228\n",
      "BLEU-2: 0.242152\n",
      "BLEU-3: 0.166250\n",
      "BLEU-4: 0.070856\n",
      "BLEU-1: 0.497880\n",
      "BLEU-2: 0.241740\n",
      "BLEU-3: 0.165953\n",
      "BLEU-4: 0.070709\n",
      "BLEU-1: 0.499472\n",
      "BLEU-2: 0.242361\n",
      "BLEU-3: 0.166467\n",
      "BLEU-4: 0.070807\n",
      "BLEU-1: 0.499825\n",
      "BLEU-2: 0.243305\n",
      "BLEU-3: 0.167218\n",
      "BLEU-4: 0.071031\n",
      "BLEU-1: 0.500349\n",
      "BLEU-2: 0.243659\n",
      "BLEU-3: 0.167616\n",
      "BLEU-4: 0.071089\n",
      "BLEU-1: 0.500870\n",
      "BLEU-2: 0.244586\n",
      "BLEU-3: 0.168812\n",
      "BLEU-4: 0.072297\n",
      "BLEU-1: 0.499653\n",
      "BLEU-2: 0.243733\n",
      "BLEU-3: 0.168227\n",
      "BLEU-4: 0.072004\n",
      "BLEU-1: 0.499483\n",
      "BLEU-2: 0.243527\n",
      "BLEU-3: 0.167910\n",
      "BLEU-4: 0.071808\n",
      "BLEU-1: 0.500344\n",
      "BLEU-2: 0.244818\n",
      "BLEU-3: 0.169202\n",
      "BLEU-4: 0.073008\n",
      "BLEU-1: 0.500171\n",
      "BLEU-2: 0.244792\n",
      "BLEU-3: 0.169044\n",
      "BLEU-4: 0.072901\n",
      "BLEU-1: 0.500000\n",
      "BLEU-2: 0.244202\n",
      "BLEU-3: 0.168570\n",
      "BLEU-4: 0.072647\n",
      "BLEU-1: 0.499151\n",
      "BLEU-2: 0.243451\n",
      "BLEU-3: 0.168031\n",
      "BLEU-4: 0.072371\n",
      "BLEU-1: 0.499324\n",
      "BLEU-2: 0.242953\n",
      "BLEU-3: 0.167599\n",
      "BLEU-4: 0.072134\n",
      "BLEU-1: 0.498822\n",
      "BLEU-2: 0.242673\n",
      "BLEU-3: 0.167259\n",
      "BLEU-4: 0.071930\n",
      "BLEU-1: 0.499329\n",
      "BLEU-2: 0.243856\n",
      "BLEU-3: 0.168028\n",
      "BLEU-4: 0.072141\n",
      "BLEU-1: 0.498831\n",
      "BLEU-2: 0.243200\n",
      "BLEU-3: 0.167534\n",
      "BLEU-4: 0.071884\n",
      "BLEU-1: 0.499833\n",
      "BLEU-2: 0.244254\n",
      "BLEU-3: 0.168308\n",
      "BLEU-4: 0.072120\n",
      "BLEU-1: 0.499337\n",
      "BLEU-2: 0.243601\n",
      "BLEU-3: 0.167817\n",
      "BLEU-4: 0.071864\n",
      "BLEU-1: 0.500165\n",
      "BLEU-2: 0.244754\n",
      "BLEU-3: 0.168528\n",
      "BLEU-4: 0.072038\n",
      "BLEU-1: 0.500987\n",
      "BLEU-2: 0.246071\n",
      "BLEU-3: 0.169386\n",
      "BLEU-4: 0.072296\n",
      "BLEU-1: 0.501475\n",
      "BLEU-2: 0.246026\n",
      "BLEU-3: 0.169147\n",
      "BLEU-4: 0.072131\n",
      "BLEU-1: 0.501632\n",
      "BLEU-2: 0.245902\n",
      "BLEU-3: 0.168876\n",
      "BLEU-4: 0.071956\n",
      "BLEU-1: 0.501462\n",
      "BLEU-2: 0.246061\n",
      "BLEU-3: 0.169173\n",
      "BLEU-4: 0.071982\n",
      "BLEU-1: 0.500971\n",
      "BLEU-2: 0.245418\n",
      "BLEU-3: 0.168690\n",
      "BLEU-4: 0.071733\n",
      "BLEU-1: 0.500968\n",
      "BLEU-2: 0.245474\n",
      "BLEU-3: 0.168595\n",
      "BLEU-4: 0.071661\n",
      "BLEU-1: 0.501768\n",
      "BLEU-2: 0.245511\n",
      "BLEU-3: 0.168395\n",
      "BLEU-4: 0.071512\n",
      "BLEU-1: 0.501601\n",
      "BLEU-2: 0.244954\n",
      "BLEU-3: 0.167951\n",
      "BLEU-4: 0.071279\n",
      "BLEU-1: 0.503032\n",
      "BLEU-2: 0.246745\n",
      "BLEU-3: 0.169440\n",
      "BLEU-4: 0.072526\n",
      "BLEU-1: 0.502543\n",
      "BLEU-2: 0.246111\n",
      "BLEU-3: 0.168965\n",
      "BLEU-4: 0.072279\n",
      "BLEU-1: 0.503171\n",
      "BLEU-2: 0.245965\n",
      "BLEU-3: 0.168789\n",
      "BLEU-4: 0.072178\n",
      "BLEU-1: 0.503631\n",
      "BLEU-2: 0.246275\n",
      "BLEU-3: 0.169142\n",
      "BLEU-4: 0.072227\n",
      "BLEU-1: 0.502516\n",
      "BLEU-2: 0.245494\n",
      "BLEU-3: 0.168609\n",
      "BLEU-4: 0.071961\n",
      "BLEU-1: 0.502349\n",
      "BLEU-2: 0.245299\n",
      "BLEU-3: 0.168319\n",
      "BLEU-4: 0.071783\n",
      "BLEU-1: 0.502183\n",
      "BLEU-2: 0.245804\n",
      "BLEU-3: 0.168751\n",
      "BLEU-4: 0.071861\n",
      "BLEU-1: 0.501087\n",
      "BLEU-2: 0.245035\n",
      "BLEU-3: 0.168226\n",
      "BLEU-4: 0.071600\n",
      "BLEU-1: 0.500309\n",
      "BLEU-2: 0.244347\n",
      "BLEU-3: 0.167736\n",
      "BLEU-4: 0.071352\n",
      "BLEU-1: 0.500617\n",
      "BLEU-2: 0.244824\n",
      "BLEU-3: 0.167820\n",
      "BLEU-4: 0.071344\n",
      "BLEU-1: 0.500462\n",
      "BLEU-2: 0.244457\n",
      "BLEU-3: 0.167538\n",
      "BLEU-4: 0.071200\n",
      "BLEU-1: 0.500307\n",
      "BLEU-2: 0.244270\n",
      "BLEU-3: 0.167257\n",
      "BLEU-4: 0.071027\n",
      "BLEU-1: 0.499847\n",
      "BLEU-2: 0.243669\n",
      "BLEU-3: 0.166807\n",
      "BLEU-4: 0.070795\n",
      "BLEU-1: 0.499391\n",
      "BLEU-2: 0.243233\n",
      "BLEU-3: 0.166499\n",
      "BLEU-4: 0.070643\n",
      "BLEU-1: 0.499696\n",
      "BLEU-2: 0.243285\n",
      "BLEU-3: 0.166374\n",
      "BLEU-4: 0.070549\n",
      "BLEU-1: 0.499849\n",
      "BLEU-2: 0.242839\n",
      "BLEU-3: 0.165991\n",
      "BLEU-4: 0.070342\n",
      "BLEU-1: 0.500602\n",
      "BLEU-2: 0.243897\n",
      "BLEU-3: 0.166650\n",
      "BLEU-4: 0.070503\n",
      "BLEU-1: 0.500150\n",
      "BLEU-2: 0.243643\n",
      "BLEU-3: 0.166347\n",
      "BLEU-4: 0.070325\n",
      "BLEU-1: 0.500449\n",
      "BLEU-2: 0.243773\n",
      "BLEU-3: 0.166292\n",
      "BLEU-4: 0.070270\n",
      "BLEU-1: 0.500896\n",
      "BLEU-2: 0.244568\n",
      "BLEU-3: 0.166491\n",
      "BLEU-4: 0.070298\n",
      "BLEU-1: 0.501935\n",
      "BLEU-2: 0.246167\n",
      "BLEU-3: 0.168280\n",
      "BLEU-4: 0.071612\n",
      "BLEU-1: 0.502076\n",
      "BLEU-2: 0.245722\n",
      "BLEU-3: 0.167899\n",
      "BLEU-4: 0.071405\n",
      "BLEU-1: 0.501627\n",
      "BLEU-2: 0.245294\n",
      "BLEU-3: 0.167598\n",
      "BLEU-4: 0.071256\n",
      "BLEU-1: 0.501475\n",
      "BLEU-2: 0.244941\n",
      "BLEU-3: 0.167328\n",
      "BLEU-4: 0.071118\n",
      "BLEU-1: 0.501029\n",
      "BLEU-2: 0.244688\n",
      "BLEU-3: 0.167028\n",
      "BLEU-4: 0.070942\n",
      "BLEU-1: 0.500585\n",
      "BLEU-2: 0.244110\n",
      "BLEU-3: 0.166597\n",
      "BLEU-4: 0.070719\n",
      "BLEU-1: 0.500437\n",
      "BLEU-2: 0.243607\n",
      "BLEU-3: 0.166197\n",
      "BLEU-4: 0.070509\n",
      "BLEU-1: 0.500000\n",
      "BLEU-2: 0.243036\n",
      "BLEU-3: 0.165772\n",
      "BLEU-4: 0.070289\n",
      "BLEU-1: 0.500724\n",
      "BLEU-2: 0.243401\n",
      "BLEU-3: 0.165730\n",
      "BLEU-4: 0.070206\n",
      "BLEU-1: 0.501730\n",
      "BLEU-2: 0.244481\n",
      "BLEU-3: 0.166798\n",
      "BLEU-4: 0.071210\n",
      "BLEU-1: 0.502155\n",
      "BLEU-2: 0.245412\n",
      "BLEU-3: 0.167798\n",
      "BLEU-4: 0.072174\n",
      "BLEU-1: 0.501719\n",
      "BLEU-2: 0.244998\n",
      "BLEU-3: 0.167506\n",
      "BLEU-4: 0.072028\n",
      "BLEU-1: 0.502429\n",
      "BLEU-2: 0.245824\n",
      "BLEU-3: 0.168125\n",
      "BLEU-4: 0.072208\n",
      "BLEU-1: 0.502278\n",
      "BLEU-2: 0.245328\n",
      "BLEU-3: 0.167731\n",
      "BLEU-4: 0.071997\n",
      "BLEU-1: 0.503262\n",
      "BLEU-2: 0.246381\n",
      "BLEU-3: 0.168768\n",
      "BLEU-4: 0.072959\n",
      "BLEU-1: 0.503392\n",
      "BLEU-2: 0.245955\n",
      "BLEU-3: 0.168403\n",
      "BLEU-4: 0.072759\n",
      "BLEU-1: 0.503239\n",
      "BLEU-2: 0.245779\n",
      "BLEU-3: 0.168142\n",
      "BLEU-4: 0.072596\n",
      "BLEU-1: 0.502806\n",
      "BLEU-2: 0.245221\n",
      "BLEU-3: 0.167725\n",
      "BLEU-4: 0.072378\n",
      "BLEU-1: 0.502800\n",
      "BLEU-2: 0.244956\n",
      "BLEU-3: 0.167515\n",
      "BLEU-4: 0.072268\n",
      "BLEU-1: 0.502929\n",
      "BLEU-2: 0.244539\n",
      "BLEU-3: 0.167158\n",
      "BLEU-4: 0.072072\n",
      "BLEU-1: 0.502779\n",
      "BLEU-2: 0.244057\n",
      "BLEU-3: 0.166775\n",
      "BLEU-4: 0.071867\n",
      "BLEU-1: 0.502077\n",
      "BLEU-2: 0.243443\n",
      "BLEU-3: 0.166340\n",
      "BLEU-4: 0.071644\n",
      "BLEU-1: 0.502762\n",
      "BLEU-2: 0.244559\n",
      "BLEU-3: 0.167070\n",
      "BLEU-4: 0.071866\n",
      "BLEU-1: 0.503169\n",
      "BLEU-2: 0.245601\n",
      "BLEU-3: 0.168538\n",
      "BLEU-4: 0.073610\n",
      "BLEU-1: 0.503295\n",
      "BLEU-2: 0.245804\n",
      "BLEU-3: 0.168819\n",
      "BLEU-4: 0.073645\n",
      "BLEU-1: 0.502873\n",
      "BLEU-2: 0.245566\n",
      "BLEU-3: 0.168537\n",
      "BLEU-4: 0.073475\n",
      "BLEU-1: 0.502182\n",
      "BLEU-2: 0.245031\n",
      "BLEU-3: 0.168167\n",
      "BLEU-4: 0.073286\n",
      "BLEU-1: 0.502039\n",
      "BLEU-2: 0.244864\n",
      "BLEU-3: 0.167916\n",
      "BLEU-4: 0.073128\n",
      "BLEU-1: 0.501625\n",
      "BLEU-2: 0.244328\n",
      "BLEU-3: 0.167515\n",
      "BLEU-4: 0.072916\n",
      "BLEU-1: 0.502025\n",
      "BLEU-2: 0.244671\n",
      "BLEU-3: 0.167508\n",
      "BLEU-4: 0.072861\n",
      "BLEU-1: 0.501884\n",
      "BLEU-2: 0.244204\n",
      "BLEU-3: 0.167137\n",
      "BLEU-4: 0.072661\n",
      "BLEU-1: 0.501207\n",
      "BLEU-2: 0.243610\n",
      "BLEU-3: 0.166715\n",
      "BLEU-4: 0.072442\n",
      "BLEU-1: 0.501603\n",
      "BLEU-2: 0.245079\n",
      "BLEU-3: 0.167515\n",
      "BLEU-4: 0.072667\n",
      "BLEU-1: 0.501200\n",
      "BLEU-2: 0.244694\n",
      "BLEU-3: 0.167245\n",
      "BLEU-4: 0.072530\n",
      "BLEU-1: 0.500531\n",
      "BLEU-2: 0.244105\n",
      "BLEU-3: 0.166826\n",
      "BLEU-4: 0.072314\n",
      "BLEU-1: 0.500397\n",
      "BLEU-2: 0.244538\n",
      "BLEU-3: 0.167571\n",
      "BLEU-4: 0.073115\n",
      "BLEU-1: 0.500528\n",
      "BLEU-2: 0.244736\n",
      "BLEU-3: 0.167476\n",
      "BLEU-4: 0.073016\n",
      "BLEU-1: 0.500131\n",
      "BLEU-2: 0.244511\n",
      "BLEU-3: 0.167209\n",
      "BLEU-4: 0.072854\n",
      "BLEU-1: 0.501312\n",
      "BLEU-2: 0.245692\n",
      "BLEU-3: 0.168317\n",
      "BLEU-4: 0.073801\n",
      "BLEU-1: 0.501961\n",
      "BLEU-2: 0.246885\n",
      "BLEU-3: 0.169723\n",
      "BLEU-4: 0.074823\n",
      "BLEU-1: 0.502084\n",
      "BLEU-2: 0.247073\n",
      "BLEU-3: 0.169984\n",
      "BLEU-4: 0.074853\n",
      "BLEU-1: 0.502207\n",
      "BLEU-2: 0.246971\n",
      "BLEU-3: 0.169766\n",
      "BLEU-4: 0.074708\n",
      "BLEU-1: 0.503106\n",
      "BLEU-2: 0.248209\n",
      "BLEU-3: 0.171171\n",
      "BLEU-4: 0.075721\n",
      "BLEU-1: 0.502966\n",
      "BLEU-2: 0.248040\n",
      "BLEU-3: 0.170926\n",
      "BLEU-4: 0.075565\n",
      "BLEU-1: 0.502828\n",
      "BLEU-2: 0.247588\n",
      "BLEU-3: 0.170564\n",
      "BLEU-4: 0.075366\n",
      "BLEU-1: 0.502690\n",
      "BLEU-2: 0.247138\n",
      "BLEU-3: 0.170204\n",
      "BLEU-4: 0.075169\n",
      "BLEU-1: 0.503194\n",
      "BLEU-2: 0.247803\n",
      "BLEU-3: 0.170704\n",
      "BLEU-4: 0.075308\n",
      "BLEU-1: 0.503315\n",
      "BLEU-2: 0.247839\n",
      "BLEU-3: 0.170609\n",
      "BLEU-4: 0.075234\n",
      "BLEU-1: 0.502922\n",
      "BLEU-2: 0.247330\n",
      "BLEU-3: 0.170226\n",
      "BLEU-4: 0.075029\n",
      "BLEU-1: 0.503424\n",
      "BLEU-2: 0.247495\n",
      "BLEU-3: 0.170201\n",
      "BLEU-4: 0.074988\n",
      "BLEU-1: 0.503033\n",
      "BLEU-2: 0.247269\n",
      "BLEU-3: 0.169937\n",
      "BLEU-4: 0.074827\n",
      "BLEU-1: 0.502899\n",
      "BLEU-2: 0.247456\n",
      "BLEU-3: 0.170222\n",
      "BLEU-4: 0.074881\n",
      "BLEU-1: 0.503266\n",
      "BLEU-2: 0.247697\n",
      "BLEU-3: 0.170498\n",
      "BLEU-4: 0.074919\n",
      "BLEU-1: 0.503882\n",
      "BLEU-2: 0.247719\n",
      "BLEU-3: 0.170337\n",
      "BLEU-4: 0.074797\n",
      "BLEU-1: 0.503744\n",
      "BLEU-2: 0.247280\n",
      "BLEU-3: 0.169987\n",
      "BLEU-4: 0.074606\n",
      "BLEU-1: 0.503857\n",
      "BLEU-2: 0.246904\n",
      "BLEU-3: 0.169663\n",
      "BLEU-4: 0.074426\n",
      "BLEU-1: 0.504220\n",
      "BLEU-2: 0.247002\n",
      "BLEU-3: 0.169597\n",
      "BLEU-4: 0.074365\n",
      "BLEU-1: 0.504087\n",
      "BLEU-2: 0.246978\n",
      "BLEU-3: 0.169481\n",
      "BLEU-4: 0.074285\n",
      "BLEU-1: 0.504938\n",
      "BLEU-2: 0.248162\n",
      "BLEU-3: 0.170486\n",
      "BLEU-4: 0.074590\n",
      "BLEU-1: 0.505046\n",
      "BLEU-2: 0.247788\n",
      "BLEU-3: 0.170165\n",
      "BLEU-4: 0.074411\n",
      "BLEU-1: 0.504907\n",
      "BLEU-2: 0.247355\n",
      "BLEU-3: 0.169821\n",
      "BLEU-4: 0.074225\n",
      "BLEU-1: 0.504280\n",
      "BLEU-2: 0.246805\n",
      "BLEU-3: 0.169429\n",
      "BLEU-4: 0.074021\n",
      "BLEU-1: 0.504515\n",
      "BLEU-2: 0.247177\n",
      "BLEU-3: 0.169492\n",
      "BLEU-4: 0.074014\n",
      "BLEU-1: 0.504623\n",
      "BLEU-2: 0.247080\n",
      "BLEU-3: 0.169288\n",
      "BLEU-4: 0.073879\n",
      "BLEU-1: 0.504857\n",
      "BLEU-2: 0.247179\n",
      "BLEU-3: 0.169240\n",
      "BLEU-4: 0.073831\n",
      "BLEU-1: 0.504962\n",
      "BLEU-2: 0.246812\n",
      "BLEU-3: 0.168926\n",
      "BLEU-4: 0.073657\n",
      "BLEU-1: 0.505072\n",
      "BLEU-2: 0.246848\n",
      "BLEU-3: 0.168838\n",
      "BLEU-4: 0.073589\n",
      "BLEU-1: 0.504455\n",
      "BLEU-2: 0.246307\n",
      "BLEU-3: 0.168454\n",
      "BLEU-4: 0.073391\n",
      "BLEU-1: 0.504801\n",
      "BLEU-2: 0.246810\n",
      "BLEU-3: 0.168835\n",
      "BLEU-4: 0.073470\n",
      "BLEU-1: 0.505271\n",
      "BLEU-2: 0.247234\n",
      "BLEU-3: 0.169256\n",
      "BLEU-4: 0.073593\n",
      "BLEU-1: 0.505374\n",
      "BLEU-2: 0.246872\n",
      "BLEU-3: 0.168947\n",
      "BLEU-4: 0.073422\n",
      "BLEU-1: 0.505000\n",
      "BLEU-2: 0.246395\n",
      "BLEU-3: 0.168591\n",
      "BLEU-4: 0.073234\n",
      "BLEU-1: 0.504866\n",
      "BLEU-2: 0.245978\n",
      "BLEU-3: 0.168261\n",
      "BLEU-4: 0.073056\n",
      "BLEU-1: 0.504496\n",
      "BLEU-2: 0.245506\n",
      "BLEU-3: 0.167909\n",
      "BLEU-4: 0.072871\n",
      "BLEU-1: 0.504960\n",
      "BLEU-2: 0.245928\n",
      "BLEU-3: 0.167995\n",
      "BLEU-4: 0.072873\n",
      "BLEU-1: 0.505422\n",
      "BLEU-2: 0.246083\n",
      "BLEU-3: 0.167973\n",
      "BLEU-4: 0.072836\n",
      "BLEU-1: 0.505758\n",
      "BLEU-2: 0.246313\n",
      "BLEU-3: 0.167910\n",
      "BLEU-4: 0.072756\n",
      "BLEU-1: 0.505623\n",
      "BLEU-2: 0.246165\n",
      "BLEU-3: 0.167693\n",
      "BLEU-4: 0.072620\n",
      "BLEU-1: 0.505022\n",
      "BLEU-2: 0.245904\n",
      "BLEU-3: 0.167430\n",
      "BLEU-4: 0.072469\n",
      "BLEU-1: 0.505359\n",
      "BLEU-2: 0.246457\n",
      "BLEU-3: 0.167859\n",
      "BLEU-4: 0.072578\n",
      "BLEU-1: 0.505226\n",
      "BLEU-2: 0.246049\n",
      "BLEU-3: 0.167537\n",
      "BLEU-4: 0.072405\n",
      "BLEU-1: 0.506021\n",
      "BLEU-2: 0.247167\n",
      "BLEU-3: 0.168494\n",
      "BLEU-4: 0.072693\n",
      "BLEU-1: 0.506350\n",
      "BLEU-2: 0.247647\n",
      "BLEU-3: 0.168860\n",
      "BLEU-4: 0.072768\n",
      "BLEU-1: 0.506912\n",
      "BLEU-2: 0.248565\n",
      "BLEU-3: 0.169784\n",
      "BLEU-4: 0.073066\n",
      "BLEU-1: 0.507466\n",
      "BLEU-2: 0.249094\n",
      "BLEU-3: 0.170167\n",
      "BLEU-4: 0.073147\n",
      "BLEU-1: 0.507100\n",
      "BLEU-2: 0.248885\n",
      "BLEU-3: 0.169927\n",
      "BLEU-4: 0.073005\n",
      "BLEU-1: 0.506737\n",
      "BLEU-2: 0.248423\n",
      "BLEU-3: 0.169583\n",
      "BLEU-4: 0.072826\n",
      "BLEU-1: 0.507065\n",
      "BLEU-2: 0.249017\n",
      "BLEU-3: 0.170048\n",
      "BLEU-4: 0.072958\n",
      "BLEU-1: 0.507839\n",
      "BLEU-2: 0.250603\n",
      "BLEU-3: 0.171811\n",
      "BLEU-4: 0.075103\n",
      "BLEU-1: 0.508156\n",
      "BLEU-2: 0.251062\n",
      "BLEU-3: 0.172158\n",
      "BLEU-4: 0.075172\n",
      "BLEU-1: 0.507793\n",
      "BLEU-2: 0.250600\n",
      "BLEU-3: 0.171813\n",
      "BLEU-4: 0.074990\n",
      "BLEU-1: 0.507207\n",
      "BLEU-2: 0.250085\n",
      "BLEU-3: 0.171448\n",
      "BLEU-4: 0.074800\n",
      "BLEU-1: 0.507523\n",
      "BLEU-2: 0.250541\n",
      "BLEU-3: 0.171482\n",
      "BLEU-4: 0.074756\n",
      "BLEU-1: 0.507841\n",
      "BLEU-2: 0.250809\n",
      "BLEU-3: 0.171467\n",
      "BLEU-4: 0.074706\n",
      "BLEU-1: 0.507489\n",
      "BLEU-2: 0.250477\n",
      "BLEU-3: 0.171233\n",
      "BLEU-4: 0.074587\n",
      "BLEU-1: 0.507802\n",
      "BLEU-2: 0.250928\n",
      "BLEU-3: 0.171577\n",
      "BLEU-4: 0.074656\n",
      "BLEU-1: 0.508335\n",
      "BLEU-2: 0.251677\n",
      "BLEU-3: 0.172350\n",
      "BLEU-4: 0.075381\n",
      "BLEU-1: 0.507986\n",
      "BLEU-2: 0.251346\n",
      "BLEU-3: 0.172118\n",
      "BLEU-4: 0.075263\n",
      "BLEU-1: 0.508073\n",
      "BLEU-2: 0.251248\n",
      "BLEU-3: 0.171926\n",
      "BLEU-4: 0.075137\n",
      "BLEU-1: 0.507940\n",
      "BLEU-2: 0.250851\n",
      "BLEU-3: 0.171612\n",
      "BLEU-4: 0.074967\n",
      "BLEU-1: 0.507594\n",
      "BLEU-2: 0.250524\n",
      "BLEU-3: 0.171382\n",
      "BLEU-4: 0.074850\n",
      "BLEU-1: 0.508560\n",
      "BLEU-2: 0.251131\n",
      "BLEU-3: 0.171787\n",
      "BLEU-4: 0.074942\n",
      "BLEU-1: 0.508764\n",
      "BLEU-2: 0.251213\n",
      "BLEU-3: 0.171739\n",
      "BLEU-4: 0.074897\n",
      "BLEU-1: 0.508412\n",
      "BLEU-2: 0.250766\n",
      "BLEU-3: 0.171406\n",
      "BLEU-4: 0.074722\n",
      "BLEU-1: 0.508497\n",
      "BLEU-2: 0.250429\n",
      "BLEU-3: 0.171119\n",
      "BLEU-4: 0.074563\n",
      "BLEU-1: 0.508154\n",
      "BLEU-2: 0.250106\n",
      "BLEU-3: 0.170893\n",
      "BLEU-4: 0.074448\n",
      "BLEU-1: 0.508239\n",
      "BLEU-2: 0.250012\n",
      "BLEU-3: 0.170707\n",
      "BLEU-4: 0.074326\n",
      "BLEU-1: 0.508548\n",
      "BLEU-2: 0.250333\n",
      "BLEU-3: 0.171047\n",
      "BLEU-4: 0.074417\n",
      "BLEU-1: 0.509393\n",
      "BLEU-2: 0.250994\n",
      "BLEU-3: 0.171512\n",
      "BLEU-4: 0.074548\n",
      "BLEU-1: 0.509698\n",
      "BLEU-2: 0.251549\n",
      "BLEU-3: 0.172246\n",
      "BLEU-4: 0.075268\n",
      "BLEU-1: 0.509779\n",
      "BLEU-2: 0.251452\n",
      "BLEU-3: 0.172059\n",
      "BLEU-4: 0.075146\n",
      "BLEU-1: 0.509867\n",
      "BLEU-2: 0.251951\n",
      "BLEU-3: 0.172765\n",
      "BLEU-4: 0.075849\n",
      "BLEU-1: 0.509519\n",
      "BLEU-2: 0.251748\n",
      "BLEU-3: 0.172534\n",
      "BLEU-4: 0.075710\n",
      "BLEU-1: 0.510239\n",
      "BLEU-2: 0.253223\n",
      "BLEU-3: 0.174461\n",
      "BLEU-4: 0.077752\n",
      "BLEU-1: 0.510009\n",
      "BLEU-2: 0.252959\n",
      "BLEU-3: 0.174272\n",
      "BLEU-4: 0.077654\n",
      "BLEU-1: 0.510204\n",
      "BLEU-2: 0.253271\n",
      "BLEU-3: 0.174610\n",
      "BLEU-4: 0.077752\n",
      "BLEU-1: 0.509858\n",
      "BLEU-2: 0.252832\n",
      "BLEU-3: 0.174281\n",
      "BLEU-4: 0.077574\n",
      "BLEU-1: 0.509937\n",
      "BLEU-2: 0.252967\n",
      "BLEU-3: 0.174478\n",
      "BLEU-4: 0.077592\n",
      "BLEU-1: 0.510226\n",
      "BLEU-2: 0.253386\n",
      "BLEU-3: 0.174792\n",
      "BLEU-4: 0.077653\n",
      "BLEU-1: 0.510311\n",
      "BLEU-2: 0.253637\n",
      "BLEU-3: 0.175089\n",
      "BLEU-4: 0.077730\n",
      "BLEU-1: 0.510178\n",
      "BLEU-2: 0.253717\n",
      "BLEU-3: 0.174975\n",
      "BLEU-4: 0.077633\n",
      "BLEU-1: 0.510371\n",
      "BLEU-2: 0.254252\n",
      "BLEU-3: 0.175402\n",
      "BLEU-4: 0.077764\n",
      "BLEU-1: 0.510447\n",
      "BLEU-2: 0.253922\n",
      "BLEU-3: 0.175119\n",
      "BLEU-4: 0.077605\n",
      "BLEU-1: 0.510323\n",
      "BLEU-2: 0.254118\n",
      "BLEU-3: 0.175391\n",
      "BLEU-4: 0.077673\n",
      "BLEU-1: 0.510616\n",
      "BLEU-2: 0.254873\n",
      "BLEU-3: 0.176175\n",
      "BLEU-4: 0.078378\n",
      "BLEU-1: 0.510806\n",
      "BLEU-2: 0.254945\n",
      "BLEU-3: 0.176126\n",
      "BLEU-4: 0.078333\n",
      "BLEU-1: 0.510678\n",
      "BLEU-2: 0.254851\n",
      "BLEU-3: 0.175968\n",
      "BLEU-4: 0.078230\n",
      "BLEU-1: 0.511175\n",
      "BLEU-2: 0.255425\n",
      "BLEU-3: 0.176673\n",
      "BLEU-4: 0.078901\n",
      "BLEU-1: 0.510630\n",
      "BLEU-2: 0.255168\n",
      "BLEU-3: 0.176421\n",
      "BLEU-4: 0.078752\n",
      "BLEU-1: 0.511226\n",
      "BLEU-2: 0.255509\n",
      "BLEU-3: 0.176457\n",
      "BLEU-4: 0.078727\n",
      "BLEU-1: 0.511303\n",
      "BLEU-2: 0.255915\n",
      "BLEU-3: 0.176786\n",
      "BLEU-4: 0.078806\n",
      "BLEU-1: 0.510965\n",
      "BLEU-2: 0.255487\n",
      "BLEU-3: 0.176464\n",
      "BLEU-4: 0.078632\n",
      "BLEU-1: 0.511357\n",
      "BLEU-2: 0.255608\n",
      "BLEU-3: 0.176436\n",
      "BLEU-4: 0.078594\n",
      "BLEU-1: 0.511224\n",
      "BLEU-2: 0.255456\n",
      "BLEU-3: 0.176229\n",
      "BLEU-4: 0.078464\n",
      "BLEU-1: 0.510889\n",
      "BLEU-2: 0.255031\n",
      "BLEU-3: 0.175910\n",
      "BLEU-4: 0.078292\n",
      "BLEU-1: 0.510962\n",
      "BLEU-2: 0.254709\n",
      "BLEU-3: 0.175635\n",
      "BLEU-4: 0.078136\n",
      "BLEU-1: 0.510837\n",
      "BLEU-2: 0.254618\n",
      "BLEU-3: 0.175481\n",
      "BLEU-4: 0.078037\n",
      "BLEU-1: 0.510505\n",
      "BLEU-2: 0.254420\n",
      "BLEU-3: 0.175258\n",
      "BLEU-4: 0.077901\n",
      "BLEU-1: 0.511089\n",
      "BLEU-2: 0.254976\n",
      "BLEU-3: 0.175934\n",
      "BLEU-4: 0.078545\n",
      "BLEU-1: 0.510557\n",
      "BLEU-2: 0.254507\n",
      "BLEU-3: 0.175599\n",
      "BLEU-4: 0.078367\n",
      "BLEU-1: 0.510634\n",
      "BLEU-2: 0.254687\n",
      "BLEU-3: 0.175559\n",
      "BLEU-4: 0.078310\n",
      "BLEU-1: 0.510306\n",
      "BLEU-2: 0.254490\n",
      "BLEU-3: 0.175338\n",
      "BLEU-4: 0.078175\n",
      "BLEU-1: 0.510188\n",
      "BLEU-2: 0.254238\n",
      "BLEU-3: 0.175145\n",
      "BLEU-4: 0.078072\n",
      "BLEU-1: 0.509863\n",
      "BLEU-2: 0.253825\n",
      "BLEU-3: 0.174835\n",
      "BLEU-4: 0.077904\n",
      "BLEU-1: 0.510435\n",
      "BLEU-2: 0.254319\n",
      "BLEU-3: 0.175184\n",
      "BLEU-4: 0.077987\n",
      "BLEU-1: 0.510317\n",
      "BLEU-2: 0.254069\n",
      "BLEU-3: 0.174993\n",
      "BLEU-4: 0.077885\n",
      "BLEU-1: 0.510495\n",
      "BLEU-2: 0.254083\n",
      "BLEU-3: 0.174898\n",
      "BLEU-4: 0.077813\n",
      "BLEU-1: 0.510369\n",
      "BLEU-2: 0.253939\n",
      "BLEU-3: 0.174702\n",
      "BLEU-4: 0.077689\n",
      "BLEU-1: 0.509850\n",
      "BLEU-2: 0.253482\n",
      "BLEU-3: 0.174376\n",
      "BLEU-4: 0.077516\n",
      "BLEU-1: 0.509923\n",
      "BLEU-2: 0.253389\n",
      "BLEU-3: 0.174201\n",
      "BLEU-4: 0.077400\n",
      "BLEU-1: 0.509908\n",
      "BLEU-2: 0.253195\n",
      "BLEU-3: 0.174047\n",
      "BLEU-4: 0.077318\n",
      "BLEU-1: 0.509693\n",
      "BLEU-2: 0.252897\n",
      "BLEU-3: 0.173825\n",
      "BLEU-4: 0.077200\n",
      "BLEU-1: 0.509873\n",
      "BLEU-2: 0.252968\n",
      "BLEU-3: 0.173781\n",
      "BLEU-4: 0.077158\n",
      "BLEU-1: 0.510335\n",
      "BLEU-2: 0.253404\n",
      "BLEU-3: 0.174361\n",
      "BLEU-4: 0.077739\n",
      "BLEU-1: 0.510415\n",
      "BLEU-2: 0.253851\n",
      "BLEU-3: 0.174991\n",
      "BLEU-4: 0.078354\n",
      "BLEU-1: 0.511077\n",
      "BLEU-2: 0.255080\n",
      "BLEU-3: 0.176468\n",
      "BLEU-4: 0.080078\n",
      "BLEU-1: 0.510960\n",
      "BLEU-2: 0.255047\n",
      "BLEU-3: 0.176368\n",
      "BLEU-4: 0.080009\n",
      "BLEU-1: 0.511029\n",
      "BLEU-2: 0.254740\n",
      "BLEU-3: 0.176104\n",
      "BLEU-4: 0.079857\n",
      "BLEU-1: 0.510712\n",
      "BLEU-2: 0.254338\n",
      "BLEU-3: 0.175802\n",
      "BLEU-4: 0.079691\n",
      "BLEU-1: 0.510974\n",
      "BLEU-2: 0.254716\n",
      "BLEU-3: 0.176085\n",
      "BLEU-4: 0.079746\n",
      "BLEU-1: 0.510467\n",
      "BLEU-2: 0.254480\n",
      "BLEU-3: 0.175852\n",
      "BLEU-4: 0.079606\n",
      "BLEU-1: 0.510345\n",
      "BLEU-2: 0.254129\n",
      "BLEU-3: 0.175572\n",
      "BLEU-4: 0.079450\n",
      "BLEU-1: 0.510224\n",
      "BLEU-2: 0.253780\n",
      "BLEU-3: 0.175294\n",
      "BLEU-4: 0.079294\n",
      "BLEU-1: 0.510103\n",
      "BLEU-2: 0.253642\n",
      "BLEU-3: 0.175104\n",
      "BLEU-4: 0.079171\n",
      "BLEU-1: 0.510173\n",
      "BLEU-2: 0.253552\n",
      "BLEU-3: 0.174934\n",
      "BLEU-4: 0.079056\n",
      "BLEU-1: 0.510158\n",
      "BLEU-2: 0.253573\n",
      "BLEU-3: 0.174870\n",
      "BLEU-4: 0.079007\n",
      "BLEU-1: 0.509659\n",
      "BLEU-2: 0.253134\n",
      "BLEU-3: 0.174556\n",
      "BLEU-4: 0.078839\n",
      "BLEU-1: 0.510108\n",
      "BLEU-2: 0.254178\n",
      "BLEU-3: 0.175628\n",
      "BLEU-4: 0.079577\n",
      "BLEU-1: 0.510373\n",
      "BLEU-2: 0.254449\n",
      "BLEU-3: 0.175911\n",
      "BLEU-4: 0.079653\n",
      "BLEU-1: 0.510254\n",
      "BLEU-2: 0.254105\n",
      "BLEU-3: 0.175637\n",
      "BLEU-4: 0.079499\n",
      "BLEU-1: 0.510323\n",
      "BLEU-2: 0.254427\n",
      "BLEU-3: 0.176146\n",
      "BLEU-4: 0.080021\n",
      "BLEU-1: 0.510870\n",
      "BLEU-2: 0.255407\n",
      "BLEU-3: 0.177488\n",
      "BLEU-4: 0.081619\n",
      "BLEU-1: 0.510563\n",
      "BLEU-2: 0.255222\n",
      "BLEU-3: 0.177278\n",
      "BLEU-4: 0.081488\n",
      "BLEU-1: 0.510630\n",
      "BLEU-2: 0.254926\n",
      "BLEU-3: 0.177023\n",
      "BLEU-4: 0.081339\n",
      "BLEU-1: 0.510140\n",
      "BLEU-2: 0.254696\n",
      "BLEU-3: 0.176796\n",
      "BLEU-4: 0.081201\n",
      "BLEU-1: 0.510208\n",
      "BLEU-2: 0.254810\n",
      "BLEU-3: 0.176961\n",
      "BLEU-4: 0.081213\n",
      "BLEU-1: 0.510276\n",
      "BLEU-2: 0.255125\n",
      "BLEU-3: 0.177210\n",
      "BLEU-4: 0.081258\n",
      "BLEU-1: 0.510076\n",
      "BLEU-2: 0.254895\n",
      "BLEU-3: 0.177042\n",
      "BLEU-4: 0.081169\n",
      "BLEU-1: 0.510615\n",
      "BLEU-2: 0.255657\n",
      "BLEU-3: 0.177536\n",
      "BLEU-4: 0.081332\n",
      "BLEU-1: 0.510497\n",
      "BLEU-2: 0.255318\n",
      "BLEU-3: 0.177264\n",
      "BLEU-4: 0.081178\n",
      "BLEU-1: 0.510572\n",
      "BLEU-2: 0.255533\n",
      "BLEU-3: 0.177517\n",
      "BLEU-4: 0.081244\n",
      "BLEU-1: 0.510271\n",
      "BLEU-2: 0.255151\n",
      "BLEU-3: 0.177228\n",
      "BLEU-4: 0.081084\n",
      "BLEU-1: 0.510522\n",
      "BLEU-2: 0.255507\n",
      "BLEU-3: 0.177492\n",
      "BLEU-4: 0.081134\n",
      "BLEU-1: 0.510405\n",
      "BLEU-2: 0.255571\n",
      "BLEU-3: 0.177389\n",
      "BLEU-4: 0.081045\n",
      "BLEU-1: 0.510390\n",
      "BLEU-2: 0.255588\n",
      "BLEU-3: 0.177326\n",
      "BLEU-4: 0.080996\n",
      "BLEU-1: 0.510557\n",
      "BLEU-2: 0.255849\n",
      "BLEU-3: 0.177364\n",
      "BLEU-4: 0.080986\n",
      "BLEU-1: 0.510804\n",
      "BLEU-2: 0.256200\n",
      "BLEU-3: 0.177626\n",
      "BLEU-4: 0.081036\n",
      "BLEU-1: 0.510870\n",
      "BLEU-2: 0.256110\n",
      "BLEU-3: 0.177460\n",
      "BLEU-4: 0.080923\n",
      "BLEU-1: 0.510211\n",
      "BLEU-2: 0.255641\n",
      "BLEU-3: 0.177137\n",
      "BLEU-4: 0.080752\n",
      "BLEU-1: 0.510097\n",
      "BLEU-2: 0.255703\n",
      "BLEU-3: 0.177036\n",
      "BLEU-4: 0.080664\n",
      "BLEU-1: 0.510344\n",
      "BLEU-2: 0.255463\n",
      "BLEU-3: 0.176809\n",
      "BLEU-4: 0.080529\n",
      "BLEU-1: 0.509691\n",
      "BLEU-2: 0.254999\n",
      "BLEU-3: 0.176490\n",
      "BLEU-4: 0.080360\n",
      "BLEU-1: 0.509937\n",
      "BLEU-2: 0.255739\n",
      "BLEU-3: 0.177153\n",
      "BLEU-4: 0.080563\n",
      "BLEU-1: 0.510189\n",
      "BLEU-2: 0.256381\n",
      "BLEU-3: 0.178059\n",
      "BLEU-4: 0.081589\n",
      "BLEU-1: 0.510433\n",
      "BLEU-2: 0.256918\n",
      "BLEU-3: 0.178631\n",
      "BLEU-4: 0.081758\n",
      "BLEU-1: 0.510597\n",
      "BLEU-2: 0.256977\n",
      "BLEU-3: 0.178587\n",
      "BLEU-4: 0.081717\n",
      "BLEU-1: 0.509950\n",
      "BLEU-2: 0.256515\n",
      "BLEU-3: 0.178268\n",
      "BLEU-4: 0.081546\n",
      "BLEU-1: 0.509842\n",
      "BLEU-2: 0.256625\n",
      "BLEU-3: 0.178447\n",
      "BLEU-4: 0.081576\n",
      "BLEU-1: 0.509377\n",
      "BLEU-2: 0.256210\n",
      "BLEU-3: 0.178148\n",
      "BLEU-4: 0.081413\n",
      "BLEU-1: 0.508914\n",
      "BLEU-2: 0.255797\n",
      "BLEU-3: 0.177850\n",
      "BLEU-4: 0.081251\n",
      "BLEU-1: 0.508809\n",
      "BLEU-2: 0.255907\n",
      "BLEU-3: 0.177794\n",
      "BLEU-4: 0.081192\n",
      "BLEU-1: 0.508877\n",
      "BLEU-2: 0.256202\n",
      "BLEU-3: 0.178027\n",
      "BLEU-4: 0.081232\n",
      "BLEU-1: 0.508944\n",
      "BLEU-2: 0.256305\n",
      "BLEU-3: 0.178179\n",
      "BLEU-4: 0.081242\n",
      "BLEU-1: 0.508836\n",
      "BLEU-2: 0.256364\n",
      "BLEU-3: 0.178312\n",
      "BLEU-4: 0.081245\n",
      "BLEU-1: 0.509259\n",
      "BLEU-2: 0.256843\n",
      "BLEU-3: 0.178433\n",
      "BLEU-4: 0.081262\n",
      "BLEU-1: 0.509325\n",
      "BLEU-2: 0.256944\n",
      "BLEU-3: 0.178583\n",
      "BLEU-4: 0.081271\n",
      "BLEU-1: 0.509043\n",
      "BLEU-2: 0.256579\n",
      "BLEU-3: 0.178308\n",
      "BLEU-4: 0.081119\n",
      "BLEU-1: 0.508763\n",
      "BLEU-2: 0.256216\n",
      "BLEU-3: 0.178033\n",
      "BLEU-4: 0.080968\n",
      "BLEU-1: 0.509003\n",
      "BLEU-2: 0.256550\n",
      "BLEU-3: 0.178510\n",
      "BLEU-4: 0.081449\n",
      "BLEU-1: 0.508378\n",
      "BLEU-2: 0.256101\n",
      "BLEU-3: 0.178200\n",
      "BLEU-4: 0.081283\n",
      "BLEU-1: 0.508445\n",
      "BLEU-2: 0.256390\n",
      "BLEU-3: 0.178656\n",
      "BLEU-4: 0.081752\n",
      "BLEU-1: 0.508950\n",
      "BLEU-2: 0.256721\n",
      "BLEU-3: 0.178728\n",
      "BLEU-4: 0.081756\n",
      "BLEU-1: 0.509282\n",
      "BLEU-2: 0.257195\n",
      "BLEU-3: 0.178858\n",
      "BLEU-4: 0.081782\n",
      "BLEU-1: 0.509690\n",
      "BLEU-2: 0.257936\n",
      "BLEU-3: 0.179728\n",
      "BLEU-4: 0.082741\n",
      "BLEU-1: 0.509844\n",
      "BLEU-2: 0.257943\n",
      "BLEU-3: 0.179642\n",
      "BLEU-4: 0.082675\n",
      "BLEU-1: 0.509566\n",
      "BLEU-2: 0.257583\n",
      "BLEU-3: 0.179369\n",
      "BLEU-4: 0.082523\n",
      "BLEU-1: 0.509720\n",
      "BLEU-2: 0.257591\n",
      "BLEU-3: 0.179284\n",
      "BLEU-4: 0.082457\n",
      "BLEU-1: 0.509954\n",
      "BLEU-2: 0.257546\n",
      "BLEU-3: 0.179143\n",
      "BLEU-4: 0.082356\n",
      "BLEU-1: 0.510357\n",
      "BLEU-2: 0.257729\n",
      "BLEU-3: 0.179324\n",
      "BLEU-4: 0.082378\n",
      "BLEU-1: 0.509910\n",
      "BLEU-2: 0.257329\n",
      "BLEU-3: 0.179036\n",
      "BLEU-4: 0.082221\n",
      "BLEU-1: 0.509973\n",
      "BLEU-2: 0.257060\n",
      "BLEU-3: 0.178803\n",
      "BLEU-4: 0.082085\n",
      "BLEU-1: 0.509529\n",
      "BLEU-2: 0.256663\n",
      "BLEU-3: 0.178517\n",
      "BLEU-4: 0.081929\n",
      "BLEU-1: 0.509088\n",
      "BLEU-2: 0.256269\n",
      "BLEU-3: 0.178233\n",
      "BLEU-4: 0.081774\n",
      "BLEU-1: 0.509580\n",
      "BLEU-2: 0.257322\n",
      "BLEU-3: 0.179054\n",
      "BLEU-4: 0.082065\n",
      "BLEU-1: 0.509814\n",
      "BLEU-2: 0.257508\n",
      "BLEU-3: 0.179034\n",
      "BLEU-4: 0.082020\n",
      "BLEU-1: 0.509374\n",
      "BLEU-2: 0.257114\n",
      "BLEU-3: 0.178750\n",
      "BLEU-4: 0.081865\n",
      "BLEU-1: 0.509437\n",
      "BLEU-2: 0.257210\n",
      "BLEU-3: 0.178893\n",
      "BLEU-4: 0.081874\n",
      "BLEU-1: 0.509167\n",
      "BLEU-2: 0.257222\n",
      "BLEU-3: 0.179001\n",
      "BLEU-4: 0.081869\n",
      "BLEU-1: 0.509064\n",
      "BLEU-2: 0.256915\n",
      "BLEU-3: 0.178754\n",
      "BLEU-4: 0.081729\n",
      "BLEU-1: 0.508795\n",
      "BLEU-2: 0.256747\n",
      "BLEU-3: 0.178566\n",
      "BLEU-4: 0.081612\n",
      "BLEU-1: 0.508197\n",
      "BLEU-2: 0.256317\n",
      "BLEU-3: 0.178269\n",
      "BLEU-4: 0.081453\n",
      "BLEU-1: 0.507931\n",
      "BLEU-2: 0.255972\n",
      "BLEU-3: 0.178008\n",
      "BLEU-4: 0.081309\n",
      "BLEU-1: 0.507832\n",
      "BLEU-2: 0.256028\n",
      "BLEU-3: 0.178133\n",
      "BLEU-4: 0.081311\n",
      "BLEU-1: 0.508148\n",
      "BLEU-2: 0.256079\n",
      "BLEU-3: 0.178070\n",
      "BLEU-4: 0.081255\n",
      "BLEU-1: 0.508377\n",
      "BLEU-2: 0.256039\n",
      "BLEU-3: 0.177936\n",
      "BLEU-4: 0.081160\n",
      "BLEU-1: 0.508277\n",
      "BLEU-2: 0.255916\n",
      "BLEU-3: 0.177769\n",
      "BLEU-4: 0.081052\n",
      "BLEU-1: 0.508758\n",
      "BLEU-2: 0.256054\n",
      "BLEU-3: 0.177763\n",
      "BLEU-4: 0.081027\n",
      "BLEU-1: 0.508984\n",
      "BLEU-2: 0.256192\n",
      "BLEU-3: 0.177923\n",
      "BLEU-4: 0.081043\n",
      "BLEU-1: 0.508720\n",
      "BLEU-2: 0.255852\n",
      "BLEU-3: 0.177666\n",
      "BLEU-4: 0.080901\n",
      "BLEU-1: 0.508783\n",
      "BLEU-2: 0.255594\n",
      "BLEU-3: 0.177444\n",
      "BLEU-4: 0.080773\n",
      "BLEU-1: 0.508521\n",
      "BLEU-2: 0.255256\n",
      "BLEU-3: 0.177188\n",
      "BLEU-4: 0.080632\n",
      "BLEU-1: 0.508098\n",
      "BLEU-2: 0.255055\n",
      "BLEU-3: 0.176990\n",
      "BLEU-4: 0.080513\n",
      "BLEU-1: 0.508001\n",
      "BLEU-2: 0.254760\n",
      "BLEU-3: 0.176754\n",
      "BLEU-4: 0.080379\n",
      "BLEU-1: 0.507581\n",
      "BLEU-2: 0.254385\n",
      "BLEU-3: 0.176484\n",
      "BLEU-4: 0.080234\n",
      "BLEU-1: 0.507893\n",
      "BLEU-2: 0.254834\n",
      "BLEU-3: 0.176825\n",
      "BLEU-4: 0.080341\n",
      "BLEU-1: 0.508363\n",
      "BLEU-2: 0.254925\n",
      "BLEU-3: 0.176780\n",
      "BLEU-4: 0.080294\n",
      "BLEU-1: 0.508352\n",
      "BLEU-2: 0.254766\n",
      "BLEU-3: 0.176652\n",
      "BLEU-4: 0.080224\n",
      "BLEU-1: 0.508255\n",
      "BLEU-2: 0.254473\n",
      "BLEU-3: 0.176418\n",
      "BLEU-4: 0.080092\n",
      "BLEU-1: 0.508157\n",
      "BLEU-2: 0.254182\n",
      "BLEU-3: 0.176184\n",
      "BLEU-4: 0.079960\n",
      "BLEU-1: 0.508220\n",
      "BLEU-2: 0.254280\n",
      "BLEU-3: 0.176328\n",
      "BLEU-4: 0.079972\n",
      "BLEU-1: 0.508283\n",
      "BLEU-2: 0.254204\n",
      "BLEU-3: 0.176184\n",
      "BLEU-4: 0.079875\n",
      "BLEU-1: 0.508504\n",
      "BLEU-2: 0.254863\n",
      "BLEU-3: 0.177198\n",
      "BLEU-4: 0.081168\n",
      "BLEU-1: 0.507931\n",
      "BLEU-2: 0.254454\n",
      "BLEU-3: 0.176916\n",
      "BLEU-4: 0.081017\n",
      "BLEU-1: 0.508153\n",
      "BLEU-2: 0.254763\n",
      "BLEU-3: 0.177355\n",
      "BLEU-4: 0.081451\n",
      "BLEU-1: 0.508531\n",
      "BLEU-2: 0.255111\n",
      "BLEU-3: 0.177599\n",
      "BLEU-4: 0.081501\n",
      "BLEU-1: 0.508678\n",
      "BLEU-2: 0.255337\n",
      "BLEU-3: 0.177632\n",
      "BLEU-4: 0.081492\n",
      "BLEU-1: 0.509369\n",
      "BLEU-2: 0.256104\n",
      "BLEU-3: 0.178468\n",
      "BLEU-4: 0.081769\n",
      "BLEU-1: 0.509114\n",
      "BLEU-2: 0.255776\n",
      "BLEU-3: 0.178219\n",
      "BLEU-4: 0.081630\n",
      "BLEU-1: 0.508703\n",
      "BLEU-2: 0.255409\n",
      "BLEU-3: 0.177955\n",
      "BLEU-4: 0.081486\n",
      "BLEU-1: 0.508846\n",
      "BLEU-2: 0.255590\n",
      "BLEU-3: 0.178157\n",
      "BLEU-4: 0.081533\n",
      "BLEU-1: 0.508750\n",
      "BLEU-2: 0.255303\n",
      "BLEU-3: 0.177926\n",
      "BLEU-4: 0.081403\n",
      "BLEU-1: 0.508654\n",
      "BLEU-2: 0.255358\n",
      "BLEU-3: 0.178045\n",
      "BLEU-4: 0.081405\n",
      "BLEU-1: 0.508720\n",
      "BLEU-2: 0.255370\n",
      "BLEU-3: 0.177980\n",
      "BLEU-4: 0.081355\n",
      "BLEU-1: 0.508314\n",
      "BLEU-2: 0.255008\n",
      "BLEU-3: 0.177719\n",
      "BLEU-4: 0.081213\n",
      "BLEU-1: 0.508614\n",
      "BLEU-2: 0.255101\n",
      "BLEU-3: 0.177698\n",
      "BLEU-4: 0.081184\n",
      "BLEU-1: 0.508519\n",
      "BLEU-2: 0.255155\n",
      "BLEU-3: 0.177816\n",
      "BLEU-4: 0.081187\n",
      "BLEU-1: 0.508818\n",
      "BLEU-2: 0.255248\n",
      "BLEU-3: 0.177795\n",
      "BLEU-4: 0.081157\n",
      "BLEU-1: 0.508420\n",
      "BLEU-2: 0.254975\n",
      "BLEU-3: 0.177612\n",
      "BLEU-4: 0.081062\n",
      "BLEU-1: 0.508326\n",
      "BLEU-2: 0.254862\n",
      "BLEU-3: 0.177455\n",
      "BLEU-4: 0.080961\n",
      "BLEU-1: 0.508545\n",
      "BLEU-2: 0.255417\n",
      "BLEU-3: 0.178230\n",
      "BLEU-4: 0.081838\n",
      "BLEU-1: 0.508451\n",
      "BLEU-2: 0.255135\n",
      "BLEU-3: 0.178003\n",
      "BLEU-4: 0.081709\n",
      "BLEU-1: 0.508358\n",
      "BLEU-2: 0.255022\n",
      "BLEU-3: 0.177847\n",
      "BLEU-4: 0.081608\n",
      "BLEU-1: 0.508264\n",
      "BLEU-2: 0.254910\n",
      "BLEU-3: 0.177692\n",
      "BLEU-4: 0.081506\n",
      "BLEU-1: 0.508019\n",
      "BLEU-2: 0.254593\n",
      "BLEU-3: 0.177451\n",
      "BLEU-4: 0.081372\n",
      "BLEU-1: 0.507777\n",
      "BLEU-2: 0.254486\n",
      "BLEU-3: 0.177318\n",
      "BLEU-4: 0.081288\n",
      "BLEU-1: 0.508142\n",
      "BLEU-2: 0.255153\n",
      "BLEU-3: 0.178094\n",
      "BLEU-4: 0.082136\n",
      "BLEU-1: 0.507826\n",
      "BLEU-2: 0.254883\n",
      "BLEU-3: 0.177903\n",
      "BLEU-4: 0.082033\n",
      "BLEU-1: 0.507583\n",
      "BLEU-2: 0.254568\n",
      "BLEU-3: 0.177664\n",
      "BLEU-4: 0.081899\n",
      "BLEU-1: 0.507876\n",
      "BLEU-2: 0.254824\n",
      "BLEU-3: 0.177913\n",
      "BLEU-4: 0.081974\n",
      "BLEU-1: 0.507785\n",
      "BLEU-2: 0.254549\n",
      "BLEU-3: 0.177690\n",
      "BLEU-4: 0.081847\n",
      "BLEU-1: 0.507544\n",
      "BLEU-2: 0.254236\n",
      "BLEU-3: 0.177452\n",
      "BLEU-4: 0.081714\n",
      "BLEU-1: 0.507454\n",
      "BLEU-2: 0.254291\n",
      "BLEU-3: 0.177568\n",
      "BLEU-4: 0.081717\n",
      "BLEU-1: 0.507896\n",
      "BLEU-2: 0.255075\n",
      "BLEU-3: 0.178433\n",
      "BLEU-4: 0.082608\n",
      "BLEU-1: 0.507355\n",
      "BLEU-2: 0.254688\n",
      "BLEU-3: 0.178164\n",
      "BLEU-4: 0.082462\n",
      "BLEU-1: 0.507266\n",
      "BLEU-2: 0.254416\n",
      "BLEU-3: 0.177943\n",
      "BLEU-4: 0.082336\n",
      "BLEU-1: 0.507028\n",
      "BLEU-2: 0.254106\n",
      "BLEU-3: 0.177708\n",
      "BLEU-4: 0.082203\n",
      "BLEU-1: 0.507238\n",
      "BLEU-2: 0.254723\n",
      "BLEU-3: 0.178254\n",
      "BLEU-4: 0.082372\n",
      "BLEU-1: 0.507745\n",
      "BLEU-2: 0.255250\n",
      "BLEU-3: 0.178565\n",
      "BLEU-4: 0.082451\n",
      "BLEU-1: 0.507358\n",
      "BLEU-2: 0.254904\n",
      "BLEU-3: 0.178314\n",
      "BLEU-4: 0.082313\n",
      "BLEU-1: 0.507569\n",
      "BLEU-2: 0.255073\n",
      "BLEU-3: 0.178298\n",
      "BLEU-4: 0.082274\n",
      "BLEU-1: 0.507777\n",
      "BLEU-2: 0.255200\n",
      "BLEU-3: 0.178246\n",
      "BLEU-4: 0.082213\n",
      "BLEU-1: 0.507836\n",
      "BLEU-2: 0.255128\n",
      "BLEU-3: 0.178111\n",
      "BLEU-4: 0.082121\n",
      "BLEU-1: 0.507747\n",
      "BLEU-2: 0.255180\n",
      "BLEU-3: 0.178223\n",
      "BLEU-4: 0.082123\n",
      "BLEU-1: 0.507368\n",
      "BLEU-2: 0.254920\n",
      "BLEU-3: 0.178048\n",
      "BLEU-4: 0.082031\n",
      "BLEU-1: 0.507507\n",
      "BLEU-2: 0.254811\n",
      "BLEU-3: 0.177945\n",
      "BLEU-4: 0.081971\n",
      "BLEU-1: 0.507423\n",
      "BLEU-2: 0.254627\n",
      "BLEU-3: 0.177801\n",
      "BLEU-4: 0.081892\n",
      "BLEU-1: 0.507189\n",
      "BLEU-2: 0.254323\n",
      "BLEU-3: 0.177570\n",
      "BLEU-4: 0.081763\n",
      "BLEU-1: 0.506663\n",
      "BLEU-2: 0.253946\n",
      "BLEU-3: 0.177309\n",
      "BLEU-4: 0.081622\n",
      "BLEU-1: 0.506945\n",
      "BLEU-2: 0.254313\n",
      "BLEU-3: 0.177387\n",
      "BLEU-4: 0.081624\n",
      "BLEU-1: 0.507005\n",
      "BLEU-2: 0.254403\n",
      "BLEU-3: 0.177515\n",
      "BLEU-4: 0.081633\n",
      "BLEU-1: 0.507141\n",
      "BLEU-2: 0.254254\n",
      "BLEU-3: 0.177378\n",
      "BLEU-4: 0.081553\n",
      "BLEU-1: 0.506764\n",
      "BLEU-2: 0.253917\n",
      "BLEU-3: 0.177134\n",
      "BLEU-4: 0.081419\n",
      "BLEU-1: 0.506388\n",
      "BLEU-2: 0.253581\n",
      "BLEU-3: 0.176891\n",
      "BLEU-4: 0.081287\n",
      "BLEU-1: 0.506303\n",
      "BLEU-2: 0.253319\n",
      "BLEU-3: 0.176679\n",
      "BLEU-4: 0.081166\n",
      "BLEU-1: 0.506219\n",
      "BLEU-2: 0.253215\n",
      "BLEU-3: 0.176534\n",
      "BLEU-4: 0.081071\n",
      "BLEU-1: 0.506280\n",
      "BLEU-2: 0.253464\n",
      "BLEU-3: 0.176728\n",
      "BLEU-4: 0.081106\n",
      "BLEU-1: 0.505982\n",
      "BLEU-2: 0.253209\n",
      "BLEU-3: 0.176548\n",
      "BLEU-4: 0.081010\n",
      "BLEU-1: 0.505899\n",
      "BLEU-2: 0.253107\n",
      "BLEU-3: 0.176404\n",
      "BLEU-4: 0.080915\n",
      "BLEU-1: 0.505820\n",
      "BLEU-2: 0.253085\n",
      "BLEU-3: 0.176331\n",
      "BLEU-4: 0.080864\n",
      "BLEU-1: 0.506171\n",
      "BLEU-2: 0.253641\n",
      "BLEU-3: 0.176880\n",
      "BLEU-4: 0.081050\n",
      "BLEU-1: 0.506376\n",
      "BLEU-2: 0.253962\n",
      "BLEU-3: 0.177122\n",
      "BLEU-4: 0.081111\n",
      "BLEU-1: 0.506512\n",
      "BLEU-2: 0.254169\n",
      "BLEU-3: 0.177343\n",
      "BLEU-4: 0.081176\n",
      "BLEU-1: 0.506289\n",
      "BLEU-2: 0.253955\n",
      "BLEU-3: 0.177189\n",
      "BLEU-4: 0.081094\n",
      "BLEU-1: 0.506423\n",
      "BLEU-2: 0.253965\n",
      "BLEU-3: 0.177120\n",
      "BLEU-4: 0.081040\n",
      "BLEU-1: 0.506340\n",
      "BLEU-2: 0.253707\n",
      "BLEU-3: 0.176912\n",
      "BLEU-4: 0.080922\n",
      "BLEU-1: 0.506115\n",
      "BLEU-2: 0.253724\n",
      "BLEU-3: 0.177007\n",
      "BLEU-4: 0.080920\n",
      "BLEU-1: 0.506742\n",
      "BLEU-2: 0.254573\n",
      "BLEU-3: 0.177826\n",
      "BLEU-4: 0.081473\n",
      "BLEU-1: 0.506659\n",
      "BLEU-2: 0.254316\n",
      "BLEU-3: 0.177618\n",
      "BLEU-4: 0.081355\n",
      "BLEU-1: 0.506859\n",
      "BLEU-2: 0.254438\n",
      "BLEU-3: 0.177756\n",
      "BLEU-4: 0.081369\n",
      "BLEU-1: 0.506776\n",
      "BLEU-2: 0.254335\n",
      "BLEU-3: 0.177613\n",
      "BLEU-4: 0.081276\n",
      "BLEU-1: 0.506552\n",
      "BLEU-2: 0.254044\n",
      "BLEU-3: 0.177391\n",
      "BLEU-4: 0.081153\n",
      "BLEU-1: 0.506188\n",
      "BLEU-2: 0.253718\n",
      "BLEU-3: 0.177155\n",
      "BLEU-4: 0.081024\n",
      "BLEU-1: 0.506107\n",
      "BLEU-2: 0.253464\n",
      "BLEU-3: 0.176950\n",
      "BLEU-4: 0.080908\n",
      "BLEU-1: 0.505958\n",
      "BLEU-2: 0.253252\n",
      "BLEU-3: 0.176789\n",
      "BLEU-4: 0.080820\n",
      "BLEU-1: 0.506157\n",
      "BLEU-2: 0.253681\n",
      "BLEU-3: 0.177424\n",
      "BLEU-4: 0.081573\n",
      "BLEU-1: 0.506356\n",
      "BLEU-2: 0.253803\n",
      "BLEU-3: 0.177561\n",
      "BLEU-4: 0.081587\n",
      "BLEU-1: 0.506414\n",
      "BLEU-2: 0.253737\n",
      "BLEU-3: 0.177435\n",
      "BLEU-4: 0.081500\n",
      "BLEU-1: 0.506333\n",
      "BLEU-2: 0.253637\n",
      "BLEU-3: 0.177294\n",
      "BLEU-4: 0.081409\n",
      "BLEU-1: 0.505835\n",
      "BLEU-2: 0.253281\n",
      "BLEU-3: 0.177047\n",
      "BLEU-4: 0.081276\n",
      "BLEU-1: 0.506384\n",
      "BLEU-2: 0.253738\n",
      "BLEU-3: 0.177368\n",
      "BLEU-4: 0.081380\n",
      "BLEU-1: 0.506164\n",
      "BLEU-2: 0.253755\n",
      "BLEU-3: 0.177460\n",
      "BLEU-4: 0.081377\n",
      "BLEU-1: 0.506222\n",
      "BLEU-2: 0.253841\n",
      "BLEU-3: 0.177399\n",
      "BLEU-4: 0.081316\n",
      "BLEU-1: 0.506630\n",
      "BLEU-2: 0.254261\n",
      "BLEU-3: 0.177703\n",
      "BLEU-4: 0.081413\n",
      "BLEU-1: 0.506687\n",
      "BLEU-2: 0.254345\n",
      "BLEU-3: 0.177823\n",
      "BLEU-4: 0.081421\n",
      "BLEU-1: 0.506606\n",
      "BLEU-2: 0.254095\n",
      "BLEU-3: 0.177621\n",
      "BLEU-4: 0.081306\n",
      "BLEU-1: 0.506667\n",
      "BLEU-2: 0.254257\n",
      "BLEU-3: 0.177808\n",
      "BLEU-4: 0.081355\n",
      "BLEU-1: 0.506658\n",
      "BLEU-2: 0.254233\n",
      "BLEU-3: 0.177727\n",
      "BLEU-4: 0.081298\n",
      "BLEU-1: 0.506851\n",
      "BLEU-2: 0.254501\n",
      "BLEU-3: 0.177923\n",
      "BLEU-4: 0.081335\n",
      "BLEU-1: 0.507115\n",
      "BLEU-2: 0.254694\n",
      "BLEU-3: 0.178113\n",
      "BLEU-4: 0.081381\n",
      "BLEU-1: 0.506898\n",
      "BLEU-2: 0.254411\n",
      "BLEU-3: 0.177898\n",
      "BLEU-4: 0.081262\n",
      "BLEU-1: 0.506681\n",
      "BLEU-2: 0.254129\n",
      "BLEU-3: 0.177683\n",
      "BLEU-4: 0.081143\n",
      "BLEU-1: 0.507219\n",
      "BLEU-2: 0.254873\n",
      "BLEU-3: 0.178301\n",
      "BLEU-4: 0.081360\n",
      "BLEU-1: 0.507483\n",
      "BLEU-2: 0.255251\n",
      "BLEU-3: 0.178585\n",
      "BLEU-4: 0.081449\n",
      "BLEU-1: 0.507949\n",
      "BLEU-2: 0.255512\n",
      "BLEU-3: 0.178812\n",
      "BLEU-4: 0.081513\n",
      "BLEU-1: 0.508139\n",
      "BLEU-2: 0.255332\n",
      "BLEU-3: 0.178640\n",
      "BLEU-4: 0.081410\n",
      "BLEU-1: 0.507921\n",
      "BLEU-2: 0.255050\n",
      "BLEU-3: 0.178425\n",
      "BLEU-4: 0.081292\n",
      "BLEU-1: 0.507844\n",
      "BLEU-2: 0.254880\n",
      "BLEU-3: 0.178293\n",
      "BLEU-4: 0.081219\n",
      "BLEU-1: 0.508106\n",
      "BLEU-2: 0.255108\n",
      "BLEU-3: 0.178514\n",
      "BLEU-4: 0.081285\n",
      "BLEU-1: 0.508024\n",
      "BLEU-2: 0.254862\n",
      "BLEU-3: 0.178314\n",
      "BLEU-4: 0.081172\n",
      "BLEU-1: 0.507808\n",
      "BLEU-2: 0.254583\n",
      "BLEU-3: 0.178101\n",
      "BLEU-4: 0.081055\n",
      "BLEU-1: 0.507862\n",
      "BLEU-2: 0.254665\n",
      "BLEU-3: 0.178217\n",
      "BLEU-4: 0.081062\n",
      "BLEU-1: 0.508256\n",
      "BLEU-2: 0.255218\n",
      "BLEU-3: 0.178574\n",
      "BLEU-4: 0.081179\n",
      "BLEU-1: 0.508175\n",
      "BLEU-2: 0.254973\n",
      "BLEU-3: 0.178376\n",
      "BLEU-4: 0.081067\n",
      "BLEU-1: 0.508227\n",
      "BLEU-2: 0.255054\n",
      "BLEU-3: 0.178315\n",
      "BLEU-4: 0.081007\n",
      "BLEU-1: 0.508280\n",
      "BLEU-2: 0.255135\n",
      "BLEU-3: 0.178254\n",
      "BLEU-4: 0.080948\n",
      "BLEU-1: 0.508402\n",
      "BLEU-2: 0.254998\n",
      "BLEU-3: 0.178127\n",
      "BLEU-4: 0.080875\n",
      "BLEU-1: 0.508321\n",
      "BLEU-2: 0.254900\n",
      "BLEU-3: 0.177992\n",
      "BLEU-4: 0.080787\n",
      "BLEU-1: 0.507974\n",
      "BLEU-2: 0.254591\n",
      "BLEU-3: 0.177768\n",
      "BLEU-4: 0.080667\n",
      "BLEU-1: 0.507894\n",
      "BLEU-2: 0.254783\n",
      "BLEU-3: 0.177930\n",
      "BLEU-4: 0.080692\n",
      "BLEU-1: 0.508212\n",
      "BLEU-2: 0.254930\n",
      "BLEU-3: 0.177898\n",
      "BLEU-4: 0.080644\n",
      "BLEU-1: 0.508333\n",
      "BLEU-2: 0.254939\n",
      "BLEU-3: 0.177833\n",
      "BLEU-4: 0.080594\n",
      "BLEU-1: 0.508253\n",
      "BLEU-2: 0.254842\n",
      "BLEU-3: 0.177699\n",
      "BLEU-4: 0.080508\n",
      "BLEU-1: 0.508305\n",
      "BLEU-2: 0.254922\n",
      "BLEU-3: 0.177814\n",
      "BLEU-4: 0.080515\n",
      "BLEU-1: 0.508225\n",
      "BLEU-2: 0.254825\n",
      "BLEU-3: 0.177680\n",
      "BLEU-4: 0.080429\n",
      "BLEU-1: 0.508145\n",
      "BLEU-2: 0.254585\n",
      "BLEU-3: 0.177487\n",
      "BLEU-4: 0.080321\n",
      "BLEU-1: 0.507672\n",
      "BLEU-2: 0.254248\n",
      "BLEU-3: 0.177253\n",
      "BLEU-4: 0.080197\n",
      "BLEU-1: 0.507855\n",
      "BLEU-2: 0.254361\n",
      "BLEU-3: 0.177382\n",
      "BLEU-4: 0.080210\n",
      "BLEU-1: 0.507978\n",
      "BLEU-2: 0.254550\n",
      "BLEU-3: 0.177583\n",
      "BLEU-4: 0.080269\n",
      "BLEU-1: 0.508030\n",
      "BLEU-2: 0.254772\n",
      "BLEU-3: 0.177757\n",
      "BLEU-4: 0.080299\n",
      "BLEU-1: 0.507821\n",
      "BLEU-2: 0.254502\n",
      "BLEU-3: 0.177551\n",
      "BLEU-4: 0.080186\n",
      "BLEU-1: 0.508133\n",
      "BLEU-2: 0.254789\n",
      "BLEU-3: 0.177579\n",
      "BLEU-4: 0.080162\n",
      "BLEU-1: 0.508184\n",
      "BLEU-2: 0.254726\n",
      "BLEU-3: 0.177461\n",
      "BLEU-4: 0.080082\n",
      "BLEU-1: 0.508105\n",
      "BLEU-2: 0.254489\n",
      "BLEU-3: 0.177271\n",
      "BLEU-4: 0.079976\n",
      "BLEU-1: 0.507897\n",
      "BLEU-2: 0.254221\n",
      "BLEU-3: 0.177067\n",
      "BLEU-4: 0.079865\n",
      "BLEU-1: 0.507690\n",
      "BLEU-2: 0.253954\n",
      "BLEU-3: 0.176865\n",
      "BLEU-4: 0.079754\n",
      "BLEU-1: 0.507613\n",
      "BLEU-2: 0.253719\n",
      "BLEU-3: 0.176676\n",
      "BLEU-4: 0.079648\n",
      "BLEU-1: 0.507793\n",
      "BLEU-2: 0.253691\n",
      "BLEU-3: 0.176573\n",
      "BLEU-4: 0.079575\n",
      "BLEU-1: 0.508102\n",
      "BLEU-2: 0.253835\n",
      "BLEU-3: 0.176714\n",
      "BLEU-4: 0.079594\n",
      "BLEU-1: 0.508607\n",
      "BLEU-2: 0.254539\n",
      "BLEU-3: 0.177130\n",
      "BLEU-4: 0.079732\n",
      "BLEU-1: 0.508401\n",
      "BLEU-2: 0.254273\n",
      "BLEU-3: 0.176929\n",
      "BLEU-4: 0.079622\n",
      "BLEU-1: 0.508195\n",
      "BLEU-2: 0.254008\n",
      "BLEU-3: 0.176728\n",
      "BLEU-4: 0.079513\n",
      "BLEU-1: 0.508117\n",
      "BLEU-2: 0.254056\n",
      "BLEU-3: 0.176828\n",
      "BLEU-4: 0.079516\n",
      "BLEU-1: 0.508423\n",
      "BLEU-2: 0.254198\n",
      "BLEU-3: 0.176967\n",
      "BLEU-4: 0.079534\n",
      "BLEU-1: 0.508284\n",
      "BLEU-2: 0.254004\n",
      "BLEU-3: 0.176821\n",
      "BLEU-4: 0.079456\n",
      "BLEU-1: 0.508334\n",
      "BLEU-2: 0.254083\n",
      "BLEU-3: 0.176934\n",
      "BLEU-4: 0.079464\n",
      "BLEU-1: 0.508580\n",
      "BLEU-2: 0.254438\n",
      "BLEU-3: 0.177202\n",
      "BLEU-4: 0.079547\n",
      "BLEU-1: 0.508756\n",
      "BLEU-2: 0.254409\n",
      "BLEU-3: 0.177100\n",
      "BLEU-4: 0.079475\n",
      "BLEU-1: 0.508936\n",
      "BLEU-2: 0.254728\n",
      "BLEU-3: 0.177345\n",
      "BLEU-4: 0.079547\n",
      "BLEU-1: 0.508985\n",
      "BLEU-2: 0.254529\n",
      "BLEU-3: 0.177173\n",
      "BLEU-4: 0.079448\n",
      "BLEU-1: 0.508907\n",
      "BLEU-2: 0.254299\n",
      "BLEU-3: 0.176987\n",
      "BLEU-4: 0.079345\n",
      "BLEU-1: 0.508829\n",
      "BLEU-2: 0.254207\n",
      "BLEU-3: 0.176860\n",
      "BLEU-4: 0.079264\n",
      "BLEU-1: 0.508752\n",
      "BLEU-2: 0.253977\n",
      "BLEU-3: 0.176676\n",
      "BLEU-4: 0.079162\n",
      "BLEU-1: 0.508869\n",
      "BLEU-2: 0.254297\n",
      "BLEU-3: 0.177096\n",
      "BLEU-4: 0.079565\n",
      "BLEU-1: 0.508671\n",
      "BLEU-2: 0.254108\n",
      "BLEU-3: 0.176960\n",
      "BLEU-4: 0.079494\n",
      "BLEU-1: 0.508719\n",
      "BLEU-2: 0.254048\n",
      "BLEU-3: 0.176847\n",
      "BLEU-4: 0.079418\n",
      "BLEU-1: 0.508710\n",
      "BLEU-2: 0.254199\n",
      "BLEU-3: 0.177028\n",
      "BLEU-4: 0.079469\n",
      "BLEU-1: 0.508509\n",
      "BLEU-2: 0.254076\n",
      "BLEU-3: 0.176889\n",
      "BLEU-4: 0.079384\n",
      "BLEU-1: 0.508182\n",
      "BLEU-2: 0.253787\n",
      "BLEU-3: 0.176680\n",
      "BLEU-4: 0.079272\n",
      "BLEU-1: 0.508107\n",
      "BLEU-2: 0.253833\n",
      "BLEU-3: 0.176778\n",
      "BLEU-4: 0.079275\n",
      "BLEU-1: 0.508160\n",
      "BLEU-2: 0.253708\n",
      "BLEU-3: 0.176670\n",
      "BLEU-4: 0.079215\n",
      "BLEU-1: 0.508458\n",
      "BLEU-2: 0.253848\n",
      "BLEU-3: 0.176806\n",
      "BLEU-4: 0.079233\n",
      "BLEU-1: 0.508574\n",
      "BLEU-2: 0.254028\n",
      "BLEU-3: 0.176834\n",
      "BLEU-4: 0.079227\n",
      "BLEU-1: 0.508250\n",
      "BLEU-2: 0.253741\n",
      "BLEU-3: 0.176626\n",
      "BLEU-4: 0.079116\n",
      "BLEU-1: 0.508298\n",
      "BLEU-2: 0.253953\n",
      "BLEU-3: 0.176628\n",
      "BLEU-4: 0.079084\n",
      "BLEU-1: 0.508347\n",
      "BLEU-2: 0.254030\n",
      "BLEU-3: 0.176573\n",
      "BLEU-4: 0.079031\n",
      "BLEU-1: 0.508272\n",
      "BLEU-2: 0.253805\n",
      "BLEU-3: 0.176392\n",
      "BLEU-4: 0.078930\n",
      "BLEU-1: 0.508633\n",
      "BLEU-2: 0.254316\n",
      "BLEU-3: 0.176887\n",
      "BLEU-4: 0.079357\n",
      "BLEU-1: 0.509051\n",
      "BLEU-2: 0.254753\n",
      "BLEU-3: 0.177474\n",
      "BLEU-4: 0.080056\n",
      "BLEU-1: 0.509165\n",
      "BLEU-2: 0.254662\n",
      "BLEU-3: 0.177389\n",
      "BLEU-4: 0.080007\n",
      "BLEU-1: 0.509580\n",
      "BLEU-2: 0.255365\n",
      "BLEU-3: 0.177922\n",
      "BLEU-4: 0.080174\n",
      "BLEU-1: 0.509503\n",
      "BLEU-2: 0.255274\n",
      "BLEU-3: 0.177797\n",
      "BLEU-4: 0.080094\n",
      "BLEU-1: 0.509305\n",
      "BLEU-2: 0.255020\n",
      "BLEU-3: 0.177604\n",
      "BLEU-4: 0.079989\n",
      "BLEU-1: 0.509229\n",
      "BLEU-2: 0.255063\n",
      "BLEU-3: 0.177698\n",
      "BLEU-4: 0.079991\n",
      "BLEU-1: 0.509519\n",
      "BLEU-2: 0.255464\n",
      "BLEU-3: 0.177941\n",
      "BLEU-4: 0.080049\n",
      "BLEU-1: 0.509443\n",
      "BLEU-2: 0.255374\n",
      "BLEU-3: 0.177817\n",
      "BLEU-4: 0.079970\n",
      "BLEU-1: 0.509854\n",
      "BLEU-2: 0.256068\n",
      "BLEU-3: 0.178182\n",
      "BLEU-4: 0.080074\n",
      "BLEU-1: 0.509778\n",
      "BLEU-2: 0.255977\n",
      "BLEU-3: 0.178058\n",
      "BLEU-4: 0.079995\n",
      "BLEU-1: 0.509823\n",
      "BLEU-2: 0.256181\n",
      "BLEU-3: 0.178379\n",
      "BLEU-4: 0.080335\n",
      "BLEU-1: 0.510177\n",
      "BLEU-2: 0.256678\n",
      "BLEU-3: 0.178861\n",
      "BLEU-4: 0.080750\n",
      "BLEU-1: 0.510288\n",
      "BLEU-2: 0.256587\n",
      "BLEU-3: 0.178776\n",
      "BLEU-4: 0.080701\n",
      "BLEU-1: 0.510453\n",
      "BLEU-2: 0.256688\n",
      "BLEU-3: 0.178892\n",
      "BLEU-4: 0.080712\n",
      "BLEU-1: 0.510497\n",
      "BLEU-2: 0.256758\n",
      "BLEU-3: 0.178995\n",
      "BLEU-4: 0.080718\n",
      "BLEU-1: 0.510425\n",
      "BLEU-2: 0.256605\n",
      "BLEU-3: 0.178876\n",
      "BLEU-4: 0.080654\n",
      "BLEU-1: 0.510354\n",
      "BLEU-2: 0.256714\n",
      "BLEU-3: 0.179026\n",
      "BLEU-4: 0.080690\n",
      "BLEU-1: 0.510040\n",
      "BLEU-2: 0.256466\n",
      "BLEU-3: 0.178852\n",
      "BLEU-4: 0.080599\n",
      "BLEU-1: 0.509910\n",
      "BLEU-2: 0.256315\n",
      "BLEU-3: 0.178743\n",
      "BLEU-4: 0.080542\n",
      "BLEU-1: 0.510194\n",
      "BLEU-2: 0.256577\n",
      "BLEU-3: 0.178925\n",
      "BLEU-4: 0.080578\n",
      "BLEU-1: 0.509999\n",
      "BLEU-2: 0.256326\n",
      "BLEU-3: 0.178735\n",
      "BLEU-4: 0.080474\n",
      "BLEU-1: 0.510043\n",
      "BLEU-2: 0.256526\n",
      "BLEU-3: 0.178892\n",
      "BLEU-4: 0.080500\n",
      "BLEU-1: 0.509729\n",
      "BLEU-2: 0.256376\n",
      "BLEU-3: 0.178744\n",
      "BLEU-4: 0.080412\n",
      "BLEU-1: 0.509720\n",
      "BLEU-2: 0.256516\n",
      "BLEU-3: 0.178756\n",
      "BLEU-4: 0.080401\n",
      "BLEU-1: 0.509407\n",
      "BLEU-2: 0.256237\n",
      "BLEU-3: 0.178554\n",
      "BLEU-4: 0.080293\n",
      "BLEU-1: 0.509214\n",
      "BLEU-2: 0.255988\n",
      "BLEU-3: 0.178366\n",
      "BLEU-4: 0.080191\n",
      "BLEU-1: 0.508903\n",
      "BLEU-2: 0.255711\n",
      "BLEU-3: 0.178166\n",
      "BLEU-4: 0.080084\n",
      "BLEU-1: 0.508830\n",
      "BLEU-2: 0.255493\n",
      "BLEU-3: 0.177991\n",
      "BLEU-4: 0.079986\n",
      "BLEU-1: 0.508757\n",
      "BLEU-2: 0.255277\n",
      "BLEU-3: 0.177817\n",
      "BLEU-4: 0.079889\n",
      "BLEU-1: 0.508803\n",
      "BLEU-2: 0.255090\n",
      "BLEU-3: 0.177655\n",
      "BLEU-4: 0.079797\n",
      "BLEU-1: 0.509089\n",
      "BLEU-2: 0.255545\n",
      "BLEU-3: 0.177948\n",
      "BLEU-4: 0.079888\n",
      "BLEU-1: 0.509610\n",
      "BLEU-2: 0.256186\n",
      "BLEU-3: 0.178632\n",
      "BLEU-4: 0.080614\n",
      "BLEU-1: 0.509301\n",
      "BLEU-2: 0.255910\n",
      "BLEU-3: 0.178433\n",
      "BLEU-4: 0.080507\n",
      "BLEU-1: 0.509228\n",
      "BLEU-2: 0.255950\n",
      "BLEU-3: 0.178521\n",
      "BLEU-4: 0.080509\n",
      "BLEU-1: 0.509099\n",
      "BLEU-2: 0.255770\n",
      "BLEU-3: 0.178385\n",
      "BLEU-4: 0.080436\n",
      "BLEU-1: 0.509144\n",
      "BLEU-2: 0.255840\n",
      "BLEU-3: 0.178486\n",
      "BLEU-4: 0.080442\n",
      "BLEU-1: 0.509427\n",
      "BLEU-2: 0.256162\n",
      "BLEU-3: 0.178877\n",
      "BLEU-4: 0.080811\n",
      "BLEU-1: 0.509238\n",
      "BLEU-2: 0.255918\n",
      "BLEU-3: 0.178691\n",
      "BLEU-4: 0.080709\n",
      "BLEU-1: 0.508932\n",
      "BLEU-2: 0.255645\n",
      "BLEU-3: 0.178494\n",
      "BLEU-4: 0.080603\n",
      "BLEU-1: 0.508627\n",
      "BLEU-2: 0.255373\n",
      "BLEU-3: 0.178297\n",
      "BLEU-4: 0.080498\n",
      "BLEU-1: 0.508555\n",
      "BLEU-2: 0.255160\n",
      "BLEU-3: 0.178125\n",
      "BLEU-4: 0.080402\n",
      "BLEU-1: 0.508368\n",
      "BLEU-2: 0.254918\n",
      "BLEU-3: 0.177942\n",
      "BLEU-4: 0.080301\n",
      "BLEU-1: 0.508534\n",
      "BLEU-2: 0.255083\n",
      "BLEU-3: 0.178112\n",
      "BLEU-4: 0.080346\n",
      "BLEU-1: 0.508467\n",
      "BLEU-2: 0.255190\n",
      "BLEU-3: 0.178257\n",
      "BLEU-4: 0.080382\n",
      "BLEU-1: 0.508396\n",
      "BLEU-2: 0.255104\n",
      "BLEU-3: 0.178139\n",
      "BLEU-4: 0.080307\n",
      "BLEU-1: 0.508271\n",
      "BLEU-2: 0.254928\n",
      "BLEU-3: 0.178005\n",
      "BLEU-4: 0.080235\n",
      "BLEU-1: 0.508316\n",
      "BLEU-2: 0.254998\n",
      "BLEU-3: 0.177953\n",
      "BLEU-4: 0.080184\n",
      "BLEU-1: 0.508480\n",
      "BLEU-2: 0.255036\n",
      "BLEU-3: 0.177917\n",
      "BLEU-4: 0.080151\n",
      "BLEU-1: 0.508756\n",
      "BLEU-2: 0.255164\n",
      "BLEU-3: 0.177889\n",
      "BLEU-4: 0.080110\n",
      "BLEU-1: 0.508915\n",
      "BLEU-2: 0.255136\n",
      "BLEU-3: 0.177796\n",
      "BLEU-4: 0.080044\n",
      "BLEU-1: 0.509137\n",
      "BLEU-2: 0.255330\n",
      "BLEU-3: 0.177832\n",
      "BLEU-4: 0.080042\n",
      "BLEU-1: 0.509241\n",
      "BLEU-2: 0.255463\n",
      "BLEU-3: 0.177829\n",
      "BLEU-4: 0.080019\n",
      "BLEU-1: 0.508941\n",
      "BLEU-2: 0.255320\n",
      "BLEU-3: 0.177688\n",
      "BLEU-4: 0.079936\n",
      "BLEU-1: 0.508870\n",
      "BLEU-2: 0.255111\n",
      "BLEU-3: 0.177519\n",
      "BLEU-4: 0.079842\n",
      "BLEU-1: 0.508457\n",
      "BLEU-2: 0.254816\n",
      "BLEU-3: 0.177316\n",
      "BLEU-4: 0.079735\n",
      "BLEU-1: 0.508388\n",
      "BLEU-2: 0.254856\n",
      "BLEU-3: 0.177404\n",
      "BLEU-4: 0.079737\n",
      "BLEU-1: 0.508432\n",
      "BLEU-2: 0.255050\n",
      "BLEU-3: 0.177707\n",
      "BLEU-4: 0.079820\n",
      "BLEU-1: 0.508363\n",
      "BLEU-2: 0.254966\n",
      "BLEU-3: 0.177591\n",
      "BLEU-4: 0.079746\n",
      "BLEU-1: 0.508180\n",
      "BLEU-2: 0.254854\n",
      "BLEU-3: 0.177464\n",
      "BLEU-4: 0.079668\n",
      "BLEU-1: 0.507884\n",
      "BLEU-2: 0.254590\n",
      "BLEU-3: 0.177274\n",
      "BLEU-4: 0.079567\n",
      "BLEU-1: 0.507589\n",
      "BLEU-2: 0.254327\n",
      "BLEU-3: 0.177084\n",
      "BLEU-4: 0.079465\n",
      "BLEU-1: 0.507409\n",
      "BLEU-2: 0.254093\n",
      "BLEU-3: 0.176906\n",
      "BLEU-4: 0.079369\n",
      "BLEU-1: 0.507341\n",
      "BLEU-2: 0.254135\n",
      "BLEU-3: 0.176994\n",
      "BLEU-4: 0.079371\n",
      "BLEU-1: 0.507390\n",
      "BLEU-2: 0.254268\n",
      "BLEU-3: 0.177149\n",
      "BLEU-4: 0.079411\n",
      "BLEU-1: 0.507495\n",
      "BLEU-2: 0.254399\n",
      "BLEU-3: 0.177146\n",
      "BLEU-4: 0.079389\n",
      "BLEU-1: 0.507427\n",
      "BLEU-2: 0.254194\n",
      "BLEU-3: 0.176981\n",
      "BLEU-4: 0.079297\n",
      "BLEU-1: 0.507248\n",
      "BLEU-2: 0.254084\n",
      "BLEU-3: 0.176856\n",
      "BLEU-4: 0.079221\n",
      "BLEU-1: 0.506957\n",
      "BLEU-2: 0.253824\n",
      "BLEU-3: 0.176669\n",
      "BLEU-4: 0.079121\n",
      "BLEU-1: 0.507003\n",
      "BLEU-2: 0.254138\n",
      "BLEU-3: 0.177019\n",
      "BLEU-4: 0.079457\n",
      "BLEU-1: 0.507272\n",
      "BLEU-2: 0.254385\n",
      "BLEU-3: 0.177192\n",
      "BLEU-4: 0.079491\n",
      "BLEU-1: 0.507318\n",
      "BLEU-2: 0.254210\n",
      "BLEU-3: 0.177040\n",
      "BLEU-4: 0.079405\n",
      "BLEU-1: 0.507254\n",
      "BLEU-2: 0.254192\n",
      "BLEU-3: 0.176983\n",
      "BLEU-4: 0.079365\n",
      "BLEU-1: 0.507188\n",
      "BLEU-2: 0.253990\n",
      "BLEU-3: 0.176820\n",
      "BLEU-4: 0.079275\n",
      "BLEU-1: 0.507122\n",
      "BLEU-2: 0.253909\n",
      "BLEU-3: 0.176708\n",
      "BLEU-4: 0.079203\n",
      "BLEU-1: 0.507612\n",
      "BLEU-2: 0.254332\n",
      "BLEU-3: 0.177102\n",
      "BLEU-4: 0.079553\n",
      "BLEU-1: 0.507767\n",
      "BLEU-2: 0.254428\n",
      "BLEU-3: 0.177211\n",
      "BLEU-4: 0.079564\n",
      "BLEU-1: 0.507701\n",
      "BLEU-2: 0.254468\n",
      "BLEU-3: 0.177149\n",
      "BLEU-4: 0.079512\n",
      "BLEU-1: 0.507524\n",
      "BLEU-2: 0.254239\n",
      "BLEU-3: 0.176976\n",
      "BLEU-4: 0.079417\n",
      "BLEU-1: 0.507237\n",
      "BLEU-2: 0.253983\n",
      "BLEU-3: 0.176791\n",
      "BLEU-4: 0.079319\n",
      "BLEU-1: 0.507282\n",
      "BLEU-2: 0.254051\n",
      "BLEU-3: 0.176889\n",
      "BLEU-4: 0.079326\n",
      "BLEU-1: 0.507329\n",
      "BLEU-2: 0.254181\n",
      "BLEU-3: 0.177040\n",
      "BLEU-4: 0.079365\n",
      "BLEU-1: 0.507264\n",
      "BLEU-2: 0.254101\n",
      "BLEU-3: 0.176929\n",
      "BLEU-4: 0.079294\n",
      "BLEU-1: 0.507199\n",
      "BLEU-2: 0.254022\n",
      "BLEU-3: 0.176819\n",
      "BLEU-4: 0.079223\n",
      "BLEU-1: 0.507300\n",
      "BLEU-2: 0.254150\n",
      "BLEU-3: 0.176962\n",
      "BLEU-4: 0.079256\n",
      "BLEU-1: 0.507402\n",
      "BLEU-2: 0.254277\n",
      "BLEU-3: 0.177105\n",
      "BLEU-4: 0.079289\n",
      "BLEU-1: 0.507394\n",
      "BLEU-2: 0.254258\n",
      "BLEU-3: 0.177040\n",
      "BLEU-4: 0.079245\n",
      "BLEU-1: 0.507497\n",
      "BLEU-2: 0.254296\n",
      "BLEU-3: 0.177014\n",
      "BLEU-4: 0.079221\n",
      "BLEU-1: 0.507432\n",
      "BLEU-2: 0.254098\n",
      "BLEU-3: 0.176854\n",
      "BLEU-4: 0.079132\n",
      "BLEU-1: 0.507476\n",
      "BLEU-2: 0.254165\n",
      "BLEU-3: 0.176951\n",
      "BLEU-4: 0.079139\n",
      "BLEU-1: 0.507411\n",
      "BLEU-2: 0.254086\n",
      "BLEU-3: 0.176841\n",
      "BLEU-4: 0.079069\n",
      "BLEU-1: 0.507510\n",
      "BLEU-2: 0.254182\n",
      "BLEU-3: 0.176956\n",
      "BLEU-4: 0.079086\n",
      "BLEU-1: 0.507336\n",
      "BLEU-2: 0.253958\n",
      "BLEU-3: 0.176786\n",
      "BLEU-4: 0.078993\n",
      "BLEU-1: 0.507438\n",
      "BLEU-2: 0.253996\n",
      "BLEU-3: 0.176760\n",
      "BLEU-4: 0.078970\n",
      "BLEU-1: 0.507048\n",
      "BLEU-2: 0.253718\n",
      "BLEU-3: 0.176568\n",
      "BLEU-4: 0.078869\n",
      "BLEU-1: 0.507093\n",
      "BLEU-2: 0.253785\n",
      "BLEU-3: 0.176664\n",
      "BLEU-4: 0.078876\n",
      "BLEU-1: 0.507032\n",
      "BLEU-2: 0.253886\n",
      "BLEU-3: 0.176802\n",
      "BLEU-4: 0.078910\n",
      "BLEU-1: 0.507076\n",
      "BLEU-2: 0.253953\n",
      "BLEU-3: 0.176897\n",
      "BLEU-4: 0.078917\n",
      "BLEU-1: 0.507120\n",
      "BLEU-2: 0.253785\n",
      "BLEU-3: 0.176751\n",
      "BLEU-4: 0.078834\n",
      "BLEU-1: 0.507056\n",
      "BLEU-2: 0.253707\n",
      "BLEU-3: 0.176643\n",
      "BLEU-4: 0.078765\n",
      "BLEU-1: 0.506992\n",
      "BLEU-2: 0.253512\n",
      "BLEU-3: 0.176486\n",
      "BLEU-4: 0.078678\n",
      "BLEU-1: 0.506929\n",
      "BLEU-2: 0.253435\n",
      "BLEU-3: 0.176378\n",
      "BLEU-4: 0.078610\n",
      "BLEU-1: 0.507082\n",
      "BLEU-2: 0.253559\n",
      "BLEU-3: 0.176511\n",
      "BLEU-4: 0.078637\n",
      "BLEU-1: 0.506911\n",
      "BLEU-2: 0.253338\n",
      "BLEU-3: 0.176344\n",
      "BLEU-4: 0.078546\n",
      "BLEU-1: 0.507065\n",
      "BLEU-2: 0.253609\n",
      "BLEU-3: 0.176694\n",
      "BLEU-4: 0.078887\n",
      "BLEU-1: 0.507059\n",
      "BLEU-2: 0.253504\n",
      "BLEU-3: 0.176609\n",
      "BLEU-4: 0.078841\n",
      "BLEU-1: 0.506996\n",
      "BLEU-2: 0.253427\n",
      "BLEU-3: 0.176502\n",
      "BLEU-4: 0.078773\n",
      "BLEU-1: 0.506719\n",
      "BLEU-2: 0.253181\n",
      "BLEU-3: 0.176324\n",
      "BLEU-4: 0.078679\n",
      "BLEU-1: 0.506657\n",
      "BLEU-2: 0.253221\n",
      "BLEU-3: 0.176266\n",
      "BLEU-4: 0.078629\n",
      "BLEU-1: 0.506916\n",
      "BLEU-2: 0.253634\n",
      "BLEU-3: 0.176815\n",
      "BLEU-4: 0.079042\n",
      "BLEU-1: 0.506747\n",
      "BLEU-2: 0.253415\n",
      "BLEU-3: 0.176649\n",
      "BLEU-4: 0.078952\n",
      "BLEU-1: 0.507003\n",
      "BLEU-2: 0.253998\n",
      "BLEU-3: 0.177380\n",
      "BLEU-4: 0.079862\n",
      "BLEU-1: 0.506835\n",
      "BLEU-2: 0.253779\n",
      "BLEU-3: 0.177213\n",
      "BLEU-4: 0.079771\n",
      "BLEU-1: 0.506772\n",
      "BLEU-2: 0.253703\n",
      "BLEU-3: 0.177107\n",
      "BLEU-4: 0.079703\n",
      "BLEU-1: 0.507133\n",
      "BLEU-2: 0.254079\n",
      "BLEU-3: 0.177329\n",
      "BLEU-4: 0.079758\n",
      "BLEU-1: 0.506965\n",
      "BLEU-2: 0.254091\n",
      "BLEU-3: 0.177400\n",
      "BLEU-4: 0.079756\n",
      "BLEU-1: 0.507113\n",
      "BLEU-2: 0.254182\n",
      "BLEU-3: 0.177503\n",
      "BLEU-4: 0.079766\n",
      "BLEU-1: 0.507318\n",
      "BLEU-2: 0.254361\n",
      "BLEU-3: 0.177676\n",
      "BLEU-4: 0.079817\n",
      "BLEU-1: 0.507153\n",
      "BLEU-2: 0.254202\n",
      "BLEU-3: 0.177562\n",
      "BLEU-4: 0.079758\n",
      "BLEU-1: 0.507356\n",
      "BLEU-2: 0.254351\n",
      "BLEU-3: 0.177709\n",
      "BLEU-4: 0.079793\n",
      "BLEU-1: 0.507084\n",
      "BLEU-2: 0.254108\n",
      "BLEU-3: 0.177533\n",
      "BLEU-4: 0.079699\n",
      "BLEU-1: 0.507025\n",
      "BLEU-2: 0.253976\n",
      "BLEU-3: 0.177431\n",
      "BLEU-4: 0.079644\n",
      "BLEU-1: 0.506963\n",
      "BLEU-2: 0.253901\n",
      "BLEU-3: 0.177325\n",
      "BLEU-4: 0.079576\n",
      "BLEU-1: 0.507113\n",
      "BLEU-2: 0.254279\n",
      "BLEU-3: 0.177712\n",
      "BLEU-4: 0.079704\n",
      "BLEU-1: 0.506842\n",
      "BLEU-2: 0.254037\n",
      "BLEU-3: 0.177537\n",
      "BLEU-4: 0.079611\n",
      "BLEU-1: 0.506572\n",
      "BLEU-2: 0.253795\n",
      "BLEU-3: 0.177362\n",
      "BLEU-4: 0.079517\n",
      "BLEU-1: 0.506876\n",
      "BLEU-2: 0.253712\n",
      "BLEU-3: 0.177260\n",
      "BLEU-4: 0.079454\n",
      "BLEU-1: 0.506711\n",
      "BLEU-2: 0.253498\n",
      "BLEU-3: 0.177097\n",
      "BLEU-4: 0.079366\n",
      "BLEU-1: 0.507017\n",
      "BLEU-2: 0.253928\n",
      "BLEU-3: 0.177511\n",
      "BLEU-4: 0.079724\n",
      "BLEU-1: 0.506748\n",
      "BLEU-2: 0.253801\n",
      "BLEU-3: 0.177385\n",
      "BLEU-4: 0.079649\n",
      "BLEU-1: 0.507054\n",
      "BLEU-2: 0.254229\n",
      "BLEU-3: 0.177661\n",
      "BLEU-4: 0.079738\n",
      "BLEU-1: 0.506993\n",
      "BLEU-2: 0.254041\n",
      "BLEU-3: 0.177509\n",
      "BLEU-4: 0.079654\n",
      "BLEU-1: 0.506934\n",
      "BLEU-2: 0.254137\n",
      "BLEU-3: 0.177503\n",
      "BLEU-4: 0.079635\n",
      "BLEU-1: 0.507239\n",
      "BLEU-2: 0.254451\n",
      "BLEU-3: 0.177595\n",
      "BLEU-4: 0.079655\n",
      "BLEU-1: 0.507281\n",
      "BLEU-2: 0.254289\n",
      "BLEU-3: 0.177454\n",
      "BLEU-4: 0.079575\n",
      "BLEU-1: 0.507426\n",
      "BLEU-2: 0.254378\n",
      "BLEU-3: 0.177418\n",
      "BLEU-4: 0.079534\n",
      "BLEU-1: 0.507420\n",
      "BLEU-2: 0.254277\n",
      "BLEU-3: 0.177336\n",
      "BLEU-4: 0.079490\n",
      "BLEU-1: 0.507619\n",
      "BLEU-2: 0.254563\n",
      "BLEU-3: 0.177553\n",
      "BLEU-4: 0.079557\n",
      "BLEU-1: 0.507558\n",
      "BLEU-2: 0.254488\n",
      "BLEU-3: 0.177449\n",
      "BLEU-4: 0.079490\n",
      "BLEU-1: 0.507394\n",
      "BLEU-2: 0.254276\n",
      "BLEU-3: 0.177287\n",
      "BLEU-4: 0.079403\n",
      "BLEU-1: 0.507333\n",
      "BLEU-2: 0.254313\n",
      "BLEU-3: 0.177366\n",
      "BLEU-4: 0.079405\n",
      "BLEU-1: 0.507374\n",
      "BLEU-2: 0.254376\n",
      "BLEU-3: 0.177320\n",
      "BLEU-4: 0.079360\n",
      "BLEU-1: 0.507573\n",
      "BLEU-2: 0.254438\n",
      "BLEU-3: 0.177307\n",
      "BLEU-4: 0.079342\n",
      "BLEU-1: 0.507617\n",
      "BLEU-2: 0.254558\n",
      "BLEU-3: 0.177446\n",
      "BLEU-4: 0.079377\n",
      "BLEU-1: 0.507815\n",
      "BLEU-2: 0.254842\n",
      "BLEU-3: 0.177796\n",
      "BLEU-4: 0.079709\n",
      "BLEU-1: 0.508165\n",
      "BLEU-2: 0.255261\n",
      "BLEU-3: 0.178195\n",
      "BLEU-4: 0.079842\n",
      "BLEU-1: 0.507797\n",
      "BLEU-2: 0.254998\n",
      "BLEU-3: 0.178013\n",
      "BLEU-4: 0.079746\n",
      "BLEU-1: 0.508097\n",
      "BLEU-2: 0.255306\n",
      "BLEU-3: 0.178371\n",
      "BLEU-4: 0.080080\n",
      "BLEU-1: 0.508137\n",
      "BLEU-2: 0.255256\n",
      "BLEU-3: 0.178278\n",
      "BLEU-4: 0.080018\n",
      "BLEU-1: 0.508075\n",
      "BLEU-2: 0.255071\n",
      "BLEU-3: 0.178129\n",
      "BLEU-4: 0.079935\n",
      "BLEU-1: 0.508218\n",
      "BLEU-2: 0.255186\n",
      "BLEU-3: 0.178252\n",
      "BLEU-4: 0.079959\n",
      "BLEU-1: 0.508360\n",
      "BLEU-2: 0.255383\n",
      "BLEU-3: 0.178529\n",
      "BLEU-4: 0.080247\n",
      "BLEU-1: 0.508200\n",
      "BLEU-2: 0.255230\n",
      "BLEU-3: 0.178419\n",
      "BLEU-4: 0.080190\n",
      "BLEU-1: 0.508038\n",
      "BLEU-2: 0.255020\n",
      "BLEU-3: 0.178259\n",
      "BLEU-4: 0.080103\n",
      "BLEU-1: 0.507977\n",
      "BLEU-2: 0.255055\n",
      "BLEU-3: 0.178335\n",
      "BLEU-4: 0.080104\n",
      "BLEU-1: 0.507714\n",
      "BLEU-2: 0.254821\n",
      "BLEU-3: 0.178165\n",
      "BLEU-4: 0.080013\n",
      "BLEU-1: 0.508056\n",
      "BLEU-2: 0.254958\n",
      "BLEU-3: 0.178284\n",
      "BLEU-4: 0.080030\n",
      "BLEU-1: 0.507895\n",
      "BLEU-2: 0.254749\n",
      "BLEU-3: 0.178125\n",
      "BLEU-4: 0.079944\n",
      "BLEU-1: 0.508035\n",
      "BLEU-2: 0.254945\n",
      "BLEU-3: 0.178268\n",
      "BLEU-4: 0.079970\n",
      "BLEU-1: 0.507874\n",
      "BLEU-2: 0.254846\n",
      "BLEU-3: 0.178155\n",
      "BLEU-4: 0.079901\n",
      "BLEU-1: 0.508014\n",
      "BLEU-2: 0.255041\n",
      "BLEU-3: 0.178429\n",
      "BLEU-4: 0.080187\n",
      "BLEU-1: 0.507754\n",
      "BLEU-2: 0.254917\n",
      "BLEU-3: 0.178306\n",
      "BLEU-4: 0.080113\n",
      "BLEU-1: 0.507694\n",
      "BLEU-2: 0.254953\n",
      "BLEU-3: 0.178250\n",
      "BLEU-4: 0.080066\n",
      "BLEU-1: 0.507734\n",
      "BLEU-2: 0.254796\n",
      "BLEU-3: 0.178114\n",
      "BLEU-4: 0.079988\n",
      "BLEU-1: 0.507574\n",
      "BLEU-2: 0.254589\n",
      "BLEU-3: 0.177956\n",
      "BLEU-4: 0.079902\n",
      "BLEU-1: 0.507614\n",
      "BLEU-2: 0.254650\n",
      "BLEU-3: 0.177911\n",
      "BLEU-4: 0.079858\n",
      "BLEU-1: 0.507654\n",
      "BLEU-2: 0.254602\n",
      "BLEU-3: 0.177821\n",
      "BLEU-4: 0.079798\n",
      "BLEU-1: 0.507396\n",
      "BLEU-2: 0.254371\n",
      "BLEU-3: 0.177654\n",
      "BLEU-4: 0.079709\n",
      "BLEU-1: 0.507238\n",
      "BLEU-2: 0.254166\n",
      "BLEU-3: 0.177498\n",
      "BLEU-4: 0.079624\n",
      "BLEU-1: 0.507179\n",
      "BLEU-2: 0.254203\n",
      "BLEU-3: 0.177574\n",
      "BLEU-4: 0.079626\n",
      "BLEU-1: 0.507021\n",
      "BLEU-2: 0.253998\n",
      "BLEU-3: 0.177418\n",
      "BLEU-4: 0.079541\n",
      "BLEU-1: 0.506864\n",
      "BLEU-2: 0.253794\n",
      "BLEU-3: 0.177263\n",
      "BLEU-4: 0.079457\n",
      "BLEU-1: 0.506905\n",
      "BLEU-2: 0.253748\n",
      "BLEU-3: 0.177174\n",
      "BLEU-4: 0.079397\n",
      "BLEU-1: 0.506945\n",
      "BLEU-2: 0.253702\n",
      "BLEU-3: 0.177085\n",
      "BLEU-4: 0.079338\n",
      "BLEU-1: 0.506789\n",
      "BLEU-2: 0.253499\n",
      "BLEU-3: 0.176931\n",
      "BLEU-4: 0.079254\n",
      "BLEU-1: 0.506829\n",
      "BLEU-2: 0.253345\n",
      "BLEU-3: 0.176798\n",
      "BLEU-4: 0.079178\n",
      "BLEU-1: 0.506477\n",
      "BLEU-2: 0.253094\n",
      "BLEU-3: 0.176624\n",
      "BLEU-4: 0.079087\n",
      "BLEU-1: 0.506224\n",
      "BLEU-2: 0.252868\n",
      "BLEU-3: 0.176460\n",
      "BLEU-4: 0.079000\n",
      "BLEU-1: 0.506167\n",
      "BLEU-2: 0.252799\n",
      "BLEU-3: 0.176362\n",
      "BLEU-4: 0.078938\n",
      "BLEU-1: 0.506306\n",
      "BLEU-2: 0.252992\n",
      "BLEU-3: 0.176504\n",
      "BLEU-4: 0.078965\n",
      "BLEU-1: 0.506249\n",
      "BLEU-2: 0.252923\n",
      "BLEU-3: 0.176407\n",
      "BLEU-4: 0.078902\n",
      "BLEU-1: 0.506387\n",
      "BLEU-2: 0.253116\n",
      "BLEU-3: 0.176677\n",
      "BLEU-4: 0.079182\n",
      "BLEU-1: 0.506428\n",
      "BLEU-2: 0.252964\n",
      "BLEU-3: 0.176545\n",
      "BLEU-4: 0.079107\n",
      "BLEU-1: 0.506471\n",
      "BLEU-2: 0.253080\n",
      "BLEU-3: 0.176679\n",
      "BLEU-4: 0.079141\n",
      "BLEU-1: 0.506466\n",
      "BLEU-2: 0.252985\n",
      "BLEU-3: 0.176602\n",
      "BLEU-4: 0.079100\n",
      "BLEU-1: 0.506409\n",
      "BLEU-2: 0.252809\n",
      "BLEU-3: 0.176460\n",
      "BLEU-4: 0.079021\n",
      "BLEU-1: 0.506645\n",
      "BLEU-2: 0.253159\n",
      "BLEU-3: 0.176551\n",
      "BLEU-4: 0.079034\n",
      "BLEU-1: 0.506394\n",
      "BLEU-2: 0.252935\n",
      "BLEU-3: 0.176389\n",
      "BLEU-4: 0.078948\n",
      "BLEU-1: 0.506628\n",
      "BLEU-2: 0.253257\n",
      "BLEU-3: 0.176584\n",
      "BLEU-4: 0.078995\n",
      "BLEU-1: 0.506574\n",
      "BLEU-2: 0.253242\n",
      "BLEU-3: 0.176535\n",
      "BLEU-4: 0.078961\n",
      "BLEU-1: 0.506324\n",
      "BLEU-2: 0.253230\n",
      "BLEU-3: 0.176590\n",
      "BLEU-4: 0.078956\n",
      "BLEU-1: 0.506557\n",
      "BLEU-2: 0.253655\n",
      "BLEU-3: 0.177083\n",
      "BLEU-4: 0.079519\n",
      "BLEU-1: 0.506501\n",
      "BLEU-2: 0.253691\n",
      "BLEU-3: 0.177157\n",
      "BLEU-4: 0.079521\n",
      "BLEU-1: 0.506640\n",
      "BLEU-2: 0.253934\n",
      "BLEU-3: 0.177343\n",
      "BLEU-4: 0.079575\n",
      "BLEU-1: 0.506679\n",
      "BLEU-2: 0.253993\n",
      "BLEU-3: 0.177427\n",
      "BLEU-4: 0.079581\n",
      "BLEU-1: 0.506719\n",
      "BLEU-2: 0.253948\n",
      "BLEU-3: 0.177340\n",
      "BLEU-4: 0.079523\n",
      "BLEU-1: 0.506759\n",
      "BLEU-2: 0.254112\n",
      "BLEU-3: 0.177468\n",
      "BLEU-4: 0.079545\n",
      "BLEU-1: 0.507181\n",
      "BLEU-2: 0.254580\n",
      "BLEU-3: 0.177975\n",
      "BLEU-4: 0.079909\n",
      "BLEU-1: 0.507029\n",
      "BLEU-2: 0.254382\n",
      "BLEU-3: 0.177824\n",
      "BLEU-4: 0.079827\n",
      "BLEU-1: 0.507163\n",
      "BLEU-2: 0.254464\n",
      "BLEU-3: 0.177917\n",
      "BLEU-4: 0.079836\n",
      "BLEU-1: 0.506916\n",
      "BLEU-2: 0.254243\n",
      "BLEU-3: 0.177756\n",
      "BLEU-4: 0.079751\n",
      "BLEU-1: 0.506862\n",
      "BLEU-2: 0.254124\n",
      "BLEU-3: 0.177664\n",
      "BLEU-4: 0.079700\n",
      "BLEU-1: 0.507048\n",
      "BLEU-2: 0.254285\n",
      "BLEU-3: 0.177695\n",
      "BLEU-4: 0.079699\n",
      "BLEU-1: 0.507277\n",
      "BLEU-2: 0.254599\n",
      "BLEU-3: 0.178009\n",
      "BLEU-4: 0.079990\n",
      "BLEU-1: 0.507030\n",
      "BLEU-2: 0.254482\n",
      "BLEU-3: 0.177893\n",
      "BLEU-4: 0.079921\n",
      "BLEU-1: 0.506974\n",
      "BLEU-2: 0.254619\n",
      "BLEU-3: 0.178008\n",
      "BLEU-4: 0.079939\n",
      "BLEU-1: 0.506918\n",
      "BLEU-2: 0.254653\n",
      "BLEU-3: 0.178080\n",
      "BLEU-4: 0.079940\n",
      "BLEU-1: 0.506768\n",
      "BLEU-2: 0.254457\n",
      "BLEU-3: 0.177931\n",
      "BLEU-4: 0.079859\n",
      "BLEU-1: 0.506618\n",
      "BLEU-2: 0.254262\n",
      "BLEU-3: 0.177782\n",
      "BLEU-4: 0.079778\n",
      "BLEU-1: 0.506373\n",
      "BLEU-2: 0.254043\n",
      "BLEU-3: 0.177623\n",
      "BLEU-4: 0.079693\n",
      "BLEU-1: 0.506413\n",
      "BLEU-2: 0.253998\n",
      "BLEU-3: 0.177538\n",
      "BLEU-4: 0.079636\n",
      "BLEU-1: 0.506452\n",
      "BLEU-2: 0.254057\n",
      "BLEU-3: 0.177620\n",
      "BLEU-4: 0.079642\n",
      "BLEU-1: 0.506209\n",
      "BLEU-2: 0.253839\n",
      "BLEU-3: 0.177462\n",
      "BLEU-4: 0.079557\n",
      "BLEU-1: 0.506157\n",
      "BLEU-2: 0.253721\n",
      "BLEU-3: 0.177370\n",
      "BLEU-4: 0.079508\n",
      "BLEU-1: 0.506102\n",
      "BLEU-2: 0.253859\n",
      "BLEU-3: 0.177485\n",
      "BLEU-4: 0.079526\n",
      "BLEU-1: 0.506048\n",
      "BLEU-2: 0.253791\n",
      "BLEU-3: 0.177391\n",
      "BLEU-4: 0.079466\n",
      "BLEU-1: 0.505900\n",
      "BLEU-2: 0.253598\n",
      "BLEU-3: 0.177244\n",
      "BLEU-4: 0.079386\n",
      "BLEU-1: 0.505753\n",
      "BLEU-2: 0.253405\n",
      "BLEU-3: 0.177097\n",
      "BLEU-4: 0.079306\n",
      "BLEU-1: 0.505886\n",
      "BLEU-2: 0.253385\n",
      "BLEU-3: 0.177023\n",
      "BLEU-4: 0.079254\n",
      "BLEU-1: 0.505832\n",
      "BLEU-2: 0.253217\n",
      "BLEU-3: 0.176887\n",
      "BLEU-4: 0.079178\n",
      "BLEU-1: 0.505592\n",
      "BLEU-2: 0.253002\n",
      "BLEU-3: 0.176731\n",
      "BLEU-4: 0.079095\n",
      "BLEU-1: 0.505632\n",
      "BLEU-2: 0.253061\n",
      "BLEU-3: 0.176813\n",
      "BLEU-4: 0.079101\n",
      "BLEU-1: 0.505392\n",
      "BLEU-2: 0.252847\n",
      "BLEU-3: 0.176658\n",
      "BLEU-4: 0.079019\n",
      "BLEU-1: 0.505154\n",
      "BLEU-2: 0.252734\n",
      "BLEU-3: 0.176546\n",
      "BLEU-4: 0.078952\n",
      "BLEU-1: 0.505194\n",
      "BLEU-2: 0.252895\n",
      "BLEU-3: 0.176548\n",
      "BLEU-4: 0.078928\n",
      "BLEU-1: 0.505234\n",
      "BLEU-2: 0.253054\n",
      "BLEU-3: 0.176672\n",
      "BLEU-4: 0.078950\n",
      "BLEU-1: 0.505366\n",
      "BLEU-2: 0.253136\n",
      "BLEU-3: 0.176763\n",
      "BLEU-4: 0.078960\n",
      "BLEU-1: 0.505131\n",
      "BLEU-2: 0.252975\n",
      "BLEU-3: 0.176655\n",
      "BLEU-4: 0.078904\n",
      "BLEU-1: 0.504801\n",
      "BLEU-2: 0.252739\n",
      "BLEU-3: 0.176491\n",
      "BLEU-4: 0.078819\n",
      "BLEU-1: 0.504842\n",
      "BLEU-2: 0.252999\n",
      "BLEU-3: 0.176657\n",
      "BLEU-4: 0.078856\n",
      "BLEU-1: 0.504974\n",
      "BLEU-2: 0.252879\n",
      "BLEU-3: 0.176542\n",
      "BLEU-4: 0.078789\n",
      "BLEU-1: 0.504830\n",
      "BLEU-2: 0.252690\n",
      "BLEU-3: 0.176398\n",
      "BLEU-4: 0.078711\n",
      "BLEU-1: 0.504503\n",
      "BLEU-2: 0.252456\n",
      "BLEU-3: 0.176236\n",
      "BLEU-4: 0.078627\n",
      "BLEU-1: 0.504268\n",
      "BLEU-2: 0.252346\n",
      "BLEU-3: 0.176125\n",
      "BLEU-4: 0.078561\n",
      "BLEU-1: 0.504402\n",
      "BLEU-2: 0.252478\n",
      "BLEU-3: 0.176261\n",
      "BLEU-4: 0.078598\n",
      "BLEU-1: 0.504444\n",
      "BLEU-2: 0.252588\n",
      "BLEU-3: 0.176266\n",
      "BLEU-4: 0.078585\n",
      "BLEU-1: 0.504302\n",
      "BLEU-2: 0.252401\n",
      "BLEU-3: 0.176124\n",
      "BLEU-4: 0.078508\n",
      "BLEU-1: 0.504251\n",
      "BLEU-2: 0.252237\n",
      "BLEU-3: 0.175991\n",
      "BLEU-4: 0.078434\n",
      "BLEU-1: 0.504383\n",
      "BLEU-2: 0.252118\n",
      "BLEU-3: 0.175878\n",
      "BLEU-4: 0.078368\n",
      "BLEU-1: 0.504150\n",
      "BLEU-2: 0.251909\n",
      "BLEU-3: 0.175726\n",
      "BLEU-4: 0.078288\n",
      "BLEU-1: 0.504099\n",
      "BLEU-2: 0.251746\n",
      "BLEU-3: 0.175595\n",
      "BLEU-4: 0.078215\n",
      "BLEU-1: 0.504414\n",
      "BLEU-2: 0.252322\n",
      "BLEU-3: 0.176277\n",
      "BLEU-4: 0.078648\n",
      "BLEU-1: 0.504455\n",
      "BLEU-2: 0.252281\n",
      "BLEU-3: 0.176196\n",
      "BLEU-4: 0.078594\n",
      "BLEU-1: 0.504313\n",
      "BLEU-2: 0.252095\n",
      "BLEU-3: 0.176055\n",
      "BLEU-4: 0.078517\n",
      "BLEU-1: 0.504081\n",
      "BLEU-2: 0.251887\n",
      "BLEU-3: 0.175904\n",
      "BLEU-4: 0.078437\n",
      "BLEU-1: 0.504033\n",
      "BLEU-2: 0.251974\n",
      "BLEU-3: 0.176020\n",
      "BLEU-4: 0.078466\n",
      "BLEU-1: 0.504345\n",
      "BLEU-2: 0.252199\n",
      "BLEU-3: 0.176171\n",
      "BLEU-4: 0.078498\n",
      "BLEU-1: 0.504613\n",
      "BLEU-2: 0.252475\n",
      "BLEU-3: 0.176491\n",
      "BLEU-4: 0.078605\n",
      "BLEU-1: 0.504472\n",
      "BLEU-2: 0.252290\n",
      "BLEU-3: 0.176350\n",
      "BLEU-4: 0.078529\n",
      "BLEU-1: 0.504241\n",
      "BLEU-2: 0.252083\n",
      "BLEU-3: 0.176200\n",
      "BLEU-4: 0.078449\n",
      "BLEU-1: 0.504011\n",
      "BLEU-2: 0.251877\n",
      "BLEU-3: 0.176050\n",
      "BLEU-4: 0.078370\n",
      "BLEU-1: 0.504141\n",
      "BLEU-2: 0.252056\n",
      "BLEU-3: 0.176300\n",
      "BLEU-4: 0.078630\n",
      "BLEU-1: 0.504318\n",
      "BLEU-2: 0.252112\n",
      "BLEU-3: 0.176289\n",
      "BLEU-4: 0.078615\n",
      "BLEU-1: 0.504449\n",
      "BLEU-2: 0.252217\n",
      "BLEU-3: 0.176281\n",
      "BLEU-4: 0.078593\n",
      "BLEU-1: 0.504625\n",
      "BLEU-2: 0.252469\n",
      "BLEU-3: 0.176589\n",
      "BLEU-4: 0.078886\n",
      "BLEU-1: 0.504754\n",
      "BLEU-2: 0.252451\n",
      "BLEU-3: 0.176519\n",
      "BLEU-4: 0.078836\n",
      "BLEU-1: 0.504616\n",
      "BLEU-2: 0.252317\n",
      "BLEU-3: 0.176423\n",
      "BLEU-4: 0.078786\n",
      "BLEU-1: 0.504476\n",
      "BLEU-2: 0.252134\n",
      "BLEU-3: 0.176283\n",
      "BLEU-4: 0.078710\n",
      "BLEU-1: 0.504652\n",
      "BLEU-2: 0.252092\n",
      "BLEU-3: 0.176231\n",
      "BLEU-4: 0.078679\n",
      "BLEU-1: 0.504602\n",
      "BLEU-2: 0.251931\n",
      "BLEU-3: 0.176101\n",
      "BLEU-4: 0.078607\n",
      "BLEU-1: 0.504463\n",
      "BLEU-2: 0.251749\n",
      "BLEU-3: 0.175962\n",
      "BLEU-4: 0.078532\n",
      "BLEU-1: 0.504145\n",
      "BLEU-2: 0.251523\n",
      "BLEU-3: 0.175805\n",
      "BLEU-4: 0.078450\n",
      "BLEU-1: 0.504276\n",
      "BLEU-2: 0.251750\n",
      "BLEU-3: 0.175978\n",
      "BLEU-4: 0.078500\n",
      "BLEU-1: 0.504226\n",
      "BLEU-2: 0.251591\n",
      "BLEU-3: 0.175849\n",
      "BLEU-4: 0.078429\n",
      "BLEU-1: 0.504177\n",
      "BLEU-2: 0.251432\n",
      "BLEU-3: 0.175720\n",
      "BLEU-4: 0.078358\n",
      "BLEU-1: 0.504217\n",
      "BLEU-2: 0.251490\n",
      "BLEU-3: 0.175800\n",
      "BLEU-4: 0.078364\n",
      "BLEU-1: 0.504167\n",
      "BLEU-2: 0.251526\n",
      "BLEU-3: 0.175753\n",
      "BLEU-4: 0.078323\n",
      "BLEU-1: 0.504030\n",
      "BLEU-2: 0.251345\n",
      "BLEU-3: 0.175615\n",
      "BLEU-4: 0.078249\n",
      "BLEU-1: 0.503892\n",
      "BLEU-2: 0.251165\n",
      "BLEU-3: 0.175478\n",
      "BLEU-4: 0.078174\n",
      "BLEU-1: 0.503844\n",
      "BLEU-2: 0.251008\n",
      "BLEU-3: 0.175350\n",
      "BLEU-4: 0.078104\n",
      "BLEU-1: 0.503972\n",
      "BLEU-2: 0.251185\n",
      "BLEU-3: 0.175480\n",
      "BLEU-4: 0.078129\n",
      "BLEU-1: 0.503923\n",
      "BLEU-2: 0.251124\n",
      "BLEU-3: 0.175393\n",
      "BLEU-4: 0.078073\n",
      "BLEU-1: 0.503698\n",
      "BLEU-2: 0.251019\n",
      "BLEU-3: 0.175288\n",
      "BLEU-4: 0.078011\n",
      "BLEU-1: 0.503826\n",
      "BLEU-2: 0.251196\n",
      "BLEU-3: 0.175417\n",
      "BLEU-4: 0.078036\n",
      "BLEU-1: 0.503866\n",
      "BLEU-2: 0.251157\n",
      "BLEU-3: 0.175339\n",
      "BLEU-4: 0.077984\n",
      "BLEU-1: 0.503905\n",
      "BLEU-2: 0.251119\n",
      "BLEU-3: 0.175262\n",
      "BLEU-4: 0.077933\n",
      "BLEU-1: 0.503857\n",
      "BLEU-2: 0.250962\n",
      "BLEU-3: 0.175136\n",
      "BLEU-4: 0.077863\n",
      "BLEU-1: 0.503721\n",
      "BLEU-2: 0.250784\n",
      "BLEU-3: 0.175000\n",
      "BLEU-4: 0.077790\n",
      "BLEU-1: 0.503587\n",
      "BLEU-2: 0.250655\n",
      "BLEU-3: 0.174907\n",
      "BLEU-4: 0.077742\n",
      "BLEU-1: 0.503452\n",
      "BLEU-2: 0.250478\n",
      "BLEU-3: 0.174772\n",
      "BLEU-4: 0.077669\n",
      "BLEU-1: 0.503317\n",
      "BLEU-2: 0.250397\n",
      "BLEU-3: 0.174678\n",
      "BLEU-4: 0.077611\n",
      "BLEU-1: 0.503270\n",
      "BLEU-2: 0.250242\n",
      "BLEU-3: 0.174552\n",
      "BLEU-4: 0.077542\n",
      "BLEU-1: 0.503311\n",
      "BLEU-2: 0.250253\n",
      "BLEU-3: 0.174518\n",
      "BLEU-4: 0.077516\n",
      "BLEU-1: 0.503263\n",
      "BLEU-2: 0.250289\n",
      "BLEU-3: 0.174589\n",
      "BLEU-4: 0.077520\n",
      "BLEU-1: 0.503042\n",
      "BLEU-2: 0.250092\n",
      "BLEU-3: 0.174446\n",
      "BLEU-4: 0.077444\n",
      "BLEU-1: 0.503082\n",
      "BLEU-2: 0.250150\n",
      "BLEU-3: 0.174525\n",
      "BLEU-4: 0.077451\n",
      "BLEU-1: 0.503122\n",
      "BLEU-2: 0.250399\n",
      "BLEU-3: 0.174800\n",
      "BLEU-4: 0.077530\n",
      "BLEU-1: 0.503075\n",
      "BLEU-2: 0.250435\n",
      "BLEU-3: 0.174755\n",
      "BLEU-4: 0.077491\n",
      "BLEU-1: 0.502942\n",
      "BLEU-2: 0.250260\n",
      "BLEU-3: 0.174621\n",
      "BLEU-4: 0.077419\n",
      "BLEU-1: 0.502723\n",
      "BLEU-2: 0.250063\n",
      "BLEU-3: 0.174479\n",
      "BLEU-4: 0.077344\n",
      "BLEU-1: 0.502590\n",
      "BLEU-2: 0.249889\n",
      "BLEU-3: 0.174346\n",
      "BLEU-4: 0.077272\n",
      "BLEU-1: 0.502458\n",
      "BLEU-2: 0.249715\n",
      "BLEU-3: 0.174213\n",
      "BLEU-4: 0.077201\n",
      "BLEU-1: 0.502584\n",
      "BLEU-2: 0.249605\n",
      "BLEU-3: 0.174108\n",
      "BLEU-4: 0.077140\n",
      "BLEU-1: 0.502539\n",
      "BLEU-2: 0.249642\n",
      "BLEU-3: 0.174178\n",
      "BLEU-4: 0.077143\n",
      "BLEU-1: 0.502407\n",
      "BLEU-2: 0.249658\n",
      "BLEU-3: 0.174239\n",
      "BLEU-4: 0.077144\n",
      "BLEU-1: 0.502189\n",
      "BLEU-2: 0.249463\n",
      "BLEU-3: 0.174099\n",
      "BLEU-4: 0.077070\n",
      "BLEU-1: 0.501973\n",
      "BLEU-2: 0.249363\n",
      "BLEU-3: 0.173997\n",
      "BLEU-4: 0.077010\n",
      "BLEU-1: 0.501928\n",
      "BLEU-2: 0.249306\n",
      "BLEU-3: 0.173914\n",
      "BLEU-4: 0.076957\n",
      "BLEU-1: 0.501797\n",
      "BLEU-2: 0.249134\n",
      "BLEU-3: 0.173783\n",
      "BLEU-4: 0.076887\n",
      "BLEU-1: 0.501581\n",
      "BLEU-2: 0.248941\n",
      "BLEU-3: 0.173643\n",
      "BLEU-4: 0.076813\n",
      "BLEU-1: 0.501708\n",
      "BLEU-2: 0.249021\n",
      "BLEU-3: 0.173731\n",
      "BLEU-4: 0.076824\n",
      "BLEU-1: 0.501792\n",
      "BLEU-2: 0.249148\n",
      "BLEU-3: 0.173753\n",
      "BLEU-4: 0.076821\n",
      "BLEU-1: 0.501747\n",
      "BLEU-2: 0.248998\n",
      "BLEU-3: 0.173631\n",
      "BLEU-4: 0.076754\n",
      "BLEU-1: 0.501959\n",
      "BLEU-2: 0.249333\n",
      "BLEU-3: 0.173960\n",
      "BLEU-4: 0.077046\n",
      "BLEU-1: 0.501957\n",
      "BLEU-2: 0.249345\n",
      "BLEU-3: 0.173933\n",
      "BLEU-4: 0.077025\n",
      "BLEU-1: 0.501998\n",
      "BLEU-2: 0.249496\n",
      "BLEU-3: 0.174164\n",
      "BLEU-4: 0.077271\n",
      "BLEU-1: 0.501783\n",
      "BLEU-2: 0.249304\n",
      "BLEU-3: 0.174025\n",
      "BLEU-4: 0.077198\n",
      "BLEU-1: 0.501484\n",
      "BLEU-2: 0.249091\n",
      "BLEU-3: 0.173877\n",
      "BLEU-4: 0.077121\n",
      "BLEU-1: 0.501695\n",
      "BLEU-2: 0.249378\n",
      "BLEU-3: 0.174163\n",
      "BLEU-4: 0.077205\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating new captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pre-defined list of photo identifiers\n",
    "def load_set(filename):\n",
    "\tdoc = load_doc(filename)\n",
    "\tdataset = list()\n",
    "\t# process line by line\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# skip empty lines\n",
    "\t\tif len(line) < 1:\n",
    "\t\t\tcontinue\n",
    "\t\t# get the image identifier\n",
    "\t\tidentifier = line.split('.')[0]\n",
    "\t\tdataset.append(identifier)\n",
    "\treturn set(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean descriptions into memory\n",
    "def load_clean_descriptions(filename, dataset):\n",
    "\t# load document\n",
    "\tdoc = load_doc(filename)\n",
    "\tdescriptions = dict()\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# split line by white space\n",
    "\t\ttokens = line.split()\n",
    "\t\t# split id from description\n",
    "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
    "\t\t# skip images not in the set\n",
    "\t\tif image_id in dataset:\n",
    "\t\t\t# create list\n",
    "\t\t\tif image_id not in descriptions:\n",
    "\t\t\t\tdescriptions[image_id] = list()\n",
    "\t\t\t# wrap description in tokens\n",
    "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
    "\t\t\t# store\n",
    "\t\t\tdescriptions[image_id].append(desc)\n",
    "\treturn descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert a dictionary of clean descriptions to a list of descriptions\n",
    "def to_lines(descriptions):\n",
    "\tall_desc = list()\n",
    "\tfor key in descriptions.keys():\n",
    "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
    "\treturn all_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a tokenizer given caption descriptions\n",
    "def create_tokenizer(descriptions):\n",
    "\tlines = to_lines(descriptions)\n",
    "\ttokenizer = Tokenizer()\n",
    "\ttokenizer.fit_on_texts(lines)\n",
    "\treturn tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 6000\n",
      "Descriptions: train=6000\n"
     ]
    }
   ],
   "source": [
    "# load training dataset (6K)\n",
    "filename = '../Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "train = load_set(filename)\n",
    "print('Dataset: %d' % len(train))\n",
    "# descriptions\n",
    "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
    "print('Descriptions: train=%d' % len(train_descriptions))\n",
    "# prepare tokenizer\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer.joblib', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.joblib', 'rb'))\n",
    "# pre-define the max sequence length (from training)\n",
    "max_length = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = load_model('./models/model-ep007-loss3.546-val_loss3.933.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from each photo in the directory\n",
    "def extract_features(filename):\n",
    "\t# load the model\n",
    "\tmodel = VGG16()\n",
    "\t# re-structure the model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\t# load the photo\n",
    "\timage = load_img(filename, target_size=(224, 224))\n",
    "\t# convert the image pixels to a numpy array\n",
    "\timage = img_to_array(image)\n",
    "\t# reshape data for the model\n",
    "\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\t# prepare the image for the VGG model\n",
    "\timage = preprocess_input(image)\n",
    "\t# get features\n",
    "\tfeature = model.predict(image, verbose=0)\n",
    "\treturn feature\n",
    "\n",
    "# load and prepare the photograph\n",
    "photo = extract_features('../example.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startseq black dog is running through the water endseq\n"
     ]
    }
   ],
   "source": [
    "# generate description\n",
    "description = generate_desc(model, tokenizer, photo, max_length)\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black dog is running through the water\n"
     ]
    }
   ],
   "source": [
    "# Removing startseq & endseq token from description\n",
    "description = description.replace(\"startseq \", \"\").replace(\" endseq\", \"\")\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un chien noir court dans l'eau\n"
     ]
    }
   ],
   "source": [
    "from translate import Translator\n",
    "\n",
    "# Create a translator object\n",
    "translator = Translator(from_lang=\"en\", to_lang=\"fr\")\n",
    "\n",
    "# Translate a piece of text\n",
    "translation = translator.translate(description)\n",
    "\n",
    "# Print the translation\n",
    "print(translation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on personal photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man in red shirt is standing in front of the ocean\n",
      "un homme en chemise rouge se tient devant l'océan\n"
     ]
    }
   ],
   "source": [
    "# load and prepare the photograph\n",
    "photo = extract_features('../20230124_214558.jpg')\n",
    "\n",
    "# generate description\n",
    "description = generate_desc(model, tokenizer, photo, max_length)\n",
    "\n",
    "# Removing startseq & endseq token from description\n",
    "description = description.replace(\"startseq \", \"\").replace(\" endseq\", \"\")\n",
    "print(description)\n",
    "\n",
    "# Translate a piece of text\n",
    "translation = translator.translate(description)\n",
    "\n",
    "# Print the translation\n",
    "print(translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjetFinalNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
