{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:11:08,017 : INFO : Creating C:\\Users\\AxelArcidiaco/gensim-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:18:59,820 : INFO : word2vec-google-news-300 downloaded\n",
      "2023-04-04 13:18:59,840 : INFO : loading projection weights from C:\\Users\\AxelArcidiaco/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "2023-04-04 13:20:44,571 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from C:\\\\Users\\\\AxelArcidiaco/gensim-data\\\\word2vec-google-news-300\\\\word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-04-04T13:20:44.570345', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_king = wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'cameroon' does not appear in this model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vec_cameroon = wv['cameroon']\n",
    "except KeyError:\n",
    "    print(\"The word 'cameroon' does not appear in this model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car'\t'minivan'\t0.69\n",
      "'car'\t'bicycle'\t0.54\n",
      "'car'\t'airplane'\t0.42\n",
      "'car'\t'cereal'\t0.14\n",
      "'car'\t'communism'\t0.06\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SUV', 0.8532191514968872), ('vehicle', 0.8175783753395081), ('pickup_truck', 0.7763689160346985), ('Jeep', 0.7567334175109863), ('Ford_Explorer', 0.7565719485282898)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=['car', 'minivan'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    }
   ],
   "source": [
    "print(wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Your Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:21:30,781 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2023-04-04 13:21:30,783 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
      "2023-04-04 13:21:30,785 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2023-04-04T13:21:30.785522', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:21:31,814 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:21:31,820 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:21:32,011 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2023-04-04 13:21:32,013 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:21:32,028 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1750 unique words (25.07% of original 6981, drops 5231)', 'datetime': '2023-04-04T13:21:32.028637', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:21:32,116 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 49335 word corpus (84.84% of original 58152, drops 8817)', 'datetime': '2023-04-04T13:21:32.116075', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:21:32,139 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2023-04-04 13:21:32,141 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2023-04-04 13:21:32,142 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 35935.33721568072 word corpus (72.8%% of prior 49335)', 'datetime': '2023-04-04T13:21:32.142689', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:21:32,182 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2023-04-04 13:21:32,185 : INFO : resetting layer weights\n",
      "2023-04-04 13:21:32,193 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:21:32.193739', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:21:32,195 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:21:32.195739', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:21:32,389 : INFO : EPOCH 0: training on 58152 raw words (35883 effective words) took 0.2s, 192458 effective words/s\n",
      "2023-04-04 13:21:32,587 : INFO : EPOCH 1: training on 58152 raw words (35947 effective words) took 0.2s, 186756 effective words/s\n",
      "2023-04-04 13:21:32,767 : INFO : EPOCH 2: training on 58152 raw words (35866 effective words) took 0.2s, 208094 effective words/s\n",
      "2023-04-04 13:21:32,948 : INFO : EPOCH 3: training on 58152 raw words (35871 effective words) took 0.2s, 206720 effective words/s\n",
      "2023-04-04 13:21:33,121 : INFO : EPOCH 4: training on 58152 raw words (35844 effective words) took 0.2s, 215646 effective words/s\n",
      "2023-04-04 13:21:33,122 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (179411 effective words) took 0.9s, 194028 effective words/s', 'datetime': '2023-04-04T13:21:33.122831', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:21:33,124 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1750, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:21:33.124873', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_king = model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:21:40,515 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'C:\\\\Users\\\\AxelArcidiaco\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-8c727zao', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-04T13:21:40.514561', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'saving'}\n",
      "2023-04-04 13:21:40,517 : INFO : not storing attribute cum_table\n",
      "2023-04-04 13:21:40,526 : INFO : saved C:\\Users\\AxelArcidiaco\\AppData\\Local\\Temp\\gensim-model-8c727zao\n",
      "2023-04-04 13:21:40,528 : INFO : loading Word2Vec object from C:\\Users\\AxelArcidiaco\\AppData\\Local\\Temp\\gensim-model-8c727zao\n",
      "2023-04-04 13:21:40,619 : INFO : loading wv recursively from C:\\Users\\AxelArcidiaco\\AppData\\Local\\Temp\\gensim-model-8c727zao.wv.* with mmap=None\n",
      "2023-04-04 13:21:40,621 : INFO : setting ignored attribute cum_table to None\n",
      "2023-04-04 13:21:40,661 : INFO : Word2Vec lifecycle event {'fname': 'C:\\\\Users\\\\AxelArcidiaco\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-8c727zao', 'datetime': '2023-04-04T13:21:40.661295', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    model.save(temporary_filepath)\n",
    "    #\n",
    "    # The model is now safely stored in the filepath.\n",
    "    # You can copy it to other machines, share it with others, etc.\n",
    "    #\n",
    "    # To load a saved model:\n",
    "    #\n",
    "    new_model = gensim.models.Word2Vec.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:21:41,732 : INFO : loading projection weights from /tmp/vectors.txt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/vectors.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mKeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(\u001b[39m'\u001b[39;49m\u001b[39m/tmp/vectors.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, binary\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      2\u001b[0m \u001b[39m# using gzipped/bz2 input works too, no need to unzip\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mKeyedVectors\u001b[39m.\u001b[39mload_word2vec_format(\u001b[39m'\u001b[39m\u001b[39m/tmp/vectors.bin.gz\u001b[39m\u001b[39m'\u001b[39m, binary\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\SpacyEnv\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m     \u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[0;32m   1720\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[0;32m   1721\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[0;32m   1722\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\SpacyEnv\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2048\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2045\u001b[0m             counts[word] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(count)\n\u001b[0;32m   2047\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mloading projection weights from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, fname)\n\u001b[1;32m-> 2048\u001b[0m \u001b[39mwith\u001b[39;00m utils\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fin:\n\u001b[0;32m   2049\u001b[0m     \u001b[39mif\u001b[39;00m no_header:\n\u001b[0;32m   2050\u001b[0m         \u001b[39m# deduce both vocab_size & vector_size from 1st pass over file\u001b[39;00m\n\u001b[0;32m   2051\u001b[0m         \u001b[39mif\u001b[39;00m binary:\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\SpacyEnv\\lib\\site-packages\\smart_open\\smart_open_lib.py:188\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m transport_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     transport_params \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 188\u001b[0m fobj \u001b[39m=\u001b[39m _shortcut_open(\n\u001b[0;32m    189\u001b[0m     uri,\n\u001b[0;32m    190\u001b[0m     mode,\n\u001b[0;32m    191\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    192\u001b[0m     buffering\u001b[39m=\u001b[39;49mbuffering,\n\u001b[0;32m    193\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    194\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    195\u001b[0m     newline\u001b[39m=\u001b[39;49mnewline,\n\u001b[0;32m    196\u001b[0m )\n\u001b[0;32m    197\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mreturn\u001b[39;00m fobj\n",
      "File \u001b[1;32mc:\\Users\\AxelArcidiaco\\anaconda3\\envs\\SpacyEnv\\lib\\site-packages\\smart_open\\smart_open_lib.py:361\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m errors \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m    359\u001b[0m     open_kwargs[\u001b[39m'\u001b[39m\u001b[39merrors\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m errors\n\u001b[1;32m--> 361\u001b[0m \u001b[39mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[39m=\u001b[39mbuffering, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopen_kwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/vectors.txt'"
     ]
    }
   ],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('./tmp/vectors.txt', binary=False)\n",
    "# using gzipped/bz2 input works too, no need to unzip\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./tmp/vectors.bin.gz', binary=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:39:01,487 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:01,491 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:01,719 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2023-04-04 13:39:01,720 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:01,734 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 889 unique words (12.73% of original 6981, drops 6092)', 'datetime': '2023-04-04T13:39:01.734286', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:01,736 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 43776 word corpus (75.28% of original 58152, drops 14376)', 'datetime': '2023-04-04T13:39:01.736278', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:01,753 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2023-04-04 13:39:01,755 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2023-04-04 13:39:01,757 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 29691.39528319831 word corpus (67.8%% of prior 43776)', 'datetime': '2023-04-04T13:39:01.757430', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:01,781 : INFO : estimated required memory for 889 words and 100 dimensions: 1155700 bytes\n",
      "2023-04-04 13:39:01,786 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:01,791 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:01.791730', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:01,793 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 889 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:01.793744', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:02,073 : INFO : EPOCH 0: training on 58152 raw words (29735 effective words) took 0.3s, 109990 effective words/s\n",
      "2023-04-04 13:39:02,305 : INFO : EPOCH 1: training on 58152 raw words (29761 effective words) took 0.2s, 131904 effective words/s\n",
      "2023-04-04 13:39:02,691 : INFO : EPOCH 2: training on 58152 raw words (29660 effective words) took 0.4s, 77742 effective words/s\n",
      "2023-04-04 13:39:02,984 : INFO : EPOCH 3: training on 58152 raw words (29620 effective words) took 0.3s, 106743 effective words/s\n",
      "2023-04-04 13:39:03,246 : INFO : EPOCH 4: training on 58152 raw words (29668 effective words) took 0.3s, 115875 effective words/s\n",
      "2023-04-04 13:39:03,248 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (148444 effective words) took 1.5s, 102237 effective words/s', 'datetime': '2023-04-04T13:39:03.248604', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:03,250 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=889, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:03.250605', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# min_count\n",
    "model = gensim.models.Word2Vec(sentences, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:39:03,347 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:03,353 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:03,654 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2023-04-04 13:39:03,655 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:03,683 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1750 unique words (25.07% of original 6981, drops 5231)', 'datetime': '2023-04-04T13:39:03.683507', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:03,685 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 49335 word corpus (84.84% of original 58152, drops 8817)', 'datetime': '2023-04-04T13:39:03.685496', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:03,717 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2023-04-04 13:39:03,719 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2023-04-04 13:39:03,721 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 35935.33721568072 word corpus (72.8%% of prior 49335)', 'datetime': '2023-04-04T13:39:03.721841', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:03,773 : INFO : estimated required memory for 1750 words and 200 dimensions: 3675000 bytes\n",
      "2023-04-04 13:39:03,775 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:03,784 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:03.784325', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:03,786 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1750 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:03.786321', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:04,146 : INFO : EPOCH 0: training on 58152 raw words (35883 effective words) took 0.3s, 102816 effective words/s\n",
      "2023-04-04 13:39:04,447 : INFO : EPOCH 1: training on 58152 raw words (35909 effective words) took 0.3s, 135007 effective words/s\n",
      "2023-04-04 13:39:04,704 : INFO : EPOCH 2: training on 58152 raw words (36011 effective words) took 0.3s, 142221 effective words/s\n",
      "2023-04-04 13:39:04,963 : INFO : EPOCH 3: training on 58152 raw words (35955 effective words) took 0.3s, 142835 effective words/s\n",
      "2023-04-04 13:39:05,210 : INFO : EPOCH 4: training on 58152 raw words (35937 effective words) took 0.2s, 148345 effective words/s\n",
      "2023-04-04 13:39:05,211 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (179695 effective words) took 1.4s, 126417 effective words/s', 'datetime': '2023-04-04T13:39:05.211185', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:05,212 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1750, vector_size=200, alpha=0.025>', 'datetime': '2023-04-04T13:39:05.212186', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# vector_size\n",
    "model = gensim.models.Word2Vec(sentences, vector_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:39:05,290 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:05,295 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:05,507 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2023-04-04 13:39:05,508 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:05,532 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1750 unique words (25.07% of original 6981, drops 5231)', 'datetime': '2023-04-04T13:39:05.532418', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:05,534 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 49335 word corpus (84.84% of original 58152, drops 8817)', 'datetime': '2023-04-04T13:39:05.534439', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:05,560 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2023-04-04 13:39:05,562 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2023-04-04 13:39:05,564 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 35935.33721568072 word corpus (72.8%% of prior 49335)', 'datetime': '2023-04-04T13:39:05.564691', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:05,680 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2023-04-04 13:39:05,682 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:05,690 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:05.689491', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:05,692 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:05.692506', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:06,098 : INFO : EPOCH 0: training on 58152 raw words (35883 effective words) took 0.3s, 128675 effective words/s\n",
      "2023-04-04 13:39:06,392 : INFO : EPOCH 1: training on 58152 raw words (35909 effective words) took 0.3s, 124555 effective words/s\n",
      "2023-04-04 13:39:06,644 : INFO : EPOCH 2: training on 58152 raw words (36011 effective words) took 0.2s, 147882 effective words/s\n",
      "2023-04-04 13:39:06,884 : INFO : EPOCH 3: training on 58152 raw words (35955 effective words) took 0.2s, 153729 effective words/s\n",
      "2023-04-04 13:39:07,115 : INFO : EPOCH 4: training on 58152 raw words (35937 effective words) took 0.2s, 160554 effective words/s\n",
      "2023-04-04 13:39:07,118 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (179695 effective words) took 1.4s, 126157 effective words/s', 'datetime': '2023-04-04T13:39:07.118546', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:07,118 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1750, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:07.118546', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# workers\n",
    "# default value of workers=3\n",
    "model = gensim.models.Word2Vec(sentences, workers=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:39:08,606 : INFO : Evaluating word analogies for top 300000 words in the model on c:\\Users\\AxelArcidiaco\\anaconda3\\envs\\SpacyEnv\\lib\\site-packages\\gensim\\test\\test_data\\questions-words.txt\n",
      "2023-04-04 13:39:08,621 : INFO : capital-common-countries: 0.0% (0/6)\n",
      "2023-04-04 13:39:08,662 : INFO : capital-world: 0.0% (0/2)\n",
      "2023-04-04 13:39:08,695 : INFO : family: 0.0% (0/6)\n",
      "2023-04-04 13:39:08,733 : INFO : gram3-comparative: 0.0% (0/20)\n",
      "2023-04-04 13:39:08,750 : INFO : gram4-superlative: 0.0% (0/12)\n",
      "2023-04-04 13:39:08,783 : INFO : gram5-present-participle: 0.0% (0/20)\n",
      "2023-04-04 13:39:08,828 : INFO : gram6-nationality-adjective: 0.0% (0/30)\n",
      "2023-04-04 13:39:08,863 : INFO : gram7-past-tense: 0.0% (0/20)\n",
      "2023-04-04 13:39:08,897 : INFO : gram8-plural: 0.0% (0/30)\n",
      "2023-04-04 13:39:08,905 : INFO : Quadruplets with out-of-vocabulary words: 99.3%\n",
      "2023-04-04 13:39:08,908 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2023-04-04 13:39:08,910 : INFO : Total accuracy: 0.0% (0/146)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " [{'section': 'capital-common-countries',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN')]},\n",
       "  {'section': 'capital-world',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE')]},\n",
       "  {'section': 'currency', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'city-in-state', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'family',\n",
       "   'correct': [],\n",
       "   'incorrect': [('HE', 'SHE', 'HIS', 'HER'),\n",
       "    ('HE', 'SHE', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HIS', 'HER')]},\n",
       "  {'section': 'gram1-adjective-to-adverb', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'gram2-opposite', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'gram3-comparative',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
       "    ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
       "    ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
       "    ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
       "    ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
       "    ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
       "    ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n",
       "    ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n",
       "    ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
       "    ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n",
       "    ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n",
       "    ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'LOW', 'LOWER')]},\n",
       "  {'section': 'gram4-superlative',\n",
       "   'correct': [],\n",
       "   'incorrect': [('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
       "    ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
       "    ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
       "    ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
       "    ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
       "    ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'GREAT', 'GREATEST')]},\n",
       "  {'section': 'gram5-present-participle',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
       "    ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
       "    ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
       "    ('GO', 'GOING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
       "    ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
       "    ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
       "    ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
       "    ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
       "    ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
       "    ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'GO', 'GOING'),\n",
       "    ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
       "    ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'RUN', 'RUNNING')]},\n",
       "  {'section': 'gram6-nationality-adjective',\n",
       "   'correct': [],\n",
       "   'incorrect': [('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
       "    ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
       "    ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n",
       "    ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n",
       "    ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
       "    ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n",
       "    ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n",
       "    ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
       "    ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE')]},\n",
       "  {'section': 'gram7-past-tense',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GOING', 'WENT', 'PAYING', 'PAID'),\n",
       "    ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
       "    ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
       "    ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
       "    ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
       "    ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
       "    ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
       "    ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
       "    ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
       "    ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
       "    ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
       "    ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'SAYING', 'SAID')]},\n",
       "  {'section': 'gram8-plural',\n",
       "   'correct': [],\n",
       "   'incorrect': [('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
       "    ('CAR', 'CARS', 'MAN', 'MEN'),\n",
       "    ('CAR', 'CARS', 'ROAD', 'ROADS'),\n",
       "    ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
       "    ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n",
       "    ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n",
       "    ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'ROAD', 'ROADS'),\n",
       "    ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n",
       "    ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('MAN', 'MEN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n",
       "    ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('ROAD', 'ROADS', 'CAR', 'CARS'),\n",
       "    ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n",
       "    ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n",
       "    ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]},\n",
       "  {'section': 'gram9-plural-verbs', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'Total accuracy',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('HE', 'SHE', 'HIS', 'HER'),\n",
       "    ('HE', 'SHE', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HIS', 'HER'),\n",
       "    ('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
       "    ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
       "    ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
       "    ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
       "    ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
       "    ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
       "    ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n",
       "    ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n",
       "    ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
       "    ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n",
       "    ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n",
       "    ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'LOW', 'LOWER'),\n",
       "    ('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
       "    ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
       "    ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
       "    ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
       "    ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
       "    ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'GREAT', 'GREATEST'),\n",
       "    ('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
       "    ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
       "    ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
       "    ('GO', 'GOING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
       "    ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
       "    ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
       "    ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
       "    ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
       "    ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
       "    ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'GO', 'GOING'),\n",
       "    ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
       "    ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'RUN', 'RUNNING'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
       "    ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
       "    ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n",
       "    ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n",
       "    ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
       "    ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n",
       "    ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n",
       "    ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
       "    ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE'),\n",
       "    ('GOING', 'WENT', 'PAYING', 'PAID'),\n",
       "    ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
       "    ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
       "    ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
       "    ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
       "    ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
       "    ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
       "    ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
       "    ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
       "    ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
       "    ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
       "    ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'SAYING', 'SAID'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
       "    ('CAR', 'CARS', 'MAN', 'MEN'),\n",
       "    ('CAR', 'CARS', 'ROAD', 'ROADS'),\n",
       "    ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
       "    ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n",
       "    ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n",
       "    ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'ROAD', 'ROADS'),\n",
       "    ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n",
       "    ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('MAN', 'MEN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n",
       "    ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('ROAD', 'ROADS', 'CAR', 'CARS'),\n",
       "    ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n",
       "    ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n",
       "    ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]}])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.evaluate_word_analogies(datapath('questions-words.txt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online training / Resuming training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:39:10,617 : INFO : loading Word2Vec object from C:\\Users\\AxelArcidiaco\\AppData\\Local\\Temp\\gensim-model-8c727zao\n",
      "2023-04-04 13:39:10,625 : INFO : loading wv recursively from C:\\Users\\AxelArcidiaco\\AppData\\Local\\Temp\\gensim-model-8c727zao.wv.* with mmap=None\n",
      "2023-04-04 13:39:10,626 : INFO : setting ignored attribute cum_table to None\n",
      "2023-04-04 13:39:10,667 : INFO : Word2Vec lifecycle event {'fname': 'C:\\\\Users\\\\AxelArcidiaco\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-8c727zao', 'datetime': '2023-04-04T13:39:10.667449', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'loaded'}\n",
      "2023-04-04 13:39:10,669 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:10,670 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:10,672 : INFO : collected 13 word types from a corpus of 13 raw words and 1 sentences\n",
      "2023-04-04 13:39:10,673 : INFO : Updating model with new vocabulary\n",
      "2023-04-04 13:39:10,692 : INFO : Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.00% of original 13) and increased the count of 0 pre-existing words (0.00% of original 13)', 'datetime': '2023-04-04T13:39:10.692571', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:10,693 : INFO : deleting the raw counts dictionary of 13 items\n",
      "2023-04-04 13:39:10,694 : INFO : sample=0.001 downsamples 0 most-common words\n",
      "2023-04-04 13:39:10,696 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 0 word corpus (0.0%% of prior 0)', 'datetime': '2023-04-04T13:39:10.696586', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:10,732 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2023-04-04 13:39:10,739 : INFO : updating layer weights\n",
      "2023-04-04 13:39:10,741 : INFO : Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:10.741297', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:10,744 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2023-04-04 13:39:10,746 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:10.746283', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:10,755 : INFO : EPOCH 0: training on 13 raw words (5 effective words) took 0.0s, 4303 effective words/s\n",
      "2023-04-04 13:39:10,764 : INFO : EPOCH 1: training on 13 raw words (5 effective words) took 0.0s, 4302 effective words/s\n",
      "2023-04-04 13:39:10,772 : INFO : EPOCH 2: training on 13 raw words (5 effective words) took 0.0s, 3863 effective words/s\n",
      "2023-04-04 13:39:10,779 : INFO : EPOCH 3: training on 13 raw words (6 effective words) took 0.0s, 5733 effective words/s\n",
      "2023-04-04 13:39:10,787 : INFO : EPOCH 4: training on 13 raw words (6 effective words) took 0.0s, 3450 effective words/s\n",
      "2023-04-04 13:39:10,789 : INFO : Word2Vec lifecycle event {'msg': 'training on 65 raw words (27 effective words) took 0.0s, 646 effective words/s', 'datetime': '2023-04-04T13:39:10.789906', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load(temporary_filepath)\n",
    "more_sentences = [\n",
    "    ['Advanced', 'users', 'can', 'load', 'a', 'model',\n",
    "     'and', 'continue', 'training', 'it', 'with', 'more', 'sentences'],\n",
    "]\n",
    "model.build_vocab(more_sentences, update=True)\n",
    "model.train(more_sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# cleaning up temporary file\n",
    "import os\n",
    "os.remove(temporary_filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loss Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:39:12,323 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:12,327 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:12,531 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2023-04-04 13:39:12,534 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:12,594 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 6981 unique words (100.00% of original 6981, drops 0)', 'datetime': '2023-04-04T13:39:12.593203', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:12,595 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 58152 word corpus (100.00% of original 58152, drops 0)', 'datetime': '2023-04-04T13:39:12.595206', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:12,709 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2023-04-04 13:39:12,710 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2023-04-04 13:39:12,712 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 45723.4541622429 word corpus (78.6%% of prior 58152)', 'datetime': '2023-04-04T13:39:12.712823', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:12,823 : INFO : estimated required memory for 6981 words and 100 dimensions: 9075300 bytes\n",
      "2023-04-04 13:39:12,825 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:12,835 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:12.835889', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:12,837 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 6981 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:12.837467', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:13,161 : INFO : EPOCH 0: training on 58152 raw words (45666 effective words) took 0.3s, 144645 effective words/s\n",
      "2023-04-04 13:39:13,493 : INFO : EPOCH 1: training on 58152 raw words (45568 effective words) took 0.3s, 139930 effective words/s\n",
      "2023-04-04 13:39:13,812 : INFO : EPOCH 2: training on 58152 raw words (45760 effective words) took 0.3s, 146484 effective words/s\n",
      "2023-04-04 13:39:14,148 : INFO : EPOCH 3: training on 58152 raw words (45680 effective words) took 0.3s, 138355 effective words/s\n",
      "2023-04-04 13:39:14,507 : INFO : EPOCH 4: training on 58152 raw words (45658 effective words) took 0.4s, 128934 effective words/s\n",
      "2023-04-04 13:39:14,508 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (228332 effective words) took 1.7s, 136781 effective words/s', 'datetime': '2023-04-04T13:39:14.508900', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:14,509 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=6981, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:14.509899', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360236.25\n"
     ]
    }
   ],
   "source": [
    "# instantiating and training the Word2Vec model\n",
    "model_with_loss = gensim.models.Word2Vec(\n",
    "    sentences,\n",
    "    min_count=1,\n",
    "    compute_loss=True,\n",
    "    hs=0,\n",
    "    sg=1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# getting the training loss value\n",
    "training_loss = model_with_loss.get_latest_training_loss()\n",
    "print(training_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:39:30,330 : INFO : text8 downloaded\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "import gensim.models.word2vec\n",
    "import gensim.downloader as api\n",
    "import smart_open\n",
    "\n",
    "\n",
    "def head(path, size):\n",
    "    with smart_open.open(path) as fin:\n",
    "        return io.StringIO(fin.read(size))\n",
    "\n",
    "\n",
    "def generate_input_data():\n",
    "    lee_path = datapath('lee_background.cor')\n",
    "    ls = gensim.models.word2vec.LineSentence(lee_path)\n",
    "    ls.name = '25kB'\n",
    "    yield ls\n",
    "\n",
    "    text8_path = api.load('text8').fn\n",
    "    labels = ('1MB', '10MB', '50MB', '100MB')\n",
    "    sizes = (1024 ** 2, 10 * 1024 ** 2, 50 * 1024 ** 2, 100 * 1024 ** 2)\n",
    "    for l, s in zip(labels, sizes):\n",
    "        ls = gensim.models.word2vec.LineSentence(head(text8_path, s))\n",
    "        ls.name = l\n",
    "        yield ls\n",
    "\n",
    "\n",
    "input_data = list(generate_input_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:39:48,600 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:48,603 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:48,635 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:48,637 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:48,664 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:48.664459', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:48,666 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:48.666461', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:48,703 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:48,705 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:48,710 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:48.710379', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:48,758 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:39:48,760 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:48,766 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:48.766227', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:48,768 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:48.768765', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:48,868 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.1s, 354088 effective words/s\n",
      "2023-04-04 13:39:48,977 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.1s, 336240 effective words/s\n",
      "2023-04-04 13:39:49,067 : INFO : EPOCH 2: training on 59890 raw words (32603 effective words) took 0.1s, 387557 effective words/s\n",
      "2023-04-04 13:39:49,150 : INFO : EPOCH 3: training on 59890 raw words (32587 effective words) took 0.1s, 413456 effective words/s\n",
      "2023-04-04 13:39:49,234 : INFO : EPOCH 4: training on 59890 raw words (32592 effective words) took 0.1s, 417873 effective words/s\n",
      "2023-04-04 13:39:49,235 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.5s, 349629 effective words/s', 'datetime': '2023-04-04T13:39:49.235727', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:49,237 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:49.237298', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:39:49,240 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:49,245 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:49,294 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:49,295 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:49,320 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:49.320142', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:49,322 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:49.322154', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:49,359 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:49,361 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:49,364 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:49.363915', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:49,411 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:39:49,412 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:49,418 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:49.418339', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:49,420 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:49.420345', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:49,511 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.1s, 392446 effective words/s\n",
      "2023-04-04 13:39:49,602 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.1s, 388352 effective words/s\n",
      "2023-04-04 13:39:49,685 : INFO : EPOCH 2: training on 59890 raw words (32603 effective words) took 0.1s, 426563 effective words/s\n",
      "2023-04-04 13:39:49,770 : INFO : EPOCH 3: training on 59890 raw words (32587 effective words) took 0.1s, 418921 effective words/s\n",
      "2023-04-04 13:39:49,853 : INFO : EPOCH 4: training on 59890 raw words (32592 effective words) took 0.1s, 430291 effective words/s\n",
      "2023-04-04 13:39:49,854 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.4s, 375615 effective words/s', 'datetime': '2023-04-04T13:39:49.854569', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:49,859 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:49.859114', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:39:49,861 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:49,864 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:49,909 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:49,911 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:49,935 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:49.935454', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:49,936 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:49.936967', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:49,970 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:49,972 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:49,975 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:49.975631', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:50,024 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:39:50,025 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:50,030 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:50.030077', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:50,032 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:50.032096', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:50,117 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.1s, 400422 effective words/s\n",
      "2023-04-04 13:39:50,201 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.1s, 438848 effective words/s\n",
      "2023-04-04 13:39:50,279 : INFO : EPOCH 2: training on 59890 raw words (32603 effective words) took 0.1s, 473140 effective words/s\n",
      "2023-04-04 13:39:50,359 : INFO : EPOCH 3: training on 59890 raw words (32587 effective words) took 0.1s, 436610 effective words/s\n",
      "2023-04-04 13:39:50,438 : INFO : EPOCH 4: training on 59890 raw words (32592 effective words) took 0.1s, 442658 effective words/s\n",
      "2023-04-04 13:39:50,440 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.4s, 398772 effective words/s', 'datetime': '2023-04-04T13:39:50.440607', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:50,443 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:50.443631', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:39:50,447 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:50,449 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:50,510 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:50,512 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:50,535 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:50.535101', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:50,537 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:50.537111', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:50,572 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:50,574 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:50,577 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:50.577332', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:50,620 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:39:50,621 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:50,628 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:50.628616', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:50,630 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:50.630622', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #0: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 0.6145718097686768, 'train_time_std': 0.022985500695540954}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:39:50,725 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.1s, 363343 effective words/s\n",
      "2023-04-04 13:39:50,811 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.1s, 405975 effective words/s\n",
      "2023-04-04 13:39:50,903 : INFO : EPOCH 2: training on 59890 raw words (32603 effective words) took 0.1s, 376672 effective words/s\n",
      "2023-04-04 13:39:50,983 : INFO : EPOCH 3: training on 59890 raw words (32587 effective words) took 0.1s, 448391 effective words/s\n",
      "2023-04-04 13:39:51,074 : INFO : EPOCH 4: training on 59890 raw words (32592 effective words) took 0.1s, 395887 effective words/s\n",
      "2023-04-04 13:39:51,075 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.4s, 366249 effective words/s', 'datetime': '2023-04-04T13:39:51.075702', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:51,078 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:51.078239', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:39:51,080 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:51,083 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:51,128 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:51,130 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:51,157 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:51.157238', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:51,159 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:51.159807', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:51,194 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:51,198 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:51,200 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:51.200456', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:51,251 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:39:51,252 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:51,258 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:51.258797', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:51,260 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:51.260797', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:51,346 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.1s, 412250 effective words/s\n",
      "2023-04-04 13:39:51,427 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.1s, 429049 effective words/s\n",
      "2023-04-04 13:39:51,530 : INFO : EPOCH 2: training on 59890 raw words (32603 effective words) took 0.1s, 333509 effective words/s\n",
      "2023-04-04 13:39:51,634 : INFO : EPOCH 3: training on 59890 raw words (32587 effective words) took 0.1s, 331372 effective words/s\n",
      "2023-04-04 13:39:51,743 : INFO : EPOCH 4: training on 59890 raw words (32592 effective words) took 0.1s, 332677 effective words/s\n",
      "2023-04-04 13:39:51,745 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.5s, 337674 effective words/s', 'datetime': '2023-04-04T13:39:51.745046', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:51,747 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:51.747048', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:39:51,749 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:51,752 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:51,818 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:51,819 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:51,867 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:51.867067', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:51,869 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:51.869039', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:51,915 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:51,918 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:51,921 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:51.921494', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:51,974 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:39:51,979 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:51,985 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:51.985587', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:51,991 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:51.991137', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:52,097 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.1s, 325843 effective words/s\n",
      "2023-04-04 13:39:52,198 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.1s, 351457 effective words/s\n",
      "2023-04-04 13:39:52,302 : INFO : EPOCH 2: training on 59890 raw words (32603 effective words) took 0.1s, 354516 effective words/s\n",
      "2023-04-04 13:39:52,418 : INFO : EPOCH 3: training on 59890 raw words (32587 effective words) took 0.1s, 312753 effective words/s\n",
      "2023-04-04 13:39:52,531 : INFO : EPOCH 4: training on 59890 raw words (32592 effective words) took 0.1s, 324610 effective words/s\n",
      "2023-04-04 13:39:52,532 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.5s, 302045 effective words/s', 'datetime': '2023-04-04T13:39:52.532469', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:52,533 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:52.533469', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:39:52,543 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:52,547 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:52,612 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:52,614 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:52,649 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:52.649798', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:52,651 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:52.651791', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:52,694 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:52,697 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:52,699 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:52.699161', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:52,709 : INFO : constructing a huffman tree from 1762 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #1: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 0.696085532506307, 'train_time_std': 0.0657968697615705}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:39:52,868 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:39:52,923 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:39:52,928 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:52,933 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:52.933599', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:52,934 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:39:52,938 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:52.938144', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:53,169 : INFO : EPOCH 0: training on 59890 raw words (32530 effective words) took 0.2s, 146845 effective words/s\n",
      "2023-04-04 13:39:53,344 : INFO : EPOCH 1: training on 59890 raw words (32709 effective words) took 0.2s, 199617 effective words/s\n",
      "2023-04-04 13:39:53,517 : INFO : EPOCH 2: training on 59890 raw words (32568 effective words) took 0.2s, 195276 effective words/s\n",
      "2023-04-04 13:39:53,688 : INFO : EPOCH 3: training on 59890 raw words (32637 effective words) took 0.2s, 199988 effective words/s\n",
      "2023-04-04 13:39:53,867 : INFO : EPOCH 4: training on 59890 raw words (32540 effective words) took 0.2s, 189044 effective words/s\n",
      "2023-04-04 13:39:53,870 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162984 effective words) took 0.9s, 175401 effective words/s', 'datetime': '2023-04-04T13:39:53.870570', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:53,872 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:53.872604', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:39:53,875 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:53,881 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:53,956 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:53,957 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:53,992 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:53.992414', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:53,994 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:53.994945', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:54,031 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:54,033 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:54,037 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:54.037728', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:54,045 : INFO : constructing a huffman tree from 1762 words\n",
      "2023-04-04 13:39:54,239 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:39:54,349 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:39:54,352 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:54,361 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:54.361913', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:54,383 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:39:54,403 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:54.403257', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:54,772 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.3s, 124207 effective words/s\n",
      "2023-04-04 13:39:54,963 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.2s, 178223 effective words/s\n",
      "2023-04-04 13:39:55,130 : INFO : EPOCH 2: training on 59890 raw words (32685 effective words) took 0.2s, 207251 effective words/s\n",
      "2023-04-04 13:39:55,306 : INFO : EPOCH 3: training on 59890 raw words (32526 effective words) took 0.2s, 199492 effective words/s\n",
      "2023-04-04 13:39:55,492 : INFO : EPOCH 4: training on 59890 raw words (32543 effective words) took 0.2s, 180803 effective words/s\n",
      "2023-04-04 13:39:55,493 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162849 effective words) took 1.1s, 149836 effective words/s', 'datetime': '2023-04-04T13:39:55.493114', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:55,494 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:55.494114', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:39:55,498 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:55,507 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:55,587 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:55,589 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:55,630 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:55.630988', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:55,638 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:55.638590', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:55,691 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:55,694 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:55,696 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:55.696488', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:55,707 : INFO : constructing a huffman tree from 1762 words\n",
      "2023-04-04 13:39:55,889 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:39:55,928 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:39:55,929 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:55,939 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:55.939751', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:55,943 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:39:55,952 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:55.951879', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:56,322 : INFO : EPOCH 0: training on 59890 raw words (32549 effective words) took 0.3s, 124740 effective words/s\n",
      "2023-04-04 13:39:56,606 : INFO : EPOCH 1: training on 59890 raw words (32640 effective words) took 0.3s, 118175 effective words/s\n",
      "2023-04-04 13:39:56,797 : INFO : EPOCH 2: training on 59890 raw words (32638 effective words) took 0.2s, 176388 effective words/s\n",
      "2023-04-04 13:39:57,045 : INFO : EPOCH 3: training on 59890 raw words (32547 effective words) took 0.2s, 136580 effective words/s\n",
      "2023-04-04 13:39:57,257 : INFO : EPOCH 4: training on 59890 raw words (32627 effective words) took 0.2s, 161399 effective words/s\n",
      "2023-04-04 13:39:57,259 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (163001 effective words) took 1.3s, 126450 effective words/s', 'datetime': '2023-04-04T13:39:57.259065', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:57,260 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:57.260071', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:39:57,264 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:57,269 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:57,318 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:57,319 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:57,340 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:57.340978', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:57,342 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:57.342985', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:57,363 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:57,365 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:57,368 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:57.368376', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:57,374 : INFO : constructing a huffman tree from 1762 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #2: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 1.5733048915863037, 'train_time_std': 0.17942882024326978}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:39:57,505 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:39:57,541 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:39:57,543 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:57,546 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:57.546278', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:57,549 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:39:57,551 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:57.551857', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:57,710 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.2s, 215473 effective words/s\n",
      "2023-04-04 13:39:57,861 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.1s, 224733 effective words/s\n",
      "2023-04-04 13:39:58,009 : INFO : EPOCH 2: training on 59890 raw words (32603 effective words) took 0.1s, 230302 effective words/s\n",
      "2023-04-04 13:39:58,178 : INFO : EPOCH 3: training on 59890 raw words (32587 effective words) took 0.2s, 200696 effective words/s\n",
      "2023-04-04 13:39:58,310 : INFO : EPOCH 4: training on 59890 raw words (32592 effective words) took 0.1s, 263011 effective words/s\n",
      "2023-04-04 13:39:58,311 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.8s, 215132 effective words/s', 'datetime': '2023-04-04T13:39:58.311258', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:58,312 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:58.312262', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:39:58,316 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:58,319 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:58,362 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:58,364 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:58,403 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:58.403265', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:58,404 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:58.404280', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:58,433 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:58,435 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:58,438 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:58.438236', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:58,442 : INFO : constructing a huffman tree from 1762 words\n",
      "2023-04-04 13:39:58,566 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:39:58,606 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:39:58,607 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:58,612 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:58.612782', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:58,615 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:39:58,619 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:58.619349', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:58,780 : INFO : EPOCH 0: training on 59890 raw words (32549 effective words) took 0.2s, 210165 effective words/s\n",
      "2023-04-04 13:39:58,965 : INFO : EPOCH 1: training on 59890 raw words (32604 effective words) took 0.2s, 184997 effective words/s\n",
      "2023-04-04 13:39:59,096 : INFO : EPOCH 2: training on 59890 raw words (32676 effective words) took 0.1s, 261696 effective words/s\n",
      "2023-04-04 13:39:59,252 : INFO : EPOCH 3: training on 59890 raw words (32605 effective words) took 0.1s, 221212 effective words/s\n",
      "2023-04-04 13:39:59,384 : INFO : EPOCH 4: training on 59890 raw words (32405 effective words) took 0.1s, 254847 effective words/s\n",
      "2023-04-04 13:39:59,386 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162839 effective words) took 0.8s, 212781 effective words/s', 'datetime': '2023-04-04T13:39:59.386989', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:59,392 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:39:59.392549', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:39:59,401 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:39:59,412 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:39:59,460 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:39:59,461 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:39:59,487 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:39:59.487159', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:59,488 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:39:59.488706', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:59,521 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:39:59,523 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:39:59,525 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:39:59.525593', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:39:59,531 : INFO : constructing a huffman tree from 1762 words\n",
      "2023-04-04 13:39:59,673 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:39:59,710 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:39:59,712 : INFO : resetting layer weights\n",
      "2023-04-04 13:39:59,716 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:39:59.716382', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:39:59,717 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:39:59,719 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:39:59.719910', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:39:59,867 : INFO : EPOCH 0: training on 59890 raw words (32528 effective words) took 0.1s, 237405 effective words/s\n",
      "2023-04-04 13:39:59,984 : INFO : EPOCH 1: training on 59890 raw words (32557 effective words) took 0.1s, 288437 effective words/s\n",
      "2023-04-04 13:40:00,124 : INFO : EPOCH 2: training on 59890 raw words (32654 effective words) took 0.1s, 241062 effective words/s\n",
      "2023-04-04 13:40:00,286 : INFO : EPOCH 3: training on 59890 raw words (32527 effective words) took 0.2s, 211650 effective words/s\n",
      "2023-04-04 13:40:00,440 : INFO : EPOCH 4: training on 59890 raw words (32640 effective words) took 0.1s, 219432 effective words/s\n",
      "2023-04-04 13:40:00,442 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162906 effective words) took 0.7s, 226487 effective words/s', 'datetime': '2023-04-04T13:40:00.442502', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:00,443 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:00.443506', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:00,448 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:00,450 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:00,491 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:00,492 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:00,515 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:00.515526', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:00,518 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:00.518061', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:00,546 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:00,547 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:00,549 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:00.549719', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:00,598 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:40:00,599 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:00,604 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:00.604043', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:00,606 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:00.606051', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #3: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 1.0613186359405518, 'train_time_std': 0.015410054581855438}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:40:00,822 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.2s, 157100 effective words/s\n",
      "2023-04-04 13:40:01,047 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.2s, 147642 effective words/s\n",
      "2023-04-04 13:40:01,252 : INFO : EPOCH 2: training on 59890 raw words (32603 effective words) took 0.2s, 163898 effective words/s\n",
      "2023-04-04 13:40:01,441 : INFO : EPOCH 3: training on 59890 raw words (32587 effective words) took 0.2s, 177131 effective words/s\n",
      "2023-04-04 13:40:01,609 : INFO : EPOCH 4: training on 59890 raw words (32592 effective words) took 0.2s, 200952 effective words/s\n",
      "2023-04-04 13:40:01,611 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 1.0s, 162235 effective words/s', 'datetime': '2023-04-04T13:40:01.611302', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:01,613 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:01.613309', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:01,616 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:01,620 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:01,689 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:01,690 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:01,713 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:01.713325', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:01,715 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:01.715347', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:01,739 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:01,741 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:01,744 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:01.744961', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:01,780 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:40:01,782 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:01,789 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:01.789386', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:01,790 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:01.790415', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:02,002 : INFO : EPOCH 0: training on 59890 raw words (32668 effective words) took 0.2s, 158809 effective words/s\n",
      "2023-04-04 13:40:02,215 : INFO : EPOCH 1: training on 59890 raw words (32652 effective words) took 0.2s, 157850 effective words/s\n",
      "2023-04-04 13:40:02,386 : INFO : EPOCH 2: training on 59890 raw words (32568 effective words) took 0.2s, 197972 effective words/s\n",
      "2023-04-04 13:40:02,580 : INFO : EPOCH 3: training on 59890 raw words (32585 effective words) took 0.2s, 172099 effective words/s\n",
      "2023-04-04 13:40:02,885 : INFO : EPOCH 4: training on 59890 raw words (32720 effective words) took 0.3s, 109745 effective words/s\n",
      "2023-04-04 13:40:02,887 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (163193 effective words) took 1.1s, 148992 effective words/s', 'datetime': '2023-04-04T13:40:02.887253', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:02,888 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:02.888787', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:02,893 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:02,898 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:02,983 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:02,985 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:03,030 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:03.029420', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:03,032 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:03.032461', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:03,094 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:03,101 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:03,102 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:03.102727', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:03,201 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:40:03,203 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:03,209 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:03.209130', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:03,211 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:03.211168', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:03,501 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.3s, 114679 effective words/s\n",
      "2023-04-04 13:40:03,697 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.2s, 174041 effective words/s\n",
      "2023-04-04 13:40:03,867 : INFO : EPOCH 2: training on 59890 raw words (32603 effective words) took 0.2s, 197425 effective words/s\n",
      "2023-04-04 13:40:04,028 : INFO : EPOCH 3: training on 59890 raw words (32587 effective words) took 0.2s, 204111 effective words/s\n",
      "2023-04-04 13:40:04,187 : INFO : EPOCH 4: training on 59890 raw words (32592 effective words) took 0.2s, 210163 effective words/s\n",
      "2023-04-04 13:40:04,187 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 1.0s, 166104 effective words/s', 'datetime': '2023-04-04T13:40:04.187330', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:04,187 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:04.187330', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:04,187 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:04,197 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:04,237 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:04,237 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:04,257 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:04.257418', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:04,257 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:04.257418', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:04,282 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:04,282 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:04,287 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:04.287430', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:04,317 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:40:04,317 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:04,317 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:04.317447', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:04,317 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:04.317447', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #4: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 1.246769905090332, 'train_time_std': 0.055282476235718726}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:40:04,491 : INFO : EPOCH 0: training on 59890 raw words (32676 effective words) took 0.2s, 200983 effective words/s\n",
      "2023-04-04 13:40:04,661 : INFO : EPOCH 1: training on 59890 raw words (32585 effective words) took 0.2s, 200539 effective words/s\n",
      "2023-04-04 13:40:04,872 : INFO : EPOCH 2: training on 59890 raw words (32615 effective words) took 0.2s, 161800 effective words/s\n",
      "2023-04-04 13:40:05,052 : INFO : EPOCH 3: training on 59890 raw words (32602 effective words) took 0.2s, 190077 effective words/s\n",
      "2023-04-04 13:40:05,216 : INFO : EPOCH 4: training on 59890 raw words (32563 effective words) took 0.2s, 197954 effective words/s\n",
      "2023-04-04 13:40:05,216 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (163041 effective words) took 0.9s, 181596 effective words/s', 'datetime': '2023-04-04T13:40:05.216956', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:05,227 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:05.227093', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:05,227 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:05,232 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:05,278 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:05,278 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:05,297 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:05.297215', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:05,304 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:05.304218', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:05,327 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:05,327 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:05,327 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:05.327292', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:05,373 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:40:05,373 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:05,377 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:05.377169', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:05,377 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:05.377169', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:05,552 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.2s, 196109 effective words/s\n",
      "2023-04-04 13:40:05,721 : INFO : EPOCH 1: training on 59890 raw words (32705 effective words) took 0.2s, 199807 effective words/s\n",
      "2023-04-04 13:40:05,904 : INFO : EPOCH 2: training on 59890 raw words (32617 effective words) took 0.2s, 182210 effective words/s\n",
      "2023-04-04 13:40:06,068 : INFO : EPOCH 3: training on 59890 raw words (32571 effective words) took 0.2s, 203031 effective words/s\n",
      "2023-04-04 13:40:06,260 : INFO : EPOCH 4: training on 59890 raw words (32604 effective words) took 0.2s, 177259 effective words/s\n",
      "2023-04-04 13:40:06,260 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (163040 effective words) took 0.9s, 185365 effective words/s', 'datetime': '2023-04-04T13:40:06.260862', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:06,260 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:06.260862', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:06,260 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:06,266 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:06,311 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:06,317 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:06,340 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:06.340003', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:06,342 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:06.342019', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:06,372 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:06,372 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:06,377 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:06.377266', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:06,427 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2023-04-04 13:40:06,427 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:06,427 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:06.427258', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:06,427 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:06.427258', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:06,626 : INFO : EPOCH 0: training on 59890 raw words (32596 effective words) took 0.2s, 170868 effective words/s\n",
      "2023-04-04 13:40:06,805 : INFO : EPOCH 1: training on 59890 raw words (32570 effective words) took 0.2s, 191891 effective words/s\n",
      "2023-04-04 13:40:06,977 : INFO : EPOCH 2: training on 59890 raw words (32509 effective words) took 0.2s, 190852 effective words/s\n",
      "2023-04-04 13:40:07,157 : INFO : EPOCH 3: training on 59890 raw words (32612 effective words) took 0.2s, 188552 effective words/s\n",
      "2023-04-04 13:40:07,317 : INFO : EPOCH 4: training on 59890 raw words (32612 effective words) took 0.2s, 207218 effective words/s\n",
      "2023-04-04 13:40:07,317 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162899 effective words) took 0.9s, 183780 effective words/s', 'datetime': '2023-04-04T13:40:07.317095', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:07,317 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:07.317095', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:07,326 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:07,326 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:07,376 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:07,376 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:07,397 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:07.397153', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:07,402 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:07.402235', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:07,426 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:07,432 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:07,432 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:07.432008', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:07,437 : INFO : constructing a huffman tree from 1762 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #5: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 1.0432551701863606, 'train_time_std': 0.009498107327648228}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:40:07,547 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:40:07,577 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:40:07,577 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:07,577 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:07.577169', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:07,587 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:07,587 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:07.587549', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:07,977 : INFO : EPOCH 0: training on 59890 raw words (32530 effective words) took 0.4s, 84827 effective words/s\n",
      "2023-04-04 13:40:08,457 : INFO : EPOCH 1: training on 59890 raw words (32568 effective words) took 0.5s, 68926 effective words/s\n",
      "2023-04-04 13:40:08,849 : INFO : EPOCH 2: training on 59890 raw words (32682 effective words) took 0.4s, 84434 effective words/s\n",
      "2023-04-04 13:40:09,190 : INFO : EPOCH 3: training on 59890 raw words (32586 effective words) took 0.3s, 97283 effective words/s\n",
      "2023-04-04 13:40:09,579 : INFO : EPOCH 4: training on 59890 raw words (32662 effective words) took 0.4s, 84978 effective words/s\n",
      "2023-04-04 13:40:09,581 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (163028 effective words) took 2.0s, 81995 effective words/s', 'datetime': '2023-04-04T13:40:09.581748', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:09,583 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:09.583742', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:09,588 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:09,593 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:09,647 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:09,647 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:09,668 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:09.668126', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:09,670 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:09.670122', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:09,691 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:09,693 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:09,696 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:09.696187', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:09,702 : INFO : constructing a huffman tree from 1762 words\n",
      "2023-04-04 13:40:09,788 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:40:09,817 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:40:09,818 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:09,822 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:09.822581', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:09,823 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:09,824 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:09.824570', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:10,178 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.3s, 93586 effective words/s\n",
      "2023-04-04 13:40:10,504 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.3s, 101390 effective words/s\n",
      "2023-04-04 13:40:10,838 : INFO : EPOCH 2: training on 59890 raw words (32603 effective words) took 0.3s, 99373 effective words/s\n",
      "2023-04-04 13:40:11,161 : INFO : EPOCH 3: training on 59890 raw words (32587 effective words) took 0.3s, 102733 effective words/s\n",
      "2023-04-04 13:40:11,481 : INFO : EPOCH 4: training on 59890 raw words (32693 effective words) took 0.3s, 104635 effective words/s\n",
      "2023-04-04 13:40:11,483 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162978 effective words) took 1.7s, 98246 effective words/s', 'datetime': '2023-04-04T13:40:11.483943', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:11,484 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:11.484946', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:11,487 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:11,490 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:11,526 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:11,527 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:11,544 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:11.544165', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:11,545 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:11.545130', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:11,573 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:11,575 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:11,577 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:11.577403', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:11,582 : INFO : constructing a huffman tree from 1762 words\n",
      "2023-04-04 13:40:11,654 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:40:11,683 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:40:11,685 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:11,690 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:11.690685', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:11,691 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:11,693 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:11.693679', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:12,125 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.4s, 76997 effective words/s\n",
      "2023-04-04 13:40:12,520 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.4s, 83542 effective words/s\n",
      "2023-04-04 13:40:12,920 : INFO : EPOCH 2: training on 59890 raw words (32517 effective words) took 0.4s, 82429 effective words/s\n",
      "2023-04-04 13:40:13,305 : INFO : EPOCH 3: training on 59890 raw words (32769 effective words) took 0.4s, 86325 effective words/s\n",
      "2023-04-04 13:40:13,674 : INFO : EPOCH 4: training on 59890 raw words (32723 effective words) took 0.4s, 89845 effective words/s\n",
      "2023-04-04 13:40:13,675 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (163104 effective words) took 2.0s, 82334 effective words/s', 'datetime': '2023-04-04T13:40:13.675949', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:13,676 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:13.676948', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:13,681 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:13,684 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:13,737 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:13,739 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:13,759 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:13.759459', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:13,760 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:13.760458', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:13,789 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:13,791 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:13,793 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:13.792131', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:13,797 : INFO : constructing a huffman tree from 1762 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #6: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 2.120964209238688, 'train_time_std': 0.1604011660980497}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:40:13,921 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:40:13,960 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:40:13,962 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:13,967 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:13.967522', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:13,969 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:13,971 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:13.971328', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:14,342 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.4s, 89440 effective words/s\n",
      "2023-04-04 13:40:14,753 : INFO : EPOCH 1: training on 59890 raw words (32616 effective words) took 0.4s, 80337 effective words/s\n",
      "2023-04-04 13:40:15,139 : INFO : EPOCH 2: training on 59890 raw words (32670 effective words) took 0.4s, 86119 effective words/s\n",
      "2023-04-04 13:40:15,534 : INFO : EPOCH 3: training on 59890 raw words (32605 effective words) took 0.4s, 83717 effective words/s\n",
      "2023-04-04 13:40:15,955 : INFO : EPOCH 4: training on 59890 raw words (32405 effective words) took 0.4s, 78008 effective words/s\n",
      "2023-04-04 13:40:15,957 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162839 effective words) took 2.0s, 82091 effective words/s', 'datetime': '2023-04-04T13:40:15.957297', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:15,958 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:15.958836', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:15,960 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:15,965 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:16,010 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:16,011 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:16,036 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:16.036279', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:16,037 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:16.037803', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:16,065 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:16,068 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:16,070 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:16.070475', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:16,072 : INFO : constructing a huffman tree from 1762 words\n",
      "2023-04-04 13:40:16,176 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:40:16,210 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:40:16,211 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:16,218 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:16.218295', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:16,220 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:16,222 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:16.222291', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:16,599 : INFO : EPOCH 0: training on 59890 raw words (32543 effective words) took 0.4s, 87955 effective words/s\n",
      "2023-04-04 13:40:16,938 : INFO : EPOCH 1: training on 59890 raw words (32552 effective words) took 0.3s, 97462 effective words/s\n",
      "2023-04-04 13:40:17,285 : INFO : EPOCH 2: training on 59890 raw words (32517 effective words) took 0.3s, 95692 effective words/s\n",
      "2023-04-04 13:40:17,611 : INFO : EPOCH 3: training on 59890 raw words (32654 effective words) took 0.3s, 101807 effective words/s\n",
      "2023-04-04 13:40:17,941 : INFO : EPOCH 4: training on 59890 raw words (32643 effective words) took 0.3s, 100546 effective words/s\n",
      "2023-04-04 13:40:17,942 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162909 effective words) took 1.7s, 94741 effective words/s', 'datetime': '2023-04-04T13:40:17.942689', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:17,944 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:17.944652', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:17,948 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:17,951 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:17,985 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 13:40:17,988 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:18,009 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T13:40:18.009430', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:18,011 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T13:40:18.010950', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:18,030 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 13:40:18,032 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 13:40:18,033 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T13:40:18.033267', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:18,036 : INFO : constructing a huffman tree from 1762 words\n",
      "2023-04-04 13:40:18,127 : INFO : built huffman tree with maximum node depth 13\n",
      "2023-04-04 13:40:18,154 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2023-04-04 13:40:18,155 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:18,162 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:18.161258', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:18,163 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:18,165 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:18.165268', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:18,504 : INFO : EPOCH 0: training on 59890 raw words (32668 effective words) took 0.3s, 98060 effective words/s\n",
      "2023-04-04 13:40:18,847 : INFO : EPOCH 1: training on 59890 raw words (32652 effective words) took 0.3s, 96725 effective words/s\n",
      "2023-04-04 13:40:19,183 : INFO : EPOCH 2: training on 59890 raw words (32568 effective words) took 0.3s, 98995 effective words/s\n",
      "2023-04-04 13:40:19,509 : INFO : EPOCH 3: training on 59890 raw words (32613 effective words) took 0.3s, 101533 effective words/s\n",
      "2023-04-04 13:40:19,829 : INFO : EPOCH 4: training on 59890 raw words (32601 effective words) took 0.3s, 103609 effective words/s\n",
      "2023-04-04 13:40:19,831 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (163102 effective words) took 1.7s, 98001 effective words/s', 'datetime': '2023-04-04T13:40:19.831068', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:19,833 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1762, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:19.833073', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:19,837 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:19,867 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:19,923 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:19,925 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:19,963 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:19.963997', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:19,964 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:19.964952', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:20,006 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:20,008 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:20,012 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:20.012591', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #7: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 2.0520317554473877, 'train_time_std': 0.16663456503251287}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:40:20,078 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:40:20,080 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:20,084 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:20.084210', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:20,085 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:20.085146', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:20,277 : INFO : EPOCH 0: training on 175599 raw words (110284 effective words) took 0.2s, 679533 effective words/s\n",
      "2023-04-04 13:40:20,457 : INFO : EPOCH 1: training on 175599 raw words (110008 effective words) took 0.2s, 723849 effective words/s\n",
      "2023-04-04 13:40:20,630 : INFO : EPOCH 2: training on 175599 raw words (110258 effective words) took 0.1s, 747215 effective words/s\n",
      "2023-04-04 13:40:20,850 : INFO : EPOCH 3: training on 175599 raw words (110197 effective words) took 0.2s, 582686 effective words/s\n",
      "2023-04-04 13:40:21,059 : INFO : EPOCH 4: training on 175599 raw words (110171 effective words) took 0.2s, 622783 effective words/s\n",
      "2023-04-04 13:40:21,060 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550918 effective words) took 1.0s, 565318 effective words/s', 'datetime': '2023-04-04T13:40:21.060136', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:21,062 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:21.062139', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:21,065 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:21,097 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:21,169 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:21,172 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:21,218 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:21.218130', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:21,219 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:21.219132', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:21,273 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:21,277 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:21,279 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:21.279350', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:21,353 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:40:21,355 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:21,361 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:21.361238', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:21,362 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:21.362283', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:21,562 : INFO : EPOCH 0: training on 175599 raw words (110329 effective words) took 0.2s, 653883 effective words/s\n",
      "2023-04-04 13:40:21,760 : INFO : EPOCH 1: training on 175599 raw words (110082 effective words) took 0.2s, 668301 effective words/s\n",
      "2023-04-04 13:40:22,019 : INFO : EPOCH 2: training on 175599 raw words (110169 effective words) took 0.2s, 498258 effective words/s\n",
      "2023-04-04 13:40:22,267 : INFO : EPOCH 3: training on 175599 raw words (110223 effective words) took 0.2s, 519470 effective words/s\n",
      "2023-04-04 13:40:22,515 : INFO : EPOCH 4: training on 175599 raw words (110279 effective words) took 0.2s, 511314 effective words/s\n",
      "2023-04-04 13:40:22,517 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551082 effective words) took 1.2s, 477481 effective words/s', 'datetime': '2023-04-04T13:40:22.517916', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:22,518 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:22.518937', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:22,521 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:22,553 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:22,656 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:22,658 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:22,711 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:22.711071', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:22,713 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:22.713083', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:22,789 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:22,793 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:22,796 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:22.796015', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:22,915 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:40:22,917 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:22,924 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:22.924907', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:22,927 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:22.927422', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:23,195 : INFO : EPOCH 0: training on 175599 raw words (110523 effective words) took 0.2s, 488957 effective words/s\n",
      "2023-04-04 13:40:23,439 : INFO : EPOCH 1: training on 175599 raw words (110248 effective words) took 0.2s, 534602 effective words/s\n",
      "2023-04-04 13:40:23,686 : INFO : EPOCH 2: training on 175599 raw words (110096 effective words) took 0.2s, 535056 effective words/s\n",
      "2023-04-04 13:40:23,991 : INFO : EPOCH 3: training on 175599 raw words (110241 effective words) took 0.3s, 417908 effective words/s\n",
      "2023-04-04 13:40:24,310 : INFO : EPOCH 4: training on 175599 raw words (110344 effective words) took 0.3s, 410755 effective words/s\n",
      "2023-04-04 13:40:24,313 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551452 effective words) took 1.4s, 398700 effective words/s', 'datetime': '2023-04-04T13:40:24.313298', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:24,315 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:24.315273', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:24,321 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:24,385 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #8: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 1.4942554632822673, 'train_time_std': 0.23456594456286886}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:40:24,554 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:24,558 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:24,653 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:24.653755', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:24,655 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:24.655762', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:24,762 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:24,765 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:24,767 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:24.767007', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:24,877 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:40:24,879 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:24,885 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:24.884016', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:24,887 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:24.887023', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:25,159 : INFO : EPOCH 0: training on 175599 raw words (110344 effective words) took 0.2s, 478613 effective words/s\n",
      "2023-04-04 13:40:25,405 : INFO : EPOCH 1: training on 175599 raw words (110067 effective words) took 0.2s, 528747 effective words/s\n",
      "2023-04-04 13:40:25,667 : INFO : EPOCH 2: training on 175599 raw words (110159 effective words) took 0.2s, 493267 effective words/s\n",
      "2023-04-04 13:40:25,901 : INFO : EPOCH 3: training on 175599 raw words (110432 effective words) took 0.2s, 562090 effective words/s\n",
      "2023-04-04 13:40:26,135 : INFO : EPOCH 4: training on 175599 raw words (110093 effective words) took 0.2s, 553456 effective words/s\n",
      "2023-04-04 13:40:26,139 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551095 effective words) took 1.2s, 441685 effective words/s', 'datetime': '2023-04-04T13:40:26.139328', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:26,141 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:26.141324', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:26,144 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:26,179 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:26,278 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:26,280 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:26,341 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:26.341234', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:26,343 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:26.343225', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:26,425 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:26,427 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:26,428 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:26.428699', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:26,524 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:40:26,525 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:26,530 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:26.530792', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:26,534 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:26.534798', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:26,785 : INFO : EPOCH 0: training on 175599 raw words (110190 effective words) took 0.2s, 527979 effective words/s\n",
      "2023-04-04 13:40:26,995 : INFO : EPOCH 1: training on 175599 raw words (110125 effective words) took 0.2s, 652835 effective words/s\n",
      "2023-04-04 13:40:27,176 : INFO : EPOCH 2: training on 175599 raw words (110129 effective words) took 0.2s, 716663 effective words/s\n",
      "2023-04-04 13:40:27,353 : INFO : EPOCH 3: training on 175599 raw words (110223 effective words) took 0.1s, 743377 effective words/s\n",
      "2023-04-04 13:40:27,528 : INFO : EPOCH 4: training on 175599 raw words (110409 effective words) took 0.1s, 749009 effective words/s\n",
      "2023-04-04 13:40:27,530 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551076 effective words) took 1.0s, 554781 effective words/s', 'datetime': '2023-04-04T13:40:27.530262', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:27,532 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:27.532263', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:27,536 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:27,558 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:27,618 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:27,619 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:27,652 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:27.652802', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:27,653 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:27.653804', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:27,692 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:27,693 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:27,694 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:27.694959', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:27,749 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:40:27,752 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:27,756 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:27.756274', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:27,757 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:27.757784', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:27,939 : INFO : EPOCH 0: training on 175599 raw words (110230 effective words) took 0.2s, 731250 effective words/s\n",
      "2023-04-04 13:40:28,119 : INFO : EPOCH 1: training on 175599 raw words (110065 effective words) took 0.2s, 731006 effective words/s\n",
      "2023-04-04 13:40:28,300 : INFO : EPOCH 2: training on 175599 raw words (110345 effective words) took 0.2s, 712213 effective words/s\n",
      "2023-04-04 13:40:28,490 : INFO : EPOCH 3: training on 175599 raw words (110243 effective words) took 0.2s, 673417 effective words/s\n",
      "2023-04-04 13:40:28,674 : INFO : EPOCH 4: training on 175599 raw words (110320 effective words) took 0.2s, 721595 effective words/s\n",
      "2023-04-04 13:40:28,676 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551203 effective words) took 0.9s, 601090 effective words/s', 'datetime': '2023-04-04T13:40:28.676840', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:28,678 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:28.678404', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:28,682 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:28,706 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:28,769 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:28,770 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:28,807 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:28.807314', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:28,808 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:28.808182', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:28,873 : INFO : deleting the raw counts dictionary of 17251 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #9: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 1.4536771774291992, 'train_time_std': 0.2802451038893119}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:40:28,875 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:28,879 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:28.878298', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:28,886 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:40:29,251 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:40:29,303 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:40:29,305 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:29,311 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:29.311920', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:29,312 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:29,314 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:29.314916', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:29,663 : INFO : EPOCH 0: training on 175599 raw words (110078 effective words) took 0.3s, 339076 effective words/s\n",
      "2023-04-04 13:40:30,006 : INFO : EPOCH 1: training on 175599 raw words (110143 effective words) took 0.3s, 348341 effective words/s\n",
      "2023-04-04 13:40:30,340 : INFO : EPOCH 2: training on 175599 raw words (110191 effective words) took 0.3s, 360294 effective words/s\n",
      "2023-04-04 13:40:30,674 : INFO : EPOCH 3: training on 175599 raw words (110247 effective words) took 0.3s, 360047 effective words/s\n",
      "2023-04-04 13:40:31,023 : INFO : EPOCH 4: training on 175599 raw words (110320 effective words) took 0.3s, 346108 effective words/s\n",
      "2023-04-04 13:40:31,024 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550979 effective words) took 1.7s, 322629 effective words/s', 'datetime': '2023-04-04T13:40:31.024082', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:31,026 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:31.026082', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:31,029 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:31,059 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:31,143 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:31,145 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:31,191 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:31.191265', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:31,192 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:31.192273', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:31,241 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:31,244 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:31,245 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:31.245437', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:31,252 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:40:31,429 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:40:31,478 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:40:31,480 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:31,485 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:31.485291', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:31,486 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:31,488 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:31.488840', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:31,827 : INFO : EPOCH 0: training on 175599 raw words (110344 effective words) took 0.3s, 358711 effective words/s\n",
      "2023-04-04 13:40:32,248 : INFO : EPOCH 1: training on 175599 raw words (110172 effective words) took 0.4s, 281565 effective words/s\n",
      "2023-04-04 13:40:32,669 : INFO : EPOCH 2: training on 175599 raw words (110187 effective words) took 0.4s, 287026 effective words/s\n",
      "2023-04-04 13:40:33,097 : INFO : EPOCH 3: training on 175599 raw words (110428 effective words) took 0.4s, 281897 effective words/s\n",
      "2023-04-04 13:40:33,537 : INFO : EPOCH 4: training on 175599 raw words (110289 effective words) took 0.4s, 280630 effective words/s\n",
      "2023-04-04 13:40:33,538 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551420 effective words) took 2.0s, 269157 effective words/s', 'datetime': '2023-04-04T13:40:33.538246', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:33,542 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:33.541260', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:33,548 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:33,583 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:33,667 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:33,669 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:33,708 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:33.708722', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:33,711 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:33.711732', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:33,765 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:33,767 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:33,768 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:33.768900', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:33,776 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:40:34,003 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:40:34,069 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:40:34,071 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:34,079 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:34.079025', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:34,081 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:34,083 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:34.083999', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:34,553 : INFO : EPOCH 0: training on 175599 raw words (110245 effective words) took 0.4s, 255052 effective words/s\n",
      "2023-04-04 13:40:34,994 : INFO : EPOCH 1: training on 175599 raw words (110036 effective words) took 0.4s, 269460 effective words/s\n",
      "2023-04-04 13:40:35,412 : INFO : EPOCH 2: training on 175599 raw words (110164 effective words) took 0.4s, 286270 effective words/s\n",
      "2023-04-04 13:40:35,836 : INFO : EPOCH 3: training on 175599 raw words (110259 effective words) took 0.4s, 281440 effective words/s\n",
      "2023-04-04 13:40:36,275 : INFO : EPOCH 4: training on 175599 raw words (110203 effective words) took 0.4s, 274776 effective words/s\n",
      "2023-04-04 13:40:36,279 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550907 effective words) took 2.2s, 251190 effective words/s', 'datetime': '2023-04-04T13:40:36.279304', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:36,281 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:36.281324', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:36,286 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:36,322 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:36,403 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:36,405 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:36,454 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:36.453138', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:36,457 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:36.457142', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:36,517 : INFO : deleting the raw counts dictionary of 17251 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #10: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 2.5346561272939048, 'train_time_std': 0.15934209415004857}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:40:36,521 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:36,524 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:36.523587', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:36,532 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:40:36,820 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:40:36,909 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:40:36,910 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:36,917 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:36.917254', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:36,919 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:36,921 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:36.921180', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:37,323 : INFO : EPOCH 0: training on 175599 raw words (110190 effective words) took 0.4s, 301920 effective words/s\n",
      "2023-04-04 13:40:37,723 : INFO : EPOCH 1: training on 175599 raw words (110122 effective words) took 0.4s, 299394 effective words/s\n",
      "2023-04-04 13:40:38,130 : INFO : EPOCH 2: training on 175599 raw words (110129 effective words) took 0.4s, 293371 effective words/s\n",
      "2023-04-04 13:40:38,534 : INFO : EPOCH 3: training on 175599 raw words (110138 effective words) took 0.4s, 297002 effective words/s\n",
      "2023-04-04 13:40:38,969 : INFO : EPOCH 4: training on 175599 raw words (110179 effective words) took 0.4s, 272269 effective words/s\n",
      "2023-04-04 13:40:38,970 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550758 effective words) took 2.0s, 268974 effective words/s', 'datetime': '2023-04-04T13:40:38.970193', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:38,971 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:38.971195', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:38,976 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:39,005 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:39,080 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:39,081 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:39,129 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:39.129450', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:39,130 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:39.130444', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:39,187 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:39,190 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:39,193 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:39.193534', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:39,199 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:40:39,518 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:40:39,622 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:40:39,624 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:39,632 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:39.632670', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:39,635 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:39,637 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:39.637189', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:40,120 : INFO : EPOCH 0: training on 175599 raw words (110283 effective words) took 0.4s, 251828 effective words/s\n",
      "2023-04-04 13:40:40,518 : INFO : EPOCH 1: training on 175599 raw words (110123 effective words) took 0.4s, 300197 effective words/s\n",
      "2023-04-04 13:40:40,912 : INFO : EPOCH 2: training on 175599 raw words (110244 effective words) took 0.4s, 305786 effective words/s\n",
      "2023-04-04 13:40:41,290 : INFO : EPOCH 3: training on 175599 raw words (110305 effective words) took 0.3s, 317868 effective words/s\n",
      "2023-04-04 13:40:41,675 : INFO : EPOCH 4: training on 175599 raw words (110216 effective words) took 0.4s, 311918 effective words/s\n",
      "2023-04-04 13:40:41,676 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551171 effective words) took 2.0s, 270512 effective words/s', 'datetime': '2023-04-04T13:40:41.676771', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:41,677 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:41.677781', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:41,682 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:41,708 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:41,780 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:41,781 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:41,820 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:41.820344', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:41,822 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:41.822303', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:41,882 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:41,885 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:41,887 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:41.887390', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:41,892 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:40:42,102 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:40:42,171 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:40:42,173 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:42,177 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:42.177749', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:42,178 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:40:42,180 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:42.180776', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:42,634 : INFO : EPOCH 0: training on 175599 raw words (110287 effective words) took 0.4s, 273876 effective words/s\n",
      "2023-04-04 13:40:43,085 : INFO : EPOCH 1: training on 175599 raw words (110288 effective words) took 0.4s, 266021 effective words/s\n",
      "2023-04-04 13:40:43,500 : INFO : EPOCH 2: training on 175599 raw words (110064 effective words) took 0.4s, 291885 effective words/s\n",
      "2023-04-04 13:40:43,922 : INFO : EPOCH 3: training on 175599 raw words (110311 effective words) took 0.4s, 285815 effective words/s\n",
      "2023-04-04 13:40:44,341 : INFO : EPOCH 4: training on 175599 raw words (110151 effective words) took 0.4s, 271180 effective words/s\n",
      "2023-04-04 13:40:44,343 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551101 effective words) took 2.2s, 255290 effective words/s', 'datetime': '2023-04-04T13:40:44.343366', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:44,345 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:44.344385', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:44,352 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:44,392 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:44,473 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:44,475 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:44,534 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:44.534137', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:44,536 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:44.536099', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:44,589 : INFO : deleting the raw counts dictionary of 17251 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #11: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 2.68886391321818, 'train_time_std': 0.014530134089780829}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:40:44,591 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:44,593 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:44.593617', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:44,675 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:40:44,676 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:44,685 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:44.685849', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:44,686 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:44.686849', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:45,325 : INFO : EPOCH 0: training on 175599 raw words (110146 effective words) took 0.6s, 176788 effective words/s\n",
      "2023-04-04 13:40:45,957 : INFO : EPOCH 1: training on 175599 raw words (110065 effective words) took 0.6s, 184410 effective words/s\n",
      "2023-04-04 13:40:46,576 : INFO : EPOCH 2: training on 175599 raw words (110098 effective words) took 0.6s, 188493 effective words/s\n",
      "2023-04-04 13:40:47,189 : INFO : EPOCH 3: training on 175599 raw words (110297 effective words) took 0.6s, 191307 effective words/s\n",
      "2023-04-04 13:40:47,729 : INFO : EPOCH 4: training on 175599 raw words (110151 effective words) took 0.5s, 215971 effective words/s\n",
      "2023-04-04 13:40:47,730 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550757 effective words) took 3.0s, 181041 effective words/s', 'datetime': '2023-04-04T13:40:47.730481', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:47,732 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:47.732000', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:47,736 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:47,764 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:47,837 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:47,838 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:47,879 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:47.879043', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:47,880 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:47.879999', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:47,925 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:47,927 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:47,928 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:47.928870', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:47,985 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:40:47,985 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:47,991 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:47.991114', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:47,992 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:47.992111', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:48,518 : INFO : EPOCH 0: training on 175599 raw words (110284 effective words) took 0.5s, 221549 effective words/s\n",
      "2023-04-04 13:40:49,041 : INFO : EPOCH 1: training on 175599 raw words (110111 effective words) took 0.5s, 223501 effective words/s\n",
      "2023-04-04 13:40:49,613 : INFO : EPOCH 2: training on 175599 raw words (110151 effective words) took 0.5s, 201963 effective words/s\n",
      "2023-04-04 13:40:50,141 : INFO : EPOCH 3: training on 175599 raw words (110154 effective words) took 0.5s, 220728 effective words/s\n",
      "2023-04-04 13:40:50,668 : INFO : EPOCH 4: training on 175599 raw words (110184 effective words) took 0.5s, 220041 effective words/s\n",
      "2023-04-04 13:40:50,669 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550884 effective words) took 2.7s, 205827 effective words/s', 'datetime': '2023-04-04T13:40:50.669581', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:50,672 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:50.672608', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:50,675 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:50,699 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:50,767 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:50,768 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:50,808 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:50.808076', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:50,810 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:50.809092', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:50,865 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:50,866 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:50,869 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:50.869396', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:50,928 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:40:50,929 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:50,934 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:50.934944', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:50,936 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:50.936954', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:51,467 : INFO : EPOCH 0: training on 175599 raw words (110363 effective words) took 0.5s, 219767 effective words/s\n",
      "2023-04-04 13:40:51,989 : INFO : EPOCH 1: training on 175599 raw words (110191 effective words) took 0.5s, 223156 effective words/s\n",
      "2023-04-04 13:40:52,590 : INFO : EPOCH 2: training on 175599 raw words (110368 effective words) took 0.6s, 191962 effective words/s\n",
      "2023-04-04 13:40:53,295 : INFO : EPOCH 3: training on 175599 raw words (110196 effective words) took 0.7s, 164940 effective words/s\n",
      "2023-04-04 13:40:54,009 : INFO : EPOCH 4: training on 175599 raw words (110367 effective words) took 0.7s, 163325 effective words/s\n",
      "2023-04-04 13:40:54,012 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551485 effective words) took 3.1s, 179410 effective words/s', 'datetime': '2023-04-04T13:40:54.012187', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:54,015 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:54.015185', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:54,018 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:54,056 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:54,152 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:54,154 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:54,211 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:54.211371', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #12: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 3.2219104766845703, 'train_time_std': 0.2010461983028164}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:40:54,213 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:54.213362', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:54,292 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:54,295 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:54,296 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:54.296925', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:54,385 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:40:54,388 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:54,397 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:54.397047', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:54,398 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:54.398574', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:55,088 : INFO : EPOCH 0: training on 175599 raw words (110288 effective words) took 0.6s, 170610 effective words/s\n",
      "2023-04-04 13:40:55,781 : INFO : EPOCH 1: training on 175599 raw words (110081 effective words) took 0.7s, 168276 effective words/s\n",
      "2023-04-04 13:40:56,562 : INFO : EPOCH 2: training on 175599 raw words (110053 effective words) took 0.7s, 147783 effective words/s\n",
      "2023-04-04 13:40:57,233 : INFO : EPOCH 3: training on 175599 raw words (110429 effective words) took 0.6s, 174601 effective words/s\n",
      "2023-04-04 13:40:57,789 : INFO : EPOCH 4: training on 175599 raw words (110230 effective words) took 0.5s, 210271 effective words/s\n",
      "2023-04-04 13:40:57,790 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551081 effective words) took 3.4s, 162482 effective words/s', 'datetime': '2023-04-04T13:40:57.790794', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:57,792 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:40:57.791802', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:40:57,794 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:40:57,823 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:40:57,890 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:40:57,892 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:40:57,934 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:40:57.934747', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:57,935 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:40:57.935759', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:57,983 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:40:57,986 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:40:57,988 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:40:57.988526', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:40:58,097 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:40:58,099 : INFO : resetting layer weights\n",
      "2023-04-04 13:40:58,108 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:40:58.108244', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:40:58,110 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:40:58.110241', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:40:58,769 : INFO : EPOCH 0: training on 175599 raw words (110190 effective words) took 0.6s, 179021 effective words/s\n",
      "2023-04-04 13:40:59,292 : INFO : EPOCH 1: training on 175599 raw words (110125 effective words) took 0.5s, 224442 effective words/s\n",
      "2023-04-04 13:40:59,835 : INFO : EPOCH 2: training on 175599 raw words (110137 effective words) took 0.5s, 216085 effective words/s\n",
      "2023-04-04 13:41:00,388 : INFO : EPOCH 3: training on 175599 raw words (110278 effective words) took 0.5s, 209642 effective words/s\n",
      "2023-04-04 13:41:00,905 : INFO : EPOCH 4: training on 175599 raw words (110164 effective words) took 0.5s, 225146 effective words/s\n",
      "2023-04-04 13:41:00,906 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550894 effective words) took 2.8s, 197159 effective words/s', 'datetime': '2023-04-04T13:41:00.906101', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:00,907 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:41:00.907126', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:41:00,911 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:41:00,937 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:41:00,989 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:41:00,992 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:41:01,029 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:41:01.029079', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:01,033 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:41:01.033114', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:01,079 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:41:01,081 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:41:01,083 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:41:01.083848', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:01,140 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2023-04-04 13:41:01,142 : INFO : resetting layer weights\n",
      "2023-04-04 13:41:01,147 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:41:01.147050', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:41:01,148 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:41:01.148579', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:01,680 : INFO : EPOCH 0: training on 175599 raw words (110344 effective words) took 0.5s, 219176 effective words/s\n",
      "2023-04-04 13:41:02,211 : INFO : EPOCH 1: training on 175599 raw words (110067 effective words) took 0.5s, 221976 effective words/s\n",
      "2023-04-04 13:41:03,030 : INFO : EPOCH 2: training on 175599 raw words (109913 effective words) took 0.7s, 159784 effective words/s\n",
      "2023-04-04 13:41:03,735 : INFO : EPOCH 3: training on 175599 raw words (110213 effective words) took 0.7s, 166667 effective words/s\n",
      "2023-04-04 13:41:04,414 : INFO : EPOCH 4: training on 175599 raw words (110254 effective words) took 0.6s, 171370 effective words/s\n",
      "2023-04-04 13:41:04,415 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550791 effective words) took 3.3s, 168666 effective words/s', 'datetime': '2023-04-04T13:41:04.415945', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:04,416 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:41:04.416943', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:41:04,420 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:41:04,454 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:41:04,552 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:41:04,554 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:41:04,603 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:41:04.603868', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #13: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 3.4671924908955893, 'train_time_std': 0.2715605549303989}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:41:04,605 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:41:04.605795', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:04,687 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:41:04,690 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:41:04,693 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:41:04.693687', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:04,700 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:41:04,944 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:41:05,027 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:41:05,028 : INFO : resetting layer weights\n",
      "2023-04-04 13:41:05,033 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:41:05.033913', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:41:05,033 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:41:05,034 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:41:05.034914', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:06,218 : INFO : EPOCH 0 - PROGRESS: at 72.22% examples, 71870 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:06,448 : INFO : EPOCH 0: training on 175599 raw words (110404 effective words) took 1.4s, 80566 effective words/s\n",
      "2023-04-04 13:41:07,560 : INFO : EPOCH 1 - PROGRESS: at 72.22% examples, 75792 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:07,770 : INFO : EPOCH 1: training on 175599 raw words (110004 effective words) took 1.3s, 85379 effective words/s\n",
      "2023-04-04 13:41:08,808 : INFO : EPOCH 2 - PROGRESS: at 83.33% examples, 93003 words/s, in_qsize 3, out_qsize 0\n",
      "2023-04-04 13:41:08,998 : INFO : EPOCH 2: training on 175599 raw words (110011 effective words) took 1.2s, 91442 effective words/s\n",
      "2023-04-04 13:41:10,120 : INFO : EPOCH 3 - PROGRESS: at 72.22% examples, 74960 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:10,313 : INFO : EPOCH 3: training on 175599 raw words (110220 effective words) took 1.3s, 85832 effective words/s\n",
      "2023-04-04 13:41:11,409 : INFO : EPOCH 4 - PROGRESS: at 72.22% examples, 76730 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:11,604 : INFO : EPOCH 4: training on 175599 raw words (110434 effective words) took 1.3s, 87496 effective words/s\n",
      "2023-04-04 13:41:11,606 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551073 effective words) took 6.6s, 83886 effective words/s', 'datetime': '2023-04-04T13:41:11.606085', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:11,607 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:41:11.607082', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:41:11,611 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:41:11,650 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:41:11,726 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:41:11,728 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:41:11,773 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:41:11.773198', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:11,775 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:41:11.774201', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:11,827 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:41:11,829 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:41:11,832 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:41:11.832031', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:11,839 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:41:12,084 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:41:12,157 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:41:12,159 : INFO : resetting layer weights\n",
      "2023-04-04 13:41:12,168 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:41:12.168218', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:41:12,169 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:41:12,171 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:41:12.171186', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:13,192 : INFO : EPOCH 0 - PROGRESS: at 55.56% examples, 62678 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:13,688 : INFO : EPOCH 0: training on 175599 raw words (110363 effective words) took 1.5s, 73337 effective words/s\n",
      "2023-04-04 13:41:14,825 : INFO : EPOCH 1 - PROGRESS: at 72.22% examples, 74392 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:15,067 : INFO : EPOCH 1: training on 175599 raw words (110156 effective words) took 1.3s, 82086 effective words/s\n",
      "2023-04-04 13:41:16,205 : INFO : EPOCH 2 - PROGRESS: at 72.22% examples, 74178 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:41:16,405 : INFO : EPOCH 2: training on 175599 raw words (110194 effective words) took 1.3s, 84429 effective words/s\n",
      "2023-04-04 13:41:17,551 : INFO : EPOCH 3 - PROGRESS: at 72.22% examples, 73949 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:17,726 : INFO : EPOCH 3: training on 175599 raw words (110152 effective words) took 1.3s, 86057 effective words/s\n",
      "2023-04-04 13:41:18,765 : INFO : EPOCH 4 - PROGRESS: at 77.78% examples, 87114 words/s, in_qsize 3, out_qsize 1\n",
      "2023-04-04 13:41:18,928 : INFO : EPOCH 4: training on 175599 raw words (110370 effective words) took 1.2s, 93852 effective words/s\n",
      "2023-04-04 13:41:18,930 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551235 effective words) took 6.8s, 81581 effective words/s', 'datetime': '2023-04-04T13:41:18.930398', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:18,931 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:41:18.931399', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:41:18,935 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:41:18,959 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:41:19,031 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:41:19,032 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:41:19,070 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:41:19.070544', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:19,071 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:41:19.071508', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:19,109 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:41:19,110 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:41:19,112 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:41:19.112845', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:19,117 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:41:19,296 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:41:19,352 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:41:19,353 : INFO : resetting layer weights\n",
      "2023-04-04 13:41:19,359 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:41:19.359824', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:41:19,359 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:41:19,360 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:41:19.360782', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:20,493 : INFO : EPOCH 0 - PROGRESS: at 88.89% examples, 89203 words/s, in_qsize 2, out_qsize 1\n",
      "2023-04-04 13:41:20,548 : INFO : EPOCH 0: training on 175599 raw words (110521 effective words) took 1.2s, 95825 effective words/s\n",
      "2023-04-04 13:41:21,595 : INFO : EPOCH 1 - PROGRESS: at 77.78% examples, 86315 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:41:21,764 : INFO : EPOCH 1: training on 175599 raw words (110334 effective words) took 1.2s, 92702 effective words/s\n",
      "2023-04-04 13:41:22,826 : INFO : EPOCH 2 - PROGRESS: at 77.78% examples, 85100 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:41:23,033 : INFO : EPOCH 2: training on 175599 raw words (110259 effective words) took 1.2s, 88750 effective words/s\n",
      "2023-04-04 13:41:24,153 : INFO : EPOCH 3 - PROGRESS: at 72.22% examples, 75873 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:24,404 : INFO : EPOCH 3: training on 175599 raw words (110269 effective words) took 1.3s, 82805 effective words/s\n",
      "2023-04-04 13:41:25,453 : INFO : EPOCH 4 - PROGRESS: at 61.11% examples, 68159 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:41:26,268 : INFO : EPOCH 4: training on 175599 raw words (110216 effective words) took 1.8s, 60292 effective words/s\n",
      "2023-04-04 13:41:26,271 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551599 effective words) took 6.9s, 79833 effective words/s', 'datetime': '2023-04-04T13:41:26.271820', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:26,274 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:41:26.274818', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:41:26,284 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:41:26,318 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:41:26,423 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:41:26,425 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:41:26,495 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:41:26.495315', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #14: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 7.286693255106608, 'train_time_std': 0.06879217709999681}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:41:26,500 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:41:26.500915', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:26,594 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:41:26,596 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:41:26,598 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:41:26.598248', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:26,610 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:41:27,143 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:41:27,406 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:41:27,407 : INFO : resetting layer weights\n",
      "2023-04-04 13:41:27,417 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:41:27.417169', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:41:27,419 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:41:27,421 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:41:27.421206', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:28,744 : INFO : EPOCH 0 - PROGRESS: at 55.56% examples, 52548 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:29,374 : INFO : EPOCH 0: training on 175599 raw words (110344 effective words) took 1.8s, 60160 effective words/s\n",
      "2023-04-04 13:41:30,583 : INFO : EPOCH 1 - PROGRESS: at 55.56% examples, 54243 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:41:31,155 : INFO : EPOCH 1: training on 175599 raw words (110172 effective words) took 1.7s, 63488 effective words/s\n",
      "2023-04-04 13:41:32,238 : INFO : EPOCH 2 - PROGRESS: at 55.56% examples, 61040 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:32,810 : INFO : EPOCH 2: training on 175599 raw words (110179 effective words) took 1.6s, 68596 effective words/s\n",
      "2023-04-04 13:41:33,860 : INFO : EPOCH 3 - PROGRESS: at 55.56% examples, 62056 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:41:34,362 : INFO : EPOCH 3: training on 175599 raw words (110154 effective words) took 1.5s, 72448 effective words/s\n",
      "2023-04-04 13:41:35,423 : INFO : EPOCH 4 - PROGRESS: at 55.56% examples, 61815 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:35,922 : INFO : EPOCH 4: training on 175599 raw words (110234 effective words) took 1.5s, 72457 effective words/s\n",
      "2023-04-04 13:41:35,925 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551083 effective words) took 8.5s, 64821 effective words/s', 'datetime': '2023-04-04T13:41:35.925274', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:35,926 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:41:35.926792', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:41:35,930 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:41:35,956 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:41:36,066 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:41:36,067 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:41:36,139 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:41:36.139256', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:36,140 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:41:36.140236', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:36,198 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:41:36,200 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:41:36,202 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:41:36.201731', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:36,211 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:41:36,497 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:41:36,592 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:41:36,594 : INFO : resetting layer weights\n",
      "2023-04-04 13:41:36,599 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:41:36.599945', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:41:36,600 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:41:36,602 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:41:36.602943', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:37,751 : INFO : EPOCH 0 - PROGRESS: at 55.56% examples, 57921 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:41:38,234 : INFO : EPOCH 0: training on 175599 raw words (110185 effective words) took 1.6s, 69990 effective words/s\n",
      "2023-04-04 13:41:39,309 : INFO : EPOCH 1 - PROGRESS: at 55.56% examples, 60603 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:40,013 : INFO : EPOCH 1: training on 175599 raw words (110243 effective words) took 1.7s, 63080 effective words/s\n",
      "2023-04-04 13:41:41,174 : INFO : EPOCH 2 - PROGRESS: at 55.56% examples, 56097 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:41,789 : INFO : EPOCH 2: training on 175599 raw words (110112 effective words) took 1.7s, 63282 effective words/s\n",
      "2023-04-04 13:41:43,071 : INFO : EPOCH 3 - PROGRESS: at 55.56% examples, 51619 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:43,631 : INFO : EPOCH 3: training on 175599 raw words (110157 effective words) took 1.8s, 61891 effective words/s\n",
      "2023-04-04 13:41:44,718 : INFO : EPOCH 4 - PROGRESS: at 50.00% examples, 54431 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:41:45,529 : INFO : EPOCH 4: training on 175599 raw words (110065 effective words) took 1.9s, 59276 effective words/s\n",
      "2023-04-04 13:41:45,531 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550762 effective words) took 8.9s, 61713 effective words/s', 'datetime': '2023-04-04T13:41:45.531276', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:45,533 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:41:45.533272', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:41:45,540 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:41:45,600 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:41:45,706 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2023-04-04 13:41:45,711 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:41:45,773 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91% of original 17251, drops 13126)', 'datetime': '2023-04-04T13:41:45.772307', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:45,774 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81% of original 175599, drops 21398)', 'datetime': '2023-04-04T13:41:45.774300', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:45,850 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2023-04-04 13:41:45,863 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-04-04 13:41:45,866 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2023-04-04T13:41:45.866027', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:45,872 : INFO : constructing a huffman tree from 4125 words\n",
      "2023-04-04 13:41:46,293 : INFO : built huffman tree with maximum node depth 15\n",
      "2023-04-04 13:41:46,405 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2023-04-04 13:41:46,407 : INFO : resetting layer weights\n",
      "2023-04-04 13:41:46,418 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:41:46.417954', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:41:46,420 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:41:46,421 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:41:46.421949', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:47,660 : INFO : EPOCH 0 - PROGRESS: at 55.56% examples, 53053 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:41:48,175 : INFO : EPOCH 0: training on 175599 raw words (110247 effective words) took 1.7s, 64586 effective words/s\n",
      "2023-04-04 13:41:49,210 : INFO : EPOCH 1 - PROGRESS: at 55.56% examples, 62961 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:49,704 : INFO : EPOCH 1: training on 175599 raw words (110237 effective words) took 1.5s, 73597 effective words/s\n",
      "2023-04-04 13:41:50,745 : INFO : EPOCH 2 - PROGRESS: at 61.11% examples, 68696 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:51,233 : INFO : EPOCH 2: training on 175599 raw words (110257 effective words) took 1.5s, 73715 effective words/s\n",
      "2023-04-04 13:41:52,478 : INFO : EPOCH 3 - PROGRESS: at 72.22% examples, 67727 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:52,724 : INFO : EPOCH 3: training on 175599 raw words (109966 effective words) took 1.5s, 75734 effective words/s\n",
      "2023-04-04 13:41:53,773 : INFO : EPOCH 4 - PROGRESS: at 61.11% examples, 68307 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:54,237 : INFO : EPOCH 4: training on 175599 raw words (110247 effective words) took 1.5s, 74668 effective words/s\n",
      "2023-04-04 13:41:54,239 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550954 effective words) took 7.8s, 70496 effective words/s', 'datetime': '2023-04-04T13:41:54.239360', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:54,241 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4125, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:41:54.241360', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:41:54,246 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #15: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 9.320667266845703, 'train_time_std': 0.43521996591898127}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:41:54,826 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:41:55,523 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:41:55,524 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:41:55,737 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:41:55.737829', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:55,738 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:41:55.738855', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:55,957 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:41:55,961 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:41:55,963 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:41:55.963000', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:41:56,283 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:41:56,285 : INFO : resetting layer weights\n",
      "2023-04-04 13:41:56,305 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:41:56.305826', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:41:56,308 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:41:56.308363', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:41:57,399 : INFO : EPOCH 0 - PROGRESS: at 31.84% examples, 391717 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:41:58,418 : INFO : EPOCH 0 - PROGRESS: at 74.30% examples, 452176 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:41:59,074 : INFO : EPOCH 0: training on 1788017 raw words (1242348 effective words) took 2.7s, 459887 effective words/s\n",
      "2023-04-04 13:42:00,147 : INFO : EPOCH 1 - PROGRESS: at 29.61% examples, 373307 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:42:01,155 : INFO : EPOCH 1 - PROGRESS: at 70.95% examples, 438050 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:01,871 : INFO : EPOCH 1: training on 1788017 raw words (1242809 effective words) took 2.7s, 455401 effective words/s\n",
      "2023-04-04 13:42:02,949 : INFO : EPOCH 2 - PROGRESS: at 30.17% examples, 376311 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:03,951 : INFO : EPOCH 2 - PROGRESS: at 59.78% examples, 369310 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:04,985 : INFO : EPOCH 2 - PROGRESS: at 96.09% examples, 392001 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:05,110 : INFO : EPOCH 2: training on 1788017 raw words (1242371 effective words) took 3.2s, 391367 effective words/s\n",
      "2023-04-04 13:42:06,241 : INFO : EPOCH 3 - PROGRESS: at 19.55% examples, 237214 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:07,242 : INFO : EPOCH 3 - PROGRESS: at 56.42% examples, 344106 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:08,281 : INFO : EPOCH 3 - PROGRESS: at 94.97% examples, 382959 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:42:08,409 : INFO : EPOCH 3: training on 1788017 raw words (1241964 effective words) took 3.2s, 386639 effective words/s\n",
      "2023-04-04 13:42:09,486 : INFO : EPOCH 4 - PROGRESS: at 35.75% examples, 446410 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:42:10,486 : INFO : EPOCH 4 - PROGRESS: at 84.92% examples, 525896 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:10,851 : INFO : EPOCH 4: training on 1788017 raw words (1242759 effective words) took 2.4s, 523647 effective words/s\n",
      "2023-04-04 13:42:10,852 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212251 effective words) took 14.5s, 427160 effective words/s', 'datetime': '2023-04-04T13:42:10.852673', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:42:10,853 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:42:10.853668', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:42:10,859 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:42:11,140 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:42:11,853 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:42:11,855 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:42:12,027 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:42:12.027613', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:42:12,028 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:42:12.028684', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:42:12,264 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:42:12,270 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:42:12,272 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:42:12.272021', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:42:12,558 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:42:12,559 : INFO : resetting layer weights\n",
      "2023-04-04 13:42:12,575 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:42:12.575263', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:42:12,576 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:42:12.576863', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:42:13,650 : INFO : EPOCH 0 - PROGRESS: at 24.02% examples, 300046 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:14,671 : INFO : EPOCH 0 - PROGRESS: at 59.22% examples, 361929 words/s, in_qsize 5, out_qsize 2\n",
      "2023-04-04 13:42:15,707 : INFO : EPOCH 0 - PROGRESS: at 91.06% examples, 368678 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:16,019 : INFO : EPOCH 0: training on 1788017 raw words (1242170 effective words) took 3.4s, 366935 effective words/s\n",
      "2023-04-04 13:42:17,126 : INFO : EPOCH 1 - PROGRESS: at 21.23% examples, 262675 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:18,144 : INFO : EPOCH 1 - PROGRESS: at 48.04% examples, 295119 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:19,147 : INFO : EPOCH 1 - PROGRESS: at 91.06% examples, 372087 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:19,377 : INFO : EPOCH 1: training on 1788017 raw words (1242575 effective words) took 3.3s, 379329 effective words/s\n",
      "2023-04-04 13:42:20,459 : INFO : EPOCH 2 - PROGRESS: at 31.84% examples, 393922 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:21,479 : INFO : EPOCH 2 - PROGRESS: at 80.45% examples, 490713 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:42:21,917 : INFO : EPOCH 2: training on 1788017 raw words (1242161 effective words) took 2.5s, 501335 effective words/s\n",
      "2023-04-04 13:42:22,974 : INFO : EPOCH 3 - PROGRESS: at 37.43% examples, 468245 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:23,995 : INFO : EPOCH 3 - PROGRESS: at 76.54% examples, 470242 words/s, in_qsize 6, out_qsize 2\n",
      "2023-04-04 13:42:24,693 : INFO : EPOCH 3: training on 1788017 raw words (1243085 effective words) took 2.7s, 456135 effective words/s\n",
      "2023-04-04 13:42:25,784 : INFO : EPOCH 4 - PROGRESS: at 27.93% examples, 346823 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:42:26,790 : INFO : EPOCH 4 - PROGRESS: at 68.16% examples, 417658 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:42:27,619 : INFO : EPOCH 4: training on 1788017 raw words (1242978 effective words) took 2.9s, 435094 effective words/s\n",
      "2023-04-04 13:42:27,621 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212969 effective words) took 15.0s, 413063 effective words/s', 'datetime': '2023-04-04T13:42:27.621924', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:42:27,623 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:42:27.623948', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:42:27,633 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:42:27,985 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:42:28,791 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:42:28,793 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:42:29,047 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:42:29.047981', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:42:29,049 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:42:29.049986', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:42:29,353 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:42:29,358 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:42:29,362 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:42:29.362865', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:42:29,787 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:42:29,789 : INFO : resetting layer weights\n",
      "2023-04-04 13:42:29,814 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:42:29.814030', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:42:29,816 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:42:29.816510', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:42:30,900 : INFO : EPOCH 0 - PROGRESS: at 30.73% examples, 381253 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:31,903 : INFO : EPOCH 0 - PROGRESS: at 72.63% examples, 447250 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:32,588 : INFO : EPOCH 0: training on 1788017 raw words (1242883 effective words) took 2.7s, 459431 effective words/s\n",
      "2023-04-04 13:42:33,664 : INFO : EPOCH 1 - PROGRESS: at 28.49% examples, 358707 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:34,665 : INFO : EPOCH 1 - PROGRESS: at 62.57% examples, 387227 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:35,665 : INFO : EPOCH 1 - PROGRESS: at 97.77% examples, 404275 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:42:35,718 : INFO : EPOCH 1: training on 1788017 raw words (1242450 effective words) took 3.1s, 405884 effective words/s\n",
      "2023-04-04 13:42:36,816 : INFO : EPOCH 2 - PROGRESS: at 25.70% examples, 318480 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:37,821 : INFO : EPOCH 2 - PROGRESS: at 64.25% examples, 393497 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:38,726 : INFO : EPOCH 2: training on 1788017 raw words (1242123 effective words) took 2.9s, 423462 effective words/s\n",
      "2023-04-04 13:42:39,799 : INFO : EPOCH 3 - PROGRESS: at 33.52% examples, 418257 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:40,799 : INFO : EPOCH 3 - PROGRESS: at 77.65% examples, 480619 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:41,310 : INFO : EPOCH 3: training on 1788017 raw words (1241918 effective words) took 2.5s, 492732 effective words/s\n",
      "2023-04-04 13:42:42,373 : INFO : EPOCH 4 - PROGRESS: at 35.75% examples, 448801 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:43,386 : INFO : EPOCH 4 - PROGRESS: at 83.80% examples, 517118 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:43,855 : INFO : EPOCH 4: training on 1788017 raw words (1242211 effective words) took 2.5s, 500162 effective words/s\n",
      "2023-04-04 13:42:43,856 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211585 effective words) took 14.0s, 442489 effective words/s', 'datetime': '2023-04-04T13:42:43.856449', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:42:43,856 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:42:43.856968', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:42:43,870 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:42:44,245 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #16: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 16.541062513987224, 'train_time_std': 0.22554318021683137}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:42:45,543 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:42:45,545 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:42:45,852 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:42:45.852965', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:42:45,854 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:42:45.854970', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:42:46,207 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:42:46,221 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:42:46,222 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:42:46.222520', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:42:46,750 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:42:46,752 : INFO : resetting layer weights\n",
      "2023-04-04 13:42:46,783 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:42:46.783137', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:42:46,785 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:42:46.785134', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:42:47,900 : INFO : EPOCH 0 - PROGRESS: at 19.55% examples, 245164 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:48,901 : INFO : EPOCH 0 - PROGRESS: at 54.19% examples, 336315 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:42:49,922 : INFO : EPOCH 0 - PROGRESS: at 94.97% examples, 389453 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:50,053 : INFO : EPOCH 0: training on 1788017 raw words (1242662 effective words) took 3.2s, 392563 effective words/s\n",
      "2023-04-04 13:42:51,314 : INFO : EPOCH 1 - PROGRESS: at 31.28% examples, 385553 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:52,352 : INFO : EPOCH 1 - PROGRESS: at 78.21% examples, 472401 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:52,886 : INFO : EPOCH 1: training on 1788017 raw words (1242319 effective words) took 2.6s, 478783 effective words/s\n",
      "2023-04-04 13:42:53,962 : INFO : EPOCH 2 - PROGRESS: at 32.40% examples, 407740 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:54,974 : INFO : EPOCH 2 - PROGRESS: at 59.22% examples, 365937 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:55,988 : INFO : EPOCH 2 - PROGRESS: at 94.41% examples, 387652 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:56,209 : INFO : EPOCH 2: training on 1788017 raw words (1242179 effective words) took 3.2s, 382229 effective words/s\n",
      "2023-04-04 13:42:57,289 : INFO : EPOCH 3 - PROGRESS: at 22.91% examples, 289821 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:58,322 : INFO : EPOCH 3 - PROGRESS: at 60.89% examples, 372095 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:42:59,258 : INFO : EPOCH 3: training on 1788017 raw words (1242135 effective words) took 3.0s, 418097 effective words/s\n",
      "2023-04-04 13:43:00,337 : INFO : EPOCH 4 - PROGRESS: at 34.08% examples, 423370 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:43:01,341 : INFO : EPOCH 4 - PROGRESS: at 75.42% examples, 464891 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:01,976 : INFO : EPOCH 4: training on 1788017 raw words (1241873 effective words) took 2.7s, 468193 effective words/s\n",
      "2023-04-04 13:43:01,978 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211168 effective words) took 15.2s, 408837 effective words/s', 'datetime': '2023-04-04T13:43:01.978569', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:43:01,979 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:43:01.979558', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:43:01,986 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:43:02,334 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:43:03,223 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:43:03,224 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:43:03,479 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:43:03.478784', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:43:03,480 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:43:03.480763', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:43:03,830 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:43:03,836 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:43:03,840 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:43:03.840505', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:43:04,325 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:43:04,326 : INFO : resetting layer weights\n",
      "2023-04-04 13:43:04,352 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:43:04.352444', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:43:04,354 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:43:04.354458', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:43:05,451 : INFO : EPOCH 0 - PROGRESS: at 22.91% examples, 287172 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:06,458 : INFO : EPOCH 0 - PROGRESS: at 57.54% examples, 355171 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:07,524 : INFO : EPOCH 0 - PROGRESS: at 94.97% examples, 382541 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:43:07,664 : INFO : EPOCH 0: training on 1788017 raw words (1241847 effective words) took 3.2s, 384897 effective words/s\n",
      "2023-04-04 13:43:08,799 : INFO : EPOCH 1 - PROGRESS: at 27.93% examples, 339115 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:09,801 : INFO : EPOCH 1 - PROGRESS: at 69.27% examples, 420728 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:10,456 : INFO : EPOCH 1: training on 1788017 raw words (1242187 effective words) took 2.7s, 460055 effective words/s\n",
      "2023-04-04 13:43:11,516 : INFO : EPOCH 2 - PROGRESS: at 33.52% examples, 420674 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:12,517 : INFO : EPOCH 2 - PROGRESS: at 82.12% examples, 509477 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:12,907 : INFO : EPOCH 2: training on 1788017 raw words (1242362 effective words) took 2.4s, 518680 effective words/s\n",
      "2023-04-04 13:43:13,969 : INFO : EPOCH 3 - PROGRESS: at 35.20% examples, 439043 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:14,978 : INFO : EPOCH 3 - PROGRESS: at 75.42% examples, 464619 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:15,640 : INFO : EPOCH 3: training on 1788017 raw words (1241393 effective words) took 2.7s, 463256 effective words/s\n",
      "2023-04-04 13:43:16,738 : INFO : EPOCH 4 - PROGRESS: at 27.37% examples, 336529 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:43:17,744 : INFO : EPOCH 4 - PROGRESS: at 61.45% examples, 375014 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:18,795 : INFO : EPOCH 4 - PROGRESS: at 94.41% examples, 380296 words/s, in_qsize 5, out_qsize 1\n",
      "2023-04-04 13:43:18,915 : INFO : EPOCH 4: training on 1788017 raw words (1242578 effective words) took 3.2s, 387258 effective words/s\n",
      "2023-04-04 13:43:18,917 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210367 effective words) took 14.6s, 426523 effective words/s', 'datetime': '2023-04-04T13:43:18.917121', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:43:18,920 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:43:18.920139', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:43:18,930 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:43:19,274 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:43:20,129 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:43:20,130 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:43:20,368 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:43:20.368343', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:43:20,372 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:43:20.372321', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:43:20,661 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:43:20,666 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:43:20,670 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:43:20.669574', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:43:21,088 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:43:21,090 : INFO : resetting layer weights\n",
      "2023-04-04 13:43:21,111 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:43:21.111324', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:43:21,112 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:43:21.112326', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:43:22,188 : INFO : EPOCH 0 - PROGRESS: at 32.96% examples, 411752 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:23,189 : INFO : EPOCH 0 - PROGRESS: at 81.01% examples, 501632 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:23,807 : INFO : EPOCH 0: training on 1788017 raw words (1242130 effective words) took 2.6s, 472825 effective words/s\n",
      "2023-04-04 13:43:24,896 : INFO : EPOCH 1 - PROGRESS: at 27.37% examples, 341680 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:25,920 : INFO : EPOCH 1 - PROGRESS: at 60.34% examples, 367997 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:43:26,953 : INFO : EPOCH 1 - PROGRESS: at 93.85% examples, 379702 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:43:27,366 : INFO : EPOCH 1: training on 1788017 raw words (1241572 effective words) took 3.5s, 356301 effective words/s\n",
      "2023-04-04 13:43:28,451 : INFO : EPOCH 2 - PROGRESS: at 27.37% examples, 340809 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:43:29,464 : INFO : EPOCH 2 - PROGRESS: at 72.07% examples, 441064 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:43:30,057 : INFO : EPOCH 2: training on 1788017 raw words (1242576 effective words) took 2.6s, 473551 effective words/s\n",
      "2023-04-04 13:43:31,118 : INFO : EPOCH 3 - PROGRESS: at 39.11% examples, 490668 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:32,127 : INFO : EPOCH 3 - PROGRESS: at 87.71% examples, 542250 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:32,401 : INFO : EPOCH 3: training on 1788017 raw words (1242704 effective words) took 2.3s, 543076 effective words/s\n",
      "2023-04-04 13:43:33,470 : INFO : EPOCH 4 - PROGRESS: at 32.96% examples, 407288 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:34,488 : INFO : EPOCH 4 - PROGRESS: at 73.18% examples, 446578 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:35,380 : INFO : EPOCH 4: training on 1788017 raw words (1242365 effective words) took 2.9s, 424169 effective words/s\n",
      "2023-04-04 13:43:35,381 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211347 effective words) took 14.3s, 435337 effective words/s', 'datetime': '2023-04-04T13:43:35.381646', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:43:35,382 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:43:35.382636', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:43:35,399 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:43:35,816 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #17: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 17.175948063532513, 'train_time_std': 0.69259191625874}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:43:37,079 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:43:37,081 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:43:37,611 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:43:37.611457', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:43:37,612 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:43:37.612455', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:43:37,979 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:43:37,990 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:43:37,993 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:43:37.993445', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:43:38,030 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 13:43:39,785 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 13:43:40,076 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 13:43:40,077 : INFO : resetting layer weights\n",
      "2023-04-04 13:43:40,096 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:43:40.096341', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:43:40,098 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:43:40,101 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:43:40.101915', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:43:41,178 : INFO : EPOCH 0 - PROGRESS: at 16.76% examples, 211058 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:42,194 : INFO : EPOCH 0 - PROGRESS: at 36.87% examples, 229122 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:43,218 : INFO : EPOCH 0 - PROGRESS: at 58.10% examples, 237356 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:44,256 : INFO : EPOCH 0 - PROGRESS: at 78.77% examples, 239797 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:43:45,263 : INFO : EPOCH 0 - PROGRESS: at 93.30% examples, 227741 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:43:45,807 : INFO : EPOCH 0: training on 1788017 raw words (1242232 effective words) took 5.6s, 220284 effective words/s\n",
      "2023-04-04 13:43:46,993 : INFO : EPOCH 1 - PROGRESS: at 9.50% examples, 110455 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:43:48,013 : INFO : EPOCH 1 - PROGRESS: at 24.02% examples, 143692 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:43:49,036 : INFO : EPOCH 1 - PROGRESS: at 40.78% examples, 163376 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:50,098 : INFO : EPOCH 1 - PROGRESS: at 60.34% examples, 178311 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:51,106 : INFO : EPOCH 1 - PROGRESS: at 76.54% examples, 182727 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:52,113 : INFO : EPOCH 1 - PROGRESS: at 94.41% examples, 188734 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:43:52,438 : INFO : EPOCH 1: training on 1788017 raw words (1242400 effective words) took 6.5s, 189814 effective words/s\n",
      "2023-04-04 13:43:53,529 : INFO : EPOCH 2 - PROGRESS: at 12.85% examples, 158673 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:43:54,614 : INFO : EPOCH 2 - PROGRESS: at 31.28% examples, 186415 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:43:55,657 : INFO : EPOCH 2 - PROGRESS: at 46.93% examples, 186364 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:43:56,666 : INFO : EPOCH 2 - PROGRESS: at 63.69% examples, 189866 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:43:57,733 : INFO : EPOCH 2 - PROGRESS: at 82.12% examples, 195059 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:43:58,767 : INFO : EPOCH 2 - PROGRESS: at 99.44% examples, 197269 words/s, in_qsize 1, out_qsize 1\n",
      "2023-04-04 13:43:58,770 : INFO : EPOCH 2: training on 1788017 raw words (1241956 effective words) took 6.3s, 198036 effective words/s\n",
      "2023-04-04 13:43:59,882 : INFO : EPOCH 3 - PROGRESS: at 13.97% examples, 171674 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:00,910 : INFO : EPOCH 3 - PROGRESS: at 36.31% examples, 221605 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:01,943 : INFO : EPOCH 3 - PROGRESS: at 57.54% examples, 231731 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:44:02,949 : INFO : EPOCH 3 - PROGRESS: at 77.09% examples, 234089 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:04,002 : INFO : EPOCH 3 - PROGRESS: at 97.77% examples, 236018 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:44:04,075 : INFO : EPOCH 3: training on 1788017 raw words (1242224 effective words) took 5.2s, 237727 effective words/s\n",
      "2023-04-04 13:44:05,178 : INFO : EPOCH 4 - PROGRESS: at 11.17% examples, 136561 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:44:06,197 : INFO : EPOCH 4 - PROGRESS: at 26.26% examples, 161208 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:07,208 : INFO : EPOCH 4 - PROGRESS: at 43.02% examples, 175760 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:08,214 : INFO : EPOCH 4 - PROGRESS: at 59.22% examples, 180701 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:09,227 : INFO : EPOCH 4 - PROGRESS: at 75.42% examples, 184228 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:10,253 : INFO : EPOCH 4 - PROGRESS: at 93.85% examples, 190715 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:10,719 : INFO : EPOCH 4: training on 1788017 raw words (1242224 effective words) took 6.6s, 188604 effective words/s\n",
      "2023-04-04 13:44:10,720 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211036 effective words) took 30.6s, 202862 effective words/s', 'datetime': '2023-04-04T13:44:10.720508', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:44:10,722 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:44:10.722021', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:44:10,729 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:44:11,018 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:44:11,849 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:44:11,851 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:44:12,024 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:44:12.024255', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:44:12,025 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:44:12.025256', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:44:12,234 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:44:12,241 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:44:12,242 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:44:12.242001', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:44:12,257 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 13:44:13,224 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 13:44:13,523 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 13:44:13,525 : INFO : resetting layer weights\n",
      "2023-04-04 13:44:13,546 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:44:13.546293', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:44:13,547 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:44:13,549 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:44:13.549881', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:44:14,645 : INFO : EPOCH 0 - PROGRESS: at 15.08% examples, 184754 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:15,661 : INFO : EPOCH 0 - PROGRESS: at 34.08% examples, 209228 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:16,687 : INFO : EPOCH 0 - PROGRESS: at 51.96% examples, 211365 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:17,702 : INFO : EPOCH 0 - PROGRESS: at 70.95% examples, 215323 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:18,722 : INFO : EPOCH 0 - PROGRESS: at 85.47% examples, 207762 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:19,535 : INFO : EPOCH 0: training on 1788017 raw words (1241600 effective words) took 5.9s, 209526 effective words/s\n",
      "2023-04-04 13:44:20,644 : INFO : EPOCH 1 - PROGRESS: at 15.08% examples, 182387 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:21,678 : INFO : EPOCH 1 - PROGRESS: at 32.96% examples, 199669 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:22,688 : INFO : EPOCH 1 - PROGRESS: at 50.28% examples, 203772 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:23,728 : INFO : EPOCH 1 - PROGRESS: at 69.27% examples, 208259 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:24,744 : INFO : EPOCH 1 - PROGRESS: at 87.71% examples, 211972 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:25,620 : INFO : EPOCH 1: training on 1788017 raw words (1242645 effective words) took 6.0s, 206243 effective words/s\n",
      "2023-04-04 13:44:26,704 : INFO : EPOCH 2 - PROGRESS: at 9.50% examples, 121156 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:27,770 : INFO : EPOCH 2 - PROGRESS: at 25.70% examples, 157392 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:44:28,815 : INFO : EPOCH 2 - PROGRESS: at 44.69% examples, 180026 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:29,834 : INFO : EPOCH 2 - PROGRESS: at 64.80% examples, 194757 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:30,838 : INFO : EPOCH 2 - PROGRESS: at 88.27% examples, 213764 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:31,392 : INFO : EPOCH 2: training on 1788017 raw words (1242075 effective words) took 5.7s, 218254 effective words/s\n",
      "2023-04-04 13:44:32,484 : INFO : EPOCH 3 - PROGRESS: at 17.32% examples, 211586 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:33,484 : INFO : EPOCH 3 - PROGRESS: at 40.22% examples, 248188 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:34,499 : INFO : EPOCH 3 - PROGRESS: at 58.66% examples, 239040 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:35,512 : INFO : EPOCH 3 - PROGRESS: at 76.54% examples, 234171 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:36,558 : INFO : EPOCH 3 - PROGRESS: at 94.41% examples, 229687 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:36,851 : INFO : EPOCH 3: training on 1788017 raw words (1242548 effective words) took 5.4s, 229842 effective words/s\n",
      "2023-04-04 13:44:37,974 : INFO : EPOCH 4 - PROGRESS: at 9.50% examples, 116248 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:38,982 : INFO : EPOCH 4 - PROGRESS: at 25.14% examples, 155207 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:39,982 : INFO : EPOCH 4 - PROGRESS: at 42.46% examples, 174820 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:41,019 : INFO : EPOCH 4 - PROGRESS: at 62.01% examples, 188434 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:42,024 : INFO : EPOCH 4 - PROGRESS: at 79.33% examples, 193725 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:44:43,058 : INFO : EPOCH 4 - PROGRESS: at 97.77% examples, 198455 words/s, in_qsize 3, out_qsize 1\n",
      "2023-04-04 13:44:43,202 : INFO : EPOCH 4: training on 1788017 raw words (1242781 effective words) took 6.3s, 198086 effective words/s\n",
      "2023-04-04 13:44:43,204 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211649 effective words) took 29.7s, 209496 effective words/s', 'datetime': '2023-04-04T13:44:43.203132', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:44:43,205 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:44:43.205131', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:44:43,236 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:44:43,556 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:44:44,212 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:44:44,213 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:44:44,390 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:44:44.390079', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:44:44,393 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:44:44.393067', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:44:44,621 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:44:44,629 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:44:44,633 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:44:44.633687', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:44:44,666 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 13:44:46,141 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 13:44:46,525 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 13:44:46,528 : INFO : resetting layer weights\n",
      "2023-04-04 13:44:46,552 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:44:46.552945', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:44:46,553 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:44:46,556 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:44:46.556466', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:44:47,670 : INFO : EPOCH 0 - PROGRESS: at 11.17% examples, 137275 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:48,728 : INFO : EPOCH 0 - PROGRESS: at 26.26% examples, 158658 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:49,779 : INFO : EPOCH 0 - PROGRESS: at 45.81% examples, 182644 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:44:50,807 : INFO : EPOCH 0 - PROGRESS: at 67.04% examples, 199435 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:44:51,820 : INFO : EPOCH 0 - PROGRESS: at 89.39% examples, 214371 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:44:52,301 : INFO : EPOCH 0: training on 1788017 raw words (1242742 effective words) took 5.7s, 219153 effective words/s\n",
      "2023-04-04 13:44:53,379 : INFO : EPOCH 1 - PROGRESS: at 15.08% examples, 185635 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:54,394 : INFO : EPOCH 1 - PROGRESS: at 35.75% examples, 220093 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:55,410 : INFO : EPOCH 1 - PROGRESS: at 53.07% examples, 216829 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:56,489 : INFO : EPOCH 1 - PROGRESS: at 68.16% examples, 204483 words/s, in_qsize 6, out_qsize 2\n",
      "2023-04-04 13:44:57,490 : INFO : EPOCH 1 - PROGRESS: at 83.80% examples, 202815 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:58,589 : INFO : EPOCH 1 - PROGRESS: at 96.09% examples, 191607 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:44:58,798 : INFO : EPOCH 1: training on 1788017 raw words (1242634 effective words) took 6.4s, 192661 effective words/s\n",
      "2023-04-04 13:44:59,904 : INFO : EPOCH 2 - PROGRESS: at 10.61% examples, 131320 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:00,922 : INFO : EPOCH 2 - PROGRESS: at 33.52% examples, 205889 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:01,960 : INFO : EPOCH 2 - PROGRESS: at 57.54% examples, 232022 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:03,062 : INFO : EPOCH 2 - PROGRESS: at 80.45% examples, 238673 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:04,034 : INFO : EPOCH 2: training on 1788017 raw words (1241898 effective words) took 5.2s, 240437 effective words/s\n",
      "2023-04-04 13:45:05,098 : INFO : EPOCH 3 - PROGRESS: at 15.08% examples, 190021 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:06,111 : INFO : EPOCH 3 - PROGRESS: at 32.96% examples, 205772 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:07,130 : INFO : EPOCH 3 - PROGRESS: at 50.84% examples, 209772 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:08,163 : INFO : EPOCH 3 - PROGRESS: at 70.39% examples, 214700 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:09,210 : INFO : EPOCH 3 - PROGRESS: at 84.36% examples, 204950 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:10,173 : INFO : EPOCH 3: training on 1788017 raw words (1241799 effective words) took 6.1s, 204202 effective words/s\n",
      "2023-04-04 13:45:11,292 : INFO : EPOCH 4 - PROGRESS: at 14.53% examples, 174546 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:12,303 : INFO : EPOCH 4 - PROGRESS: at 34.08% examples, 207974 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:13,337 : INFO : EPOCH 4 - PROGRESS: at 54.75% examples, 220606 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:45:14,339 : INFO : EPOCH 4 - PROGRESS: at 75.42% examples, 228805 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:15,385 : INFO : EPOCH 4 - PROGRESS: at 94.41% examples, 228112 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:45:15,652 : INFO : EPOCH 4: training on 1788017 raw words (1242475 effective words) took 5.4s, 229443 effective words/s\n",
      "2023-04-04 13:45:15,654 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211548 effective words) took 29.1s, 213498 effective words/s', 'datetime': '2023-04-04T13:45:15.654156', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:45:15,655 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:45:15.655157', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:45:15,679 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:45:16,032 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #18: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 33.42635194460551, 'train_time_std': 1.346471509499782}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:45:17,115 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:45:17,117 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:45:17,396 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:45:17.396226', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:45:17,397 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:45:17.397255', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:45:17,684 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:45:17,696 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:45:17,699 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:45:17.699940', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:45:17,734 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 13:45:19,082 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 13:45:19,501 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 13:45:19,503 : INFO : resetting layer weights\n",
      "2023-04-04 13:45:19,533 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:45:19.533997', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:45:19,539 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:45:19,541 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:45:19.541515', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:45:20,624 : INFO : EPOCH 0 - PROGRESS: at 14.53% examples, 184176 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:21,652 : INFO : EPOCH 0 - PROGRESS: at 36.87% examples, 228670 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:45:22,656 : INFO : EPOCH 0 - PROGRESS: at 56.42% examples, 232045 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:23,658 : INFO : EPOCH 0 - PROGRESS: at 77.09% examples, 237841 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:24,679 : INFO : EPOCH 0 - PROGRESS: at 97.77% examples, 240554 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:45:24,760 : INFO : EPOCH 0: training on 1788017 raw words (1242107 effective words) took 5.1s, 241858 effective words/s\n",
      "2023-04-04 13:45:25,845 : INFO : EPOCH 1 - PROGRESS: at 8.94% examples, 113867 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:26,858 : INFO : EPOCH 1 - PROGRESS: at 23.46% examples, 147349 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:27,890 : INFO : EPOCH 1 - PROGRESS: at 39.11% examples, 161410 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:28,907 : INFO : EPOCH 1 - PROGRESS: at 54.19% examples, 166480 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:29,930 : INFO : EPOCH 1 - PROGRESS: at 65.36% examples, 159567 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:45:31,004 : INFO : EPOCH 1 - PROGRESS: at 78.21% examples, 157881 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:32,080 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 153642 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:32,866 : INFO : EPOCH 1: training on 1788017 raw words (1242926 effective words) took 8.0s, 154819 effective words/s\n",
      "2023-04-04 13:45:34,012 : INFO : EPOCH 2 - PROGRESS: at 8.94% examples, 111537 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:35,016 : INFO : EPOCH 2 - PROGRESS: at 22.35% examples, 139460 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:36,041 : INFO : EPOCH 2 - PROGRESS: at 39.66% examples, 163487 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:37,047 : INFO : EPOCH 2 - PROGRESS: at 58.10% examples, 178125 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:38,087 : INFO : EPOCH 2 - PROGRESS: at 75.42% examples, 183892 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:39,090 : INFO : EPOCH 2 - PROGRESS: at 92.74% examples, 188933 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:39,506 : INFO : EPOCH 2: training on 1788017 raw words (1242293 effective words) took 6.5s, 190540 effective words/s\n",
      "2023-04-04 13:45:40,621 : INFO : EPOCH 3 - PROGRESS: at 10.61% examples, 129887 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:41,665 : INFO : EPOCH 3 - PROGRESS: at 26.26% examples, 159220 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:42,670 : INFO : EPOCH 3 - PROGRESS: at 40.78% examples, 165730 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:43,767 : INFO : EPOCH 3 - PROGRESS: at 55.31% examples, 164721 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:44,815 : INFO : EPOCH 3 - PROGRESS: at 62.57% examples, 148324 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:45,850 : INFO : EPOCH 3 - PROGRESS: at 74.86% examples, 148424 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:45:46,903 : INFO : EPOCH 3 - PROGRESS: at 87.15% examples, 147962 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:47,741 : INFO : EPOCH 3: training on 1788017 raw words (1242523 effective words) took 8.2s, 152125 effective words/s\n",
      "2023-04-04 13:45:48,881 : INFO : EPOCH 4 - PROGRESS: at 9.50% examples, 113960 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:45:50,092 : INFO : EPOCH 4 - PROGRESS: at 19.55% examples, 108929 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:45:51,100 : INFO : EPOCH 4 - PROGRESS: at 34.08% examples, 130718 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:52,105 : INFO : EPOCH 4 - PROGRESS: at 53.63% examples, 156348 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:53,139 : INFO : EPOCH 4 - PROGRESS: at 71.51% examples, 167095 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:54,139 : INFO : EPOCH 4 - PROGRESS: at 88.83% examples, 174844 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:45:54,772 : INFO : EPOCH 4: training on 1788017 raw words (1242529 effective words) took 7.0s, 178673 effective words/s\n",
      "2023-04-04 13:45:54,775 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212378 effective words) took 35.2s, 176329 effective words/s', 'datetime': '2023-04-04T13:45:54.775063', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:45:54,776 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:45:54.776070', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:45:54,797 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:45:55,113 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:45:56,058 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:45:56,060 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:45:56,287 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:45:56.287560', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:45:56,290 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:45:56.289561', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:45:56,587 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:45:56,596 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:45:56,598 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:45:56.598535', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:45:56,622 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 13:45:58,576 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 13:45:58,954 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 13:45:58,956 : INFO : resetting layer weights\n",
      "2023-04-04 13:45:58,981 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:45:58.981248', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:45:58,982 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:45:58,984 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:45:58.984251', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:46:00,081 : INFO : EPOCH 0 - PROGRESS: at 13.97% examples, 170662 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:46:01,095 : INFO : EPOCH 0 - PROGRESS: at 31.28% examples, 192203 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:46:02,119 : INFO : EPOCH 0 - PROGRESS: at 51.40% examples, 209450 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:46:03,127 : INFO : EPOCH 0 - PROGRESS: at 73.74% examples, 224330 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:04,128 : INFO : EPOCH 0 - PROGRESS: at 97.21% examples, 237647 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:04,248 : INFO : EPOCH 0: training on 1788017 raw words (1241738 effective words) took 5.2s, 238545 effective words/s\n",
      "2023-04-04 13:46:05,344 : INFO : EPOCH 1 - PROGRESS: at 17.88% examples, 215765 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:06,345 : INFO : EPOCH 1 - PROGRESS: at 37.99% examples, 232795 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:07,346 : INFO : EPOCH 1 - PROGRESS: at 58.10% examples, 236995 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:08,351 : INFO : EPOCH 1 - PROGRESS: at 77.09% examples, 236576 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:09,360 : INFO : EPOCH 1 - PROGRESS: at 96.65% examples, 237195 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:09,502 : INFO : EPOCH 1: training on 1788017 raw words (1242284 effective words) took 5.2s, 238408 effective words/s\n",
      "2023-04-04 13:46:10,606 : INFO : EPOCH 2 - PROGRESS: at 14.53% examples, 176443 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:11,628 : INFO : EPOCH 2 - PROGRESS: at 37.99% examples, 231393 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:46:12,636 : INFO : EPOCH 2 - PROGRESS: at 63.13% examples, 255243 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:13,681 : INFO : EPOCH 2 - PROGRESS: at 80.45% examples, 243114 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:14,685 : INFO : EPOCH 2 - PROGRESS: at 98.32% examples, 238853 words/s, in_qsize 3, out_qsize 0\n",
      "2023-04-04 13:46:14,744 : INFO : EPOCH 2: training on 1788017 raw words (1242375 effective words) took 5.2s, 239829 effective words/s\n",
      "2023-04-04 13:46:15,803 : INFO : EPOCH 3 - PROGRESS: at 13.41% examples, 170000 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:46:16,819 : INFO : EPOCH 3 - PROGRESS: at 29.61% examples, 185955 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:46:17,824 : INFO : EPOCH 3 - PROGRESS: at 44.69% examples, 185664 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:18,832 : INFO : EPOCH 3 - PROGRESS: at 62.57% examples, 192801 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:19,849 : INFO : EPOCH 3 - PROGRESS: at 81.56% examples, 200894 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:20,861 : INFO : EPOCH 3 - PROGRESS: at 96.09% examples, 197220 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:20,991 : INFO : EPOCH 3: training on 1788017 raw words (1242345 effective words) took 6.2s, 200718 effective words/s\n",
      "2023-04-04 13:46:22,051 : INFO : EPOCH 4 - PROGRESS: at 16.76% examples, 210993 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:23,051 : INFO : EPOCH 4 - PROGRESS: at 40.22% examples, 252177 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:46:24,058 : INFO : EPOCH 4 - PROGRESS: at 64.80% examples, 266924 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:25,070 : INFO : EPOCH 4 - PROGRESS: at 88.83% examples, 274333 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:25,821 : INFO : EPOCH 4: training on 1788017 raw words (1242589 effective words) took 4.8s, 260011 effective words/s\n",
      "2023-04-04 13:46:25,822 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211331 effective words) took 26.8s, 231447 effective words/s', 'datetime': '2023-04-04T13:46:25.822052', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:46:25,824 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:46:25.824045', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:46:25,851 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:46:26,205 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:46:27,061 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:46:27,063 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:46:27,288 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:46:27.288007', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:46:27,289 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:46:27.289990', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:46:27,535 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:46:27,541 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:46:27,543 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:46:27.543090', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:46:27,571 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 13:46:29,136 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 13:46:29,644 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 13:46:29,647 : INFO : resetting layer weights\n",
      "2023-04-04 13:46:29,673 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:46:29.673545', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:46:29,679 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:46:29,683 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:46:29.682727', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:46:30,765 : INFO : EPOCH 0 - PROGRESS: at 8.94% examples, 113288 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:46:31,770 : INFO : EPOCH 0 - PROGRESS: at 30.17% examples, 189102 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:32,779 : INFO : EPOCH 0 - PROGRESS: at 50.84% examples, 210638 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:33,799 : INFO : EPOCH 0 - PROGRESS: at 73.74% examples, 226673 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:34,825 : INFO : EPOCH 0 - PROGRESS: at 94.97% examples, 232954 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:46:35,020 : INFO : EPOCH 0: training on 1788017 raw words (1242337 effective words) took 5.3s, 235861 effective words/s\n",
      "2023-04-04 13:46:36,128 : INFO : EPOCH 1 - PROGRESS: at 15.64% examples, 188053 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:37,142 : INFO : EPOCH 1 - PROGRESS: at 35.20% examples, 214128 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:38,151 : INFO : EPOCH 1 - PROGRESS: at 55.31% examples, 224206 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:39,161 : INFO : EPOCH 1 - PROGRESS: at 68.16% examples, 206961 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:46:40,187 : INFO : EPOCH 1 - PROGRESS: at 87.15% examples, 211906 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:40,841 : INFO : EPOCH 1: training on 1788017 raw words (1241924 effective words) took 5.8s, 215293 effective words/s\n",
      "2023-04-04 13:46:41,946 : INFO : EPOCH 2 - PROGRESS: at 17.88% examples, 214668 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:42,988 : INFO : EPOCH 2 - PROGRESS: at 35.20% examples, 211112 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:44,005 : INFO : EPOCH 2 - PROGRESS: at 55.87% examples, 223807 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:45,018 : INFO : EPOCH 2 - PROGRESS: at 78.77% examples, 237453 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:46,032 : INFO : EPOCH 2 - PROGRESS: at 98.32% examples, 237874 words/s, in_qsize 3, out_qsize 0\n",
      "2023-04-04 13:46:46,103 : INFO : EPOCH 2: training on 1788017 raw words (1242795 effective words) took 5.2s, 238304 effective words/s\n",
      "2023-04-04 13:46:47,235 : INFO : EPOCH 3 - PROGRESS: at 10.61% examples, 129001 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:48,262 : INFO : EPOCH 3 - PROGRESS: at 26.82% examples, 163431 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:49,290 : INFO : EPOCH 3 - PROGRESS: at 43.02% examples, 173932 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:46:50,296 : INFO : EPOCH 3 - PROGRESS: at 60.34% examples, 182513 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:51,309 : INFO : EPOCH 3 - PROGRESS: at 80.45% examples, 195344 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:52,174 : INFO : EPOCH 3: training on 1788017 raw words (1243094 effective words) took 6.0s, 207415 effective words/s\n",
      "2023-04-04 13:46:53,241 : INFO : EPOCH 4 - PROGRESS: at 17.88% examples, 224372 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:54,242 : INFO : EPOCH 4 - PROGRESS: at 41.90% examples, 261613 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:46:55,276 : INFO : EPOCH 4 - PROGRESS: at 63.69% examples, 259601 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:46:56,321 : INFO : EPOCH 4 - PROGRESS: at 85.47% examples, 259660 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:46:57,053 : INFO : EPOCH 4: training on 1788017 raw words (1242664 effective words) took 4.8s, 257498 effective words/s\n",
      "2023-04-04 13:46:57,054 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212814 effective words) took 27.4s, 226991 effective words/s', 'datetime': '2023-04-04T13:46:57.054973', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:46:57,057 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:46:57.057073', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:46:57,083 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #19: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 33.80125188827515, 'train_time_std': 3.7604229152441206}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:46:57,406 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:46:58,262 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:46:58,264 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:46:58,466 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:46:58.466568', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:46:58,467 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:46:58.467591', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:46:58,720 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:46:58,729 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:46:58,732 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:46:58.732205', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:46:59,066 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:46:59,068 : INFO : resetting layer weights\n",
      "2023-04-04 13:46:59,088 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:46:59.088626', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:46:59,092 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:46:59.092615', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:47:00,181 : INFO : EPOCH 0 - PROGRESS: at 7.82% examples, 97525 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:01,247 : INFO : EPOCH 0 - PROGRESS: at 20.67% examples, 125317 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:02,256 : INFO : EPOCH 0 - PROGRESS: at 33.52% examples, 136132 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:03,288 : INFO : EPOCH 0 - PROGRESS: at 46.93% examples, 142391 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:04,298 : INFO : EPOCH 0 - PROGRESS: at 59.22% examples, 143248 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:05,305 : INFO : EPOCH 0 - PROGRESS: at 72.07% examples, 145593 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:06,312 : INFO : EPOCH 0 - PROGRESS: at 82.12% examples, 142572 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:07,377 : INFO : EPOCH 0 - PROGRESS: at 92.18% examples, 139326 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:08,079 : INFO : EPOCH 0: training on 1788017 raw words (1241442 effective words) took 8.9s, 139075 effective words/s\n",
      "2023-04-04 13:47:09,178 : INFO : EPOCH 1 - PROGRESS: at 7.26% examples, 89611 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:10,192 : INFO : EPOCH 1 - PROGRESS: at 18.99% examples, 117444 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:11,211 : INFO : EPOCH 1 - PROGRESS: at 31.84% examples, 130696 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:12,249 : INFO : EPOCH 1 - PROGRESS: at 45.81% examples, 139866 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:13,271 : INFO : EPOCH 1 - PROGRESS: at 60.34% examples, 146238 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:14,317 : INFO : EPOCH 1 - PROGRESS: at 71.51% examples, 143864 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:47:15,361 : INFO : EPOCH 1 - PROGRESS: at 86.03% examples, 148172 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:16,412 : INFO : EPOCH 1 - PROGRESS: at 99.44% examples, 149274 words/s, in_qsize 1, out_qsize 1\n",
      "2023-04-04 13:47:16,435 : INFO : EPOCH 1: training on 1788017 raw words (1241453 effective words) took 8.3s, 149703 effective words/s\n",
      "2023-04-04 13:47:17,609 : INFO : EPOCH 2 - PROGRESS: at 7.26% examples, 85245 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:18,609 : INFO : EPOCH 2 - PROGRESS: at 17.32% examples, 105149 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:19,859 : INFO : EPOCH 2 - PROGRESS: at 29.05% examples, 110200 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:20,919 : INFO : EPOCH 2 - PROGRESS: at 38.55% examples, 110347 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:21,935 : INFO : EPOCH 2 - PROGRESS: at 50.84% examples, 117682 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:22,944 : INFO : EPOCH 2 - PROGRESS: at 64.80% examples, 125308 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:23,957 : INFO : EPOCH 2 - PROGRESS: at 78.21% examples, 130818 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:24,968 : INFO : EPOCH 2 - PROGRESS: at 91.62% examples, 134890 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:25,606 : INFO : EPOCH 2: training on 1788017 raw words (1242568 effective words) took 9.1s, 136715 effective words/s\n",
      "2023-04-04 13:47:26,657 : INFO : EPOCH 3 - PROGRESS: at 8.94% examples, 113993 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:27,663 : INFO : EPOCH 3 - PROGRESS: at 21.23% examples, 134003 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:28,671 : INFO : EPOCH 3 - PROGRESS: at 32.96% examples, 137651 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:29,691 : INFO : EPOCH 3 - PROGRESS: at 44.69% examples, 138934 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:47:30,731 : INFO : EPOCH 3 - PROGRESS: at 56.42% examples, 138496 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:31,760 : INFO : EPOCH 3 - PROGRESS: at 69.83% examples, 141962 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:32,761 : INFO : EPOCH 3 - PROGRESS: at 82.12% examples, 143560 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:33,787 : INFO : EPOCH 3 - PROGRESS: at 94.41% examples, 144287 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:34,247 : INFO : EPOCH 3: training on 1788017 raw words (1241777 effective words) took 8.6s, 144496 effective words/s\n",
      "2023-04-04 13:47:35,406 : INFO : EPOCH 4 - PROGRESS: at 8.94% examples, 104115 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:36,544 : INFO : EPOCH 4 - PROGRESS: at 22.35% examples, 126713 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:37,565 : INFO : EPOCH 4 - PROGRESS: at 32.96% examples, 127564 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:38,591 : INFO : EPOCH 4 - PROGRESS: at 44.13% examples, 129392 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:39,608 : INFO : EPOCH 4 - PROGRESS: at 56.42% examples, 132765 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:40,622 : INFO : EPOCH 4 - PROGRESS: at 68.16% examples, 134004 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:41,635 : INFO : EPOCH 4 - PROGRESS: at 81.56% examples, 138365 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:42,680 : INFO : EPOCH 4 - PROGRESS: at 94.97% examples, 141070 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:47:43,151 : INFO : EPOCH 4: training on 1788017 raw words (1241974 effective words) took 8.8s, 140446 effective words/s\n",
      "2023-04-04 13:47:43,152 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6209214 effective words) took 44.1s, 140933 effective words/s', 'datetime': '2023-04-04T13:47:43.152800', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:47:43,153 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:47:43.153800', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:47:43,175 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:47:43,430 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:47:44,030 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:47:44,031 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:47:44,191 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:47:44.191409', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:47:44,194 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:47:44.194404', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:47:44,369 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:47:44,379 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:47:44,380 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:47:44.380075', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:47:44,635 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:47:44,637 : INFO : resetting layer weights\n",
      "2023-04-04 13:47:44,653 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:47:44.653180', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:47:44,654 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:47:44.654186', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:47:45,762 : INFO : EPOCH 0 - PROGRESS: at 10.61% examples, 127842 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:46,801 : INFO : EPOCH 0 - PROGRESS: at 24.02% examples, 144891 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:47,825 : INFO : EPOCH 0 - PROGRESS: at 36.87% examples, 148505 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:48,953 : INFO : EPOCH 0 - PROGRESS: at 49.16% examples, 145074 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:50,120 : INFO : EPOCH 0 - PROGRESS: at 59.22% examples, 136001 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:47:51,141 : INFO : EPOCH 0 - PROGRESS: at 68.72% examples, 132537 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:52,145 : INFO : EPOCH 0 - PROGRESS: at 81.01% examples, 135375 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:53,158 : INFO : EPOCH 0 - PROGRESS: at 93.85% examples, 137973 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:53,647 : INFO : EPOCH 0: training on 1788017 raw words (1242633 effective words) took 8.9s, 138854 effective words/s\n",
      "2023-04-04 13:47:54,772 : INFO : EPOCH 1 - PROGRESS: at 8.94% examples, 107743 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:55,783 : INFO : EPOCH 1 - PROGRESS: at 22.35% examples, 136734 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:56,784 : INFO : EPOCH 1 - PROGRESS: at 35.75% examples, 146436 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:57,788 : INFO : EPOCH 1 - PROGRESS: at 47.49% examples, 146181 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:58,799 : INFO : EPOCH 1 - PROGRESS: at 59.22% examples, 144915 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:47:59,802 : INFO : EPOCH 1 - PROGRESS: at 72.07% examples, 147090 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:00,815 : INFO : EPOCH 1 - PROGRESS: at 84.36% examples, 147716 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:01,960 : INFO : EPOCH 1 - PROGRESS: at 97.77% examples, 147389 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:48:02,189 : INFO : EPOCH 1: training on 1788017 raw words (1242433 effective words) took 8.5s, 146518 effective words/s\n",
      "2023-04-04 13:48:03,333 : INFO : EPOCH 2 - PROGRESS: at 10.61% examples, 124961 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:04,381 : INFO : EPOCH 2 - PROGRESS: at 25.70% examples, 152431 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:05,385 : INFO : EPOCH 2 - PROGRESS: at 39.11% examples, 156818 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:06,421 : INFO : EPOCH 2 - PROGRESS: at 52.51% examples, 157309 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:07,485 : INFO : EPOCH 2 - PROGRESS: at 64.80% examples, 153584 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:08,507 : INFO : EPOCH 2 - PROGRESS: at 74.86% examples, 148641 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:09,522 : INFO : EPOCH 2 - PROGRESS: at 85.47% examples, 146043 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:48:10,591 : INFO : EPOCH 2 - PROGRESS: at 96.09% examples, 143208 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:11,105 : INFO : EPOCH 2: training on 1788017 raw words (1241814 effective words) took 8.9s, 140192 effective words/s\n",
      "2023-04-04 13:48:12,176 : INFO : EPOCH 3 - PROGRESS: at 7.82% examples, 100424 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:13,223 : INFO : EPOCH 3 - PROGRESS: at 22.35% examples, 138509 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:14,232 : INFO : EPOCH 3 - PROGRESS: at 36.87% examples, 151895 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:15,251 : INFO : EPOCH 3 - PROGRESS: at 50.84% examples, 156511 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:16,277 : INFO : EPOCH 3 - PROGRESS: at 65.92% examples, 160624 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:17,284 : INFO : EPOCH 3 - PROGRESS: at 78.21% examples, 159427 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:18,299 : INFO : EPOCH 3 - PROGRESS: at 90.50% examples, 158235 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:48:19,107 : INFO : EPOCH 3: training on 1788017 raw words (1243134 effective words) took 7.9s, 156726 effective words/s\n",
      "2023-04-04 13:48:20,234 : INFO : EPOCH 4 - PROGRESS: at 7.82% examples, 94953 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:21,279 : INFO : EPOCH 4 - PROGRESS: at 17.32% examples, 104707 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:22,290 : INFO : EPOCH 4 - PROGRESS: at 29.05% examples, 118342 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:23,292 : INFO : EPOCH 4 - PROGRESS: at 41.90% examples, 128031 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:24,307 : INFO : EPOCH 4 - PROGRESS: at 54.75% examples, 133362 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:25,403 : INFO : EPOCH 4 - PROGRESS: at 68.16% examples, 136015 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:48:26,471 : INFO : EPOCH 4 - PROGRESS: at 80.45% examples, 137301 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:27,482 : INFO : EPOCH 4 - PROGRESS: at 92.18% examples, 138089 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:28,156 : INFO : EPOCH 4: training on 1788017 raw words (1242335 effective words) took 9.0s, 138391 effective words/s\n",
      "2023-04-04 13:48:28,160 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212349 effective words) took 43.5s, 142807 effective words/s', 'datetime': '2023-04-04T13:48:28.160626', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:48:28,162 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:48:28.162619', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:48:28,172 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:48:28,531 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:48:29,420 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:48:29,421 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:48:29,629 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:48:29.629661', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:48:29,632 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:48:29.632676', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:48:29,893 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:48:29,900 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:48:29,902 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:48:29.902676', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:48:30,267 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:48:30,269 : INFO : resetting layer weights\n",
      "2023-04-04 13:48:30,300 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:48:30.300901', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:48:30,308 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:48:30.308387', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:48:31,620 : INFO : EPOCH 0 - PROGRESS: at 5.59% examples, 67295 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:48:32,683 : INFO : EPOCH 0 - PROGRESS: at 18.99% examples, 113221 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:33,718 : INFO : EPOCH 0 - PROGRESS: at 34.08% examples, 135718 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:34,724 : INFO : EPOCH 0 - PROGRESS: at 48.04% examples, 144520 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:35,746 : INFO : EPOCH 0 - PROGRESS: at 63.13% examples, 151007 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:36,747 : INFO : EPOCH 0 - PROGRESS: at 77.09% examples, 154819 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:48:37,795 : INFO : EPOCH 0 - PROGRESS: at 88.27% examples, 151648 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:38,825 : INFO : EPOCH 0 - PROGRESS: at 97.77% examples, 146965 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:48:38,990 : INFO : EPOCH 0: training on 1788017 raw words (1242446 effective words) took 8.4s, 147198 effective words/s\n",
      "2023-04-04 13:48:40,151 : INFO : EPOCH 1 - PROGRESS: at 6.15% examples, 73370 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:48:41,184 : INFO : EPOCH 1 - PROGRESS: at 15.08% examples, 90567 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:42,221 : INFO : EPOCH 1 - PROGRESS: at 25.70% examples, 103371 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:43,259 : INFO : EPOCH 1 - PROGRESS: at 39.11% examples, 117625 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:44,305 : INFO : EPOCH 1 - PROGRESS: at 52.51% examples, 125593 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:45,338 : INFO : EPOCH 1 - PROGRESS: at 67.04% examples, 132827 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:46,343 : INFO : EPOCH 1 - PROGRESS: at 81.56% examples, 139494 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:47,385 : INFO : EPOCH 1 - PROGRESS: at 94.97% examples, 142110 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:47,965 : INFO : EPOCH 1: training on 1788017 raw words (1242377 effective words) took 8.9s, 139702 effective words/s\n",
      "2023-04-04 13:48:49,079 : INFO : EPOCH 2 - PROGRESS: at 7.26% examples, 88703 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:50,110 : INFO : EPOCH 2 - PROGRESS: at 19.55% examples, 119461 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:51,113 : INFO : EPOCH 2 - PROGRESS: at 31.28% examples, 127945 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:48:52,240 : INFO : EPOCH 2 - PROGRESS: at 44.13% examples, 131689 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:53,259 : INFO : EPOCH 2 - PROGRESS: at 58.10% examples, 138413 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:54,307 : INFO : EPOCH 2 - PROGRESS: at 71.51% examples, 141625 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:55,314 : INFO : EPOCH 2 - PROGRESS: at 84.92% examples, 144930 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:56,333 : INFO : EPOCH 2 - PROGRESS: at 96.09% examples, 143950 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:56,734 : INFO : EPOCH 2: training on 1788017 raw words (1242336 effective words) took 8.7s, 142704 effective words/s\n",
      "2023-04-04 13:48:57,842 : INFO : EPOCH 3 - PROGRESS: at 7.26% examples, 88932 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:58,952 : INFO : EPOCH 3 - PROGRESS: at 18.99% examples, 111772 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:48:59,962 : INFO : EPOCH 3 - PROGRESS: at 31.84% examples, 126789 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:00,979 : INFO : EPOCH 3 - PROGRESS: at 43.58% examples, 130765 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:49:02,038 : INFO : EPOCH 3 - PROGRESS: at 55.87% examples, 132950 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:03,075 : INFO : EPOCH 3 - PROGRESS: at 70.95% examples, 140380 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:49:04,113 : INFO : EPOCH 3 - PROGRESS: at 85.47% examples, 145217 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:05,123 : INFO : EPOCH 3 - PROGRESS: at 99.44% examples, 148298 words/s, in_qsize 1, out_qsize 1\n",
      "2023-04-04 13:49:05,140 : INFO : EPOCH 3: training on 1788017 raw words (1241883 effective words) took 8.3s, 148834 effective words/s\n",
      "2023-04-04 13:49:06,237 : INFO : EPOCH 4 - PROGRESS: at 10.61% examples, 128903 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:49:07,240 : INFO : EPOCH 4 - PROGRESS: at 22.91% examples, 141144 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:08,242 : INFO : EPOCH 4 - PROGRESS: at 35.20% examples, 144748 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:09,320 : INFO : EPOCH 4 - PROGRESS: at 46.37% examples, 140625 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:10,359 : INFO : EPOCH 4 - PROGRESS: at 58.10% examples, 139808 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:11,446 : INFO : EPOCH 4 - PROGRESS: at 69.83% examples, 138550 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:49:12,479 : INFO : EPOCH 4 - PROGRESS: at 81.56% examples, 139007 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:13,531 : INFO : EPOCH 4 - PROGRESS: at 94.41% examples, 140710 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:14,079 : INFO : EPOCH 4: training on 1788017 raw words (1242393 effective words) took 8.9s, 139690 effective words/s\n",
      "2023-04-04 13:49:14,080 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211435 effective words) took 43.8s, 141921 effective words/s', 'datetime': '2023-04-04T13:49:14.080189', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:49:14,081 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:49:14.081196', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:49:14,089 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:49:14,354 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #20: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 45.6685045560201, 'train_time_std': 0.4791627236874829}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:49:15,323 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:49:15,325 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:49:15,502 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:49:15.502439', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:49:15,505 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:49:15.505920', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:49:15,699 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:49:15,709 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:49:15,710 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:49:15.710467', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:49:15,979 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:49:15,981 : INFO : resetting layer weights\n",
      "2023-04-04 13:49:16,001 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:49:16.001350', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:49:16,005 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:49:16.005359', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:49:17,097 : INFO : EPOCH 0 - PROGRESS: at 10.61% examples, 129720 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:18,133 : INFO : EPOCH 0 - PROGRESS: at 22.91% examples, 139380 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:19,176 : INFO : EPOCH 0 - PROGRESS: at 35.75% examples, 143880 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:20,214 : INFO : EPOCH 0 - PROGRESS: at 48.04% examples, 144775 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:49:21,229 : INFO : EPOCH 0 - PROGRESS: at 58.10% examples, 139688 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:22,240 : INFO : EPOCH 0 - PROGRESS: at 69.83% examples, 140078 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:23,286 : INFO : EPOCH 0 - PROGRESS: at 83.80% examples, 143988 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:24,312 : INFO : EPOCH 0 - PROGRESS: at 97.77% examples, 147154 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:49:24,419 : INFO : EPOCH 0: training on 1788017 raw words (1241896 effective words) took 8.4s, 148370 effective words/s\n",
      "2023-04-04 13:49:25,486 : INFO : EPOCH 1 - PROGRESS: at 9.50% examples, 119789 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:26,602 : INFO : EPOCH 1 - PROGRESS: at 22.35% examples, 133038 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:27,644 : INFO : EPOCH 1 - PROGRESS: at 35.75% examples, 141878 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:28,710 : INFO : EPOCH 1 - PROGRESS: at 44.13% examples, 130775 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:29,731 : INFO : EPOCH 1 - PROGRESS: at 55.31% examples, 131374 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:30,747 : INFO : EPOCH 1 - PROGRESS: at 65.92% examples, 130507 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:31,790 : INFO : EPOCH 1 - PROGRESS: at 76.54% examples, 130215 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:32,800 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 133550 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:33,513 : INFO : EPOCH 1: training on 1788017 raw words (1242442 effective words) took 9.0s, 137397 effective words/s\n",
      "2023-04-04 13:49:34,563 : INFO : EPOCH 2 - PROGRESS: at 9.50% examples, 121151 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:35,592 : INFO : EPOCH 2 - PROGRESS: at 24.02% examples, 149842 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:36,635 : INFO : EPOCH 2 - PROGRESS: at 36.87% examples, 150934 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:37,658 : INFO : EPOCH 2 - PROGRESS: at 50.28% examples, 153783 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:38,673 : INFO : EPOCH 2 - PROGRESS: at 62.57% examples, 152075 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:39,711 : INFO : EPOCH 2 - PROGRESS: at 74.86% examples, 151400 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:40,794 : INFO : EPOCH 2 - PROGRESS: at 87.15% examples, 149910 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:41,797 : INFO : EPOCH 2 - PROGRESS: at 96.09% examples, 145113 words/s, in_qsize 5, out_qsize 1\n",
      "2023-04-04 13:49:42,263 : INFO : EPOCH 2: training on 1788017 raw words (1242510 effective words) took 8.7s, 142778 effective words/s\n",
      "2023-04-04 13:49:43,519 : INFO : EPOCH 3 - PROGRESS: at 7.26% examples, 82287 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:44,548 : INFO : EPOCH 3 - PROGRESS: at 18.99% examples, 111536 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:45,582 : INFO : EPOCH 3 - PROGRESS: at 27.37% examples, 108572 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:46,596 : INFO : EPOCH 3 - PROGRESS: at 36.87% examples, 110104 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:47,637 : INFO : EPOCH 3 - PROGRESS: at 45.81% examples, 109444 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:48,675 : INFO : EPOCH 3 - PROGRESS: at 57.54% examples, 114017 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:49,742 : INFO : EPOCH 3 - PROGRESS: at 68.72% examples, 116028 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:50,762 : INFO : EPOCH 3 - PROGRESS: at 77.09% examples, 114584 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:51,775 : INFO : EPOCH 3 - PROGRESS: at 87.71% examples, 116201 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:52,863 : INFO : EPOCH 3 - PROGRESS: at 96.09% examples, 114092 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:53,159 : INFO : EPOCH 3: training on 1788017 raw words (1242253 effective words) took 10.8s, 115319 effective words/s\n",
      "2023-04-04 13:49:54,370 : INFO : EPOCH 4 - PROGRESS: at 7.26% examples, 81487 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:55,398 : INFO : EPOCH 4 - PROGRESS: at 18.99% examples, 111047 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:56,405 : INFO : EPOCH 4 - PROGRESS: at 30.17% examples, 120117 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:57,470 : INFO : EPOCH 4 - PROGRESS: at 40.78% examples, 120980 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:58,508 : INFO : EPOCH 4 - PROGRESS: at 50.84% examples, 120659 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:49:59,547 : INFO : EPOCH 4 - PROGRESS: at 60.89% examples, 119787 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:00,616 : INFO : EPOCH 4 - PROGRESS: at 71.51% examples, 120315 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:01,623 : INFO : EPOCH 4 - PROGRESS: at 81.56% examples, 120802 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:02,656 : INFO : EPOCH 4 - PROGRESS: at 91.62% examples, 120893 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:03,579 : INFO : EPOCH 4: training on 1788017 raw words (1242418 effective words) took 10.4s, 120006 effective words/s\n",
      "2023-04-04 13:50:03,581 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211519 effective words) took 47.6s, 130564 effective words/s', 'datetime': '2023-04-04T13:50:03.581647', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:50:03,582 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:50:03.582646', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:50:03,594 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:50:03,970 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:50:05,134 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:50:05,136 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:50:05,397 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:50:05.397754', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:50:05,399 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:50:05.399780', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:50:05,730 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:50:05,740 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:50:05,742 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:50:05.742112', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:50:06,145 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:50:06,147 : INFO : resetting layer weights\n",
      "2023-04-04 13:50:06,171 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:50:06.171318', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:50:06,173 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:50:06.173317', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:50:07,282 : INFO : EPOCH 0 - PROGRESS: at 7.26% examples, 89268 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:08,436 : INFO : EPOCH 0 - PROGRESS: at 18.99% examples, 109818 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:50:09,505 : INFO : EPOCH 0 - PROGRESS: at 29.05% examples, 112699 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:10,536 : INFO : EPOCH 0 - PROGRESS: at 40.78% examples, 119486 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:11,587 : INFO : EPOCH 0 - PROGRESS: at 52.51% examples, 122892 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:12,613 : INFO : EPOCH 0 - PROGRESS: at 64.25% examples, 125218 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:13,664 : INFO : EPOCH 0 - PROGRESS: at 74.30% examples, 124444 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:14,749 : INFO : EPOCH 0 - PROGRESS: at 87.15% examples, 127433 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:50:15,809 : INFO : EPOCH 0 - PROGRESS: at 99.44% examples, 129069 words/s, in_qsize 1, out_qsize 1\n",
      "2023-04-04 13:50:15,812 : INFO : EPOCH 0: training on 1788017 raw words (1242564 effective words) took 9.6s, 129755 effective words/s\n",
      "2023-04-04 13:50:17,005 : INFO : EPOCH 1 - PROGRESS: at 7.26% examples, 82760 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:50:18,010 : INFO : EPOCH 1 - PROGRESS: at 20.11% examples, 119962 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:50:19,032 : INFO : EPOCH 1 - PROGRESS: at 29.05% examples, 116763 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:20,138 : INFO : EPOCH 1 - PROGRESS: at 40.78% examples, 120526 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:21,158 : INFO : EPOCH 1 - PROGRESS: at 52.51% examples, 124522 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:22,193 : INFO : EPOCH 1 - PROGRESS: at 65.36% examples, 128676 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:23,210 : INFO : EPOCH 1 - PROGRESS: at 74.86% examples, 127053 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:24,257 : INFO : EPOCH 1 - PROGRESS: at 88.83% examples, 131927 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:25,053 : INFO : EPOCH 1: training on 1788017 raw words (1242234 effective words) took 9.2s, 135422 effective words/s\n",
      "2023-04-04 13:50:26,189 : INFO : EPOCH 2 - PROGRESS: at 10.61% examples, 125422 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:27,269 : INFO : EPOCH 2 - PROGRESS: at 25.70% examples, 150474 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:50:28,283 : INFO : EPOCH 2 - PROGRESS: at 39.11% examples, 155041 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:50:29,381 : INFO : EPOCH 2 - PROGRESS: at 50.84% examples, 149011 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:30,385 : INFO : EPOCH 2 - PROGRESS: at 62.01% examples, 145904 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:31,409 : INFO : EPOCH 2 - PROGRESS: at 69.83% examples, 137622 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:32,432 : INFO : EPOCH 2 - PROGRESS: at 79.89% examples, 135601 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:33,457 : INFO : EPOCH 2 - PROGRESS: at 88.83% examples, 132299 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:34,365 : INFO : EPOCH 2: training on 1788017 raw words (1242074 effective words) took 9.3s, 134142 effective words/s\n",
      "2023-04-04 13:50:35,512 : INFO : EPOCH 3 - PROGRESS: at 8.94% examples, 105826 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:36,583 : INFO : EPOCH 3 - PROGRESS: at 22.35% examples, 131625 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:37,589 : INFO : EPOCH 3 - PROGRESS: at 36.87% examples, 146844 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:38,603 : INFO : EPOCH 3 - PROGRESS: at 49.16% examples, 147809 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:50:39,609 : INFO : EPOCH 3 - PROGRESS: at 60.34% examples, 144953 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:40,655 : INFO : EPOCH 3 - PROGRESS: at 71.51% examples, 142796 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:41,676 : INFO : EPOCH 3 - PROGRESS: at 82.12% examples, 140892 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:50:42,772 : INFO : EPOCH 3 - PROGRESS: at 90.50% examples, 134970 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:43,533 : INFO : EPOCH 3: training on 1788017 raw words (1242010 effective words) took 9.1s, 136444 effective words/s\n",
      "2023-04-04 13:50:44,595 : INFO : EPOCH 4 - PROGRESS: at 10.06% examples, 128405 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:45,664 : INFO : EPOCH 4 - PROGRESS: at 22.35% examples, 136532 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:46,681 : INFO : EPOCH 4 - PROGRESS: at 35.20% examples, 143306 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:47,719 : INFO : EPOCH 4 - PROGRESS: at 46.93% examples, 142651 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:48,760 : INFO : EPOCH 4 - PROGRESS: at 58.66% examples, 141241 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:49,777 : INFO : EPOCH 4 - PROGRESS: at 68.16% examples, 136743 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:50:50,846 : INFO : EPOCH 4 - PROGRESS: at 78.21% examples, 134088 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:51,886 : INFO : EPOCH 4 - PROGRESS: at 86.59% examples, 129844 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:52,891 : INFO : EPOCH 4 - PROGRESS: at 97.21% examples, 129998 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:53,158 : INFO : EPOCH 4: training on 1788017 raw words (1241662 effective words) took 9.6s, 129830 effective words/s\n",
      "2023-04-04 13:50:53,159 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210544 effective words) took 47.0s, 132185 effective words/s', 'datetime': '2023-04-04T13:50:53.159030', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:50:53,161 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:50:53.161031', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:50:53,171 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:50:53,457 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:50:54,050 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:50:54,051 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:50:54,229 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:50:54.229600', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:50:54,231 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:50:54.230578', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:50:54,431 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:50:54,438 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:50:54,440 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:50:54.440158', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:50:54,743 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2023-04-04 13:50:54,745 : INFO : resetting layer weights\n",
      "2023-04-04 13:50:54,765 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:50:54.765182', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:50:54,767 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:50:54.767033', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:50:55,900 : INFO : EPOCH 0 - PROGRESS: at 10.61% examples, 126849 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:56,909 : INFO : EPOCH 0 - PROGRESS: at 25.14% examples, 153335 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:57,987 : INFO : EPOCH 0 - PROGRESS: at 39.11% examples, 155981 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:50:59,111 : INFO : EPOCH 0 - PROGRESS: at 52.51% examples, 153503 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:51:00,143 : INFO : EPOCH 0 - PROGRESS: at 65.36% examples, 152868 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:01,197 : INFO : EPOCH 0 - PROGRESS: at 75.98% examples, 148478 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:02,218 : INFO : EPOCH 0 - PROGRESS: at 84.36% examples, 142058 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:03,287 : INFO : EPOCH 0 - PROGRESS: at 92.18% examples, 135579 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:03,921 : INFO : EPOCH 0: training on 1788017 raw words (1241943 effective words) took 9.1s, 136612 effective words/s\n",
      "2023-04-04 13:51:05,091 : INFO : EPOCH 1 - PROGRESS: at 8.94% examples, 102757 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:06,102 : INFO : EPOCH 1 - PROGRESS: at 21.23% examples, 126852 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:51:07,109 : INFO : EPOCH 1 - PROGRESS: at 34.08% examples, 137191 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:08,128 : INFO : EPOCH 1 - PROGRESS: at 46.93% examples, 141909 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:09,190 : INFO : EPOCH 1 - PROGRESS: at 59.22% examples, 141499 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:10,248 : INFO : EPOCH 1 - PROGRESS: at 71.51% examples, 141792 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:11,265 : INFO : EPOCH 1 - PROGRESS: at 80.45% examples, 137381 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:12,280 : INFO : EPOCH 1 - PROGRESS: at 92.18% examples, 138110 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:12,946 : INFO : EPOCH 1: training on 1788017 raw words (1242014 effective words) took 9.0s, 138513 effective words/s\n",
      "2023-04-04 13:51:14,096 : INFO : EPOCH 2 - PROGRESS: at 8.94% examples, 105955 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:51:15,116 : INFO : EPOCH 2 - PROGRESS: at 22.35% examples, 134870 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:16,126 : INFO : EPOCH 2 - PROGRESS: at 36.87% examples, 149084 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:17,226 : INFO : EPOCH 2 - PROGRESS: at 50.84% examples, 151334 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:18,230 : INFO : EPOCH 2 - PROGRESS: at 64.25% examples, 153066 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:19,248 : INFO : EPOCH 2 - PROGRESS: at 75.42% examples, 150591 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:20,290 : INFO : EPOCH 2 - PROGRESS: at 86.03% examples, 147083 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:21,306 : INFO : EPOCH 2 - PROGRESS: at 93.30% examples, 139958 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:51:21,973 : INFO : EPOCH 2: training on 1788017 raw words (1242074 effective words) took 9.0s, 138684 effective words/s\n",
      "2023-04-04 13:51:23,056 : INFO : EPOCH 3 - PROGRESS: at 5.03% examples, 64569 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:51:24,139 : INFO : EPOCH 3 - PROGRESS: at 15.64% examples, 95097 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:25,153 : INFO : EPOCH 3 - PROGRESS: at 29.61% examples, 120872 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:26,229 : INFO : EPOCH 3 - PROGRESS: at 44.13% examples, 132657 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:27,233 : INFO : EPOCH 3 - PROGRESS: at 58.10% examples, 139677 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:28,251 : INFO : EPOCH 3 - PROGRESS: at 72.63% examples, 145667 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:29,265 : INFO : EPOCH 3 - PROGRESS: at 83.80% examples, 144504 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:30,274 : INFO : EPOCH 3 - PROGRESS: at 95.53% examples, 144511 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:30,667 : INFO : EPOCH 3: training on 1788017 raw words (1242215 effective words) took 8.6s, 144187 effective words/s\n",
      "2023-04-04 13:51:31,860 : INFO : EPOCH 4 - PROGRESS: at 5.59% examples, 63691 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:32,954 : INFO : EPOCH 4 - PROGRESS: at 17.32% examples, 98971 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:34,054 : INFO : EPOCH 4 - PROGRESS: at 29.05% examples, 110859 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:35,095 : INFO : EPOCH 4 - PROGRESS: at 42.46% examples, 122413 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:36,173 : INFO : EPOCH 4 - PROGRESS: at 55.87% examples, 128199 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:51:37,221 : INFO : EPOCH 4 - PROGRESS: at 69.27% examples, 132646 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:38,222 : INFO : EPOCH 4 - PROGRESS: at 79.89% examples, 132715 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:39,235 : INFO : EPOCH 4 - PROGRESS: at 91.62% examples, 134064 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:40,060 : INFO : EPOCH 4: training on 1788017 raw words (1242500 effective words) took 9.3s, 133212 effective words/s\n",
      "2023-04-04 13:51:40,061 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210746 effective words) took 45.3s, 137122 effective words/s', 'datetime': '2023-04-04T13:51:40.061741', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:51:40,063 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:51:40.063742', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:51:40,072 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #21: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 48.66086856524149, 'train_time_std': 1.2453250929376887}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:51:40,432 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:51:41,416 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:51:41,417 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:51:41,672 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:51:41.672628', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:51:41,675 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:51:41.675172', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:51:42,021 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:51:42,031 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:51:42,034 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:51:42.034607', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:51:42,070 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 13:51:43,833 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 13:51:44,153 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 13:51:44,157 : INFO : resetting layer weights\n",
      "2023-04-04 13:51:44,178 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:51:44.178031', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:51:44,180 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:51:44,181 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:51:44.181040', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:51:45,527 : INFO : EPOCH 0 - PROGRESS: at 3.91% examples, 39252 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:46,663 : INFO : EPOCH 0 - PROGRESS: at 10.61% examples, 56174 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:47,798 : INFO : EPOCH 0 - PROGRESS: at 17.32% examples, 61874 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:51:48,933 : INFO : EPOCH 0 - PROGRESS: at 22.91% examples, 61954 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:50,102 : INFO : EPOCH 0 - PROGRESS: at 27.93% examples, 60484 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:51,283 : INFO : EPOCH 0 - PROGRESS: at 32.96% examples, 58987 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:52,374 : INFO : EPOCH 0 - PROGRESS: at 37.99% examples, 58804 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:53,486 : INFO : EPOCH 0 - PROGRESS: at 43.02% examples, 58470 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:54,515 : INFO : EPOCH 0 - PROGRESS: at 48.04% examples, 58675 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:51:55,520 : INFO : EPOCH 0 - PROGRESS: at 53.07% examples, 58837 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:51:56,673 : INFO : EPOCH 0 - PROGRESS: at 59.22% examples, 59289 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:51:57,675 : INFO : EPOCH 0 - PROGRESS: at 65.36% examples, 60441 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:51:58,732 : INFO : EPOCH 0 - PROGRESS: at 71.51% examples, 61331 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:51:59,744 : INFO : EPOCH 0 - PROGRESS: at 76.54% examples, 61425 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:00,896 : INFO : EPOCH 0 - PROGRESS: at 82.12% examples, 61289 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:01,941 : INFO : EPOCH 0 - PROGRESS: at 87.71% examples, 61637 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:02,960 : INFO : EPOCH 0 - PROGRESS: at 93.30% examples, 61977 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:03,995 : INFO : EPOCH 0 - PROGRESS: at 97.77% examples, 61566 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:52:04,370 : INFO : EPOCH 0: training on 1788017 raw words (1242215 effective words) took 20.1s, 61720 effective words/s\n",
      "2023-04-04 13:52:05,709 : INFO : EPOCH 1 - PROGRESS: at 3.91% examples, 39363 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:52:06,933 : INFO : EPOCH 1 - PROGRESS: at 10.61% examples, 54328 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:08,148 : INFO : EPOCH 1 - PROGRESS: at 17.32% examples, 59101 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:09,450 : INFO : EPOCH 1 - PROGRESS: at 24.02% examples, 60633 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:10,711 : INFO : EPOCH 1 - PROGRESS: at 29.05% examples, 58597 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:11,772 : INFO : EPOCH 1 - PROGRESS: at 34.64% examples, 59406 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:12,851 : INFO : EPOCH 1 - PROGRESS: at 40.22% examples, 60113 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:14,011 : INFO : EPOCH 1 - PROGRESS: at 45.81% examples, 59986 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:15,227 : INFO : EPOCH 1 - PROGRESS: at 52.51% examples, 60816 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:16,243 : INFO : EPOCH 1 - PROGRESS: at 59.22% examples, 62376 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:17,367 : INFO : EPOCH 1 - PROGRESS: at 66.48% examples, 63804 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:18,470 : INFO : EPOCH 1 - PROGRESS: at 73.18% examples, 64780 words/s, in_qsize 5, out_qsize 1\n",
      "2023-04-04 13:52:19,612 : INFO : EPOCH 1 - PROGRESS: at 79.89% examples, 65427 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:20,863 : INFO : EPOCH 1 - PROGRESS: at 86.03% examples, 65105 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:21,894 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 63651 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:22,940 : INFO : EPOCH 1 - PROGRESS: at 94.41% examples, 63402 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:24,017 : INFO : EPOCH 1 - PROGRESS: at 99.44% examples, 63039 words/s, in_qsize 1, out_qsize 1\n",
      "2023-04-04 13:52:24,086 : INFO : EPOCH 1: training on 1788017 raw words (1241736 effective words) took 19.7s, 63170 effective words/s\n",
      "2023-04-04 13:52:25,450 : INFO : EPOCH 2 - PROGRESS: at 3.91% examples, 38786 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:26,470 : INFO : EPOCH 2 - PROGRESS: at 8.94% examples, 49431 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:27,646 : INFO : EPOCH 2 - PROGRESS: at 15.64% examples, 56792 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:28,740 : INFO : EPOCH 2 - PROGRESS: at 22.35% examples, 61809 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:29,743 : INFO : EPOCH 2 - PROGRESS: at 28.49% examples, 64682 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:30,922 : INFO : EPOCH 2 - PROGRESS: at 34.08% examples, 63471 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:31,929 : INFO : EPOCH 2 - PROGRESS: at 38.55% examples, 62461 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:33,008 : INFO : EPOCH 2 - PROGRESS: at 44.13% examples, 62637 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:34,145 : INFO : EPOCH 2 - PROGRESS: at 49.72% examples, 62395 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:35,214 : INFO : EPOCH 2 - PROGRESS: at 56.42% examples, 63656 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:36,236 : INFO : EPOCH 2 - PROGRESS: at 63.13% examples, 64917 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:37,317 : INFO : EPOCH 2 - PROGRESS: at 68.16% examples, 64287 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:38,340 : INFO : EPOCH 2 - PROGRESS: at 73.74% examples, 64613 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:39,585 : INFO : EPOCH 2 - PROGRESS: at 79.89% examples, 64396 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:40,718 : INFO : EPOCH 2 - PROGRESS: at 85.47% examples, 64166 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:41,850 : INFO : EPOCH 2 - PROGRESS: at 89.94% examples, 63242 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:42,913 : INFO : EPOCH 2 - PROGRESS: at 94.97% examples, 62962 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:43,931 : INFO : EPOCH 2 - PROGRESS: at 100.00% examples, 62805 words/s, in_qsize 0, out_qsize 1\n",
      "2023-04-04 13:52:43,932 : INFO : EPOCH 2: training on 1788017 raw words (1241971 effective words) took 19.8s, 62800 effective words/s\n",
      "2023-04-04 13:52:45,166 : INFO : EPOCH 3 - PROGRESS: at 3.91% examples, 43474 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:46,205 : INFO : EPOCH 3 - PROGRESS: at 10.61% examples, 61860 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:47,435 : INFO : EPOCH 3 - PROGRESS: at 17.32% examples, 64137 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:48,600 : INFO : EPOCH 3 - PROGRESS: at 24.02% examples, 66306 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:49,607 : INFO : EPOCH 3 - PROGRESS: at 30.73% examples, 69219 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:50,615 : INFO : EPOCH 3 - PROGRESS: at 36.31% examples, 69133 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:51,778 : INFO : EPOCH 3 - PROGRESS: at 42.46% examples, 68697 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:53,039 : INFO : EPOCH 3 - PROGRESS: at 49.16% examples, 68318 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:54,065 : INFO : EPOCH 3 - PROGRESS: at 54.75% examples, 68003 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:55,184 : INFO : EPOCH 3 - PROGRESS: at 59.22% examples, 65983 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:56,295 : INFO : EPOCH 3 - PROGRESS: at 65.92% examples, 66639 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:52:57,370 : INFO : EPOCH 3 - PROGRESS: at 71.51% examples, 66501 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:58,659 : INFO : EPOCH 3 - PROGRESS: at 78.21% examples, 66431 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:52:59,676 : INFO : EPOCH 3 - PROGRESS: at 84.36% examples, 66973 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:00,828 : INFO : EPOCH 3 - PROGRESS: at 89.94% examples, 66541 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:01,874 : INFO : EPOCH 3 - PROGRESS: at 95.53% examples, 66495 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:02,659 : INFO : EPOCH 3: training on 1788017 raw words (1241858 effective words) took 18.6s, 66602 effective words/s\n",
      "2023-04-04 13:53:03,735 : INFO : EPOCH 4 - PROGRESS: at 2.79% examples, 35506 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:04,771 : INFO : EPOCH 4 - PROGRESS: at 7.26% examples, 45739 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:06,062 : INFO : EPOCH 4 - PROGRESS: at 13.97% examples, 53248 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:07,065 : INFO : EPOCH 4 - PROGRESS: at 20.11% examples, 59000 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:08,113 : INFO : EPOCH 4 - PROGRESS: at 25.70% examples, 60555 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:09,182 : INFO : EPOCH 4 - PROGRESS: at 32.40% examples, 63362 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:10,197 : INFO : EPOCH 4 - PROGRESS: at 37.99% examples, 64035 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:11,287 : INFO : EPOCH 4 - PROGRESS: at 43.58% examples, 63971 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:12,314 : INFO : EPOCH 4 - PROGRESS: at 48.04% examples, 62881 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:13,397 : INFO : EPOCH 4 - PROGRESS: at 53.07% examples, 62195 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:14,494 : INFO : EPOCH 4 - PROGRESS: at 57.54% examples, 60947 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:15,522 : INFO : EPOCH 4 - PROGRESS: at 62.01% examples, 60220 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:16,669 : INFO : EPOCH 4 - PROGRESS: at 68.16% examples, 60702 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:17,795 : INFO : EPOCH 4 - PROGRESS: at 74.86% examples, 61786 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:18,825 : INFO : EPOCH 4 - PROGRESS: at 81.56% examples, 62993 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:20,121 : INFO : EPOCH 4 - PROGRESS: at 88.27% examples, 63140 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:21,125 : INFO : EPOCH 4 - PROGRESS: at 93.85% examples, 63443 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:22,238 : INFO : EPOCH 4 - PROGRESS: at 99.44% examples, 63314 words/s, in_qsize 1, out_qsize 1\n",
      "2023-04-04 13:53:22,248 : INFO : EPOCH 4: training on 1788017 raw words (1241910 effective words) took 19.5s, 63635 effective words/s\n",
      "2023-04-04 13:53:22,250 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6209690 effective words) took 98.1s, 63320 effective words/s', 'datetime': '2023-04-04T13:53:22.250860', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:53:22,252 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:53:22.252861', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:53:22,262 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:53:22,634 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:53:23,703 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:53:23,704 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:53:23,952 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:53:23.952646', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:53:23,954 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:53:23.954711', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:53:24,232 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:53:24,238 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:53:24,239 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:53:24.239458', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:53:24,269 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 13:53:26,186 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 13:53:26,630 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 13:53:26,631 : INFO : resetting layer weights\n",
      "2023-04-04 13:53:26,651 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:53:26.651584', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:53:26,652 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:53:26,659 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:53:26.658150', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:53:27,808 : INFO : EPOCH 0 - PROGRESS: at 2.23% examples, 26729 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:28,832 : INFO : EPOCH 0 - PROGRESS: at 7.26% examples, 44283 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:29,894 : INFO : EPOCH 0 - PROGRESS: at 12.29% examples, 49441 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:30,939 : INFO : EPOCH 0 - PROGRESS: at 17.32% examples, 52209 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:31,943 : INFO : EPOCH 0 - PROGRESS: at 22.35% examples, 54317 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:32,978 : INFO : EPOCH 0 - PROGRESS: at 27.93% examples, 56678 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:34,027 : INFO : EPOCH 0 - PROGRESS: at 34.08% examples, 58829 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:35,044 : INFO : EPOCH 0 - PROGRESS: at 38.55% examples, 58374 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:36,058 : INFO : EPOCH 0 - PROGRESS: at 44.13% examples, 59403 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:37,195 : INFO : EPOCH 0 - PROGRESS: at 50.84% examples, 60880 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:38,204 : INFO : EPOCH 0 - PROGRESS: at 57.54% examples, 62479 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:39,236 : INFO : EPOCH 0 - PROGRESS: at 64.25% examples, 63767 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:40,287 : INFO : EPOCH 0 - PROGRESS: at 70.39% examples, 64478 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:41,486 : INFO : EPOCH 0 - PROGRESS: at 76.54% examples, 64520 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:42,632 : INFO : EPOCH 0 - PROGRESS: at 80.45% examples, 62917 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:43,778 : INFO : EPOCH 0 - PROGRESS: at 85.47% examples, 62322 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:44,862 : INFO : EPOCH 0 - PROGRESS: at 90.50% examples, 62096 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:45,961 : INFO : EPOCH 0 - PROGRESS: at 96.09% examples, 62111 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:53:46,695 : INFO : EPOCH 0: training on 1788017 raw words (1241994 effective words) took 20.0s, 62197 effective words/s\n",
      "2023-04-04 13:53:48,012 : INFO : EPOCH 1 - PROGRESS: at 3.91% examples, 40088 words/s, in_qsize 3, out_qsize 2\n",
      "2023-04-04 13:53:49,089 : INFO : EPOCH 1 - PROGRESS: at 10.61% examples, 58233 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:50,135 : INFO : EPOCH 1 - PROGRESS: at 17.32% examples, 65067 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:51,188 : INFO : EPOCH 1 - PROGRESS: at 22.91% examples, 65499 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:52,256 : INFO : EPOCH 1 - PROGRESS: at 27.37% examples, 63078 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:53,368 : INFO : EPOCH 1 - PROGRESS: at 31.84% examples, 60673 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:54,386 : INFO : EPOCH 1 - PROGRESS: at 36.87% examples, 60768 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:53:55,519 : INFO : EPOCH 1 - PROGRESS: at 43.02% examples, 61654 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:56,610 : INFO : EPOCH 1 - PROGRESS: at 49.72% examples, 63281 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:57,675 : INFO : EPOCH 1 - PROGRESS: at 55.87% examples, 63855 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:53:58,864 : INFO : EPOCH 1 - PROGRESS: at 61.45% examples, 63068 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:00,098 : INFO : EPOCH 1 - PROGRESS: at 68.16% examples, 63400 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:01,154 : INFO : EPOCH 1 - PROGRESS: at 73.18% examples, 63163 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:02,279 : INFO : EPOCH 1 - PROGRESS: at 78.21% examples, 62674 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:03,314 : INFO : EPOCH 1 - PROGRESS: at 82.68% examples, 62101 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:04,419 : INFO : EPOCH 1 - PROGRESS: at 87.71% examples, 61767 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:05,438 : INFO : EPOCH 1 - PROGRESS: at 93.30% examples, 62098 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:06,489 : INFO : EPOCH 1 - PROGRESS: at 99.44% examples, 62589 words/s, in_qsize 1, out_qsize 1\n",
      "2023-04-04 13:54:06,529 : INFO : EPOCH 1: training on 1788017 raw words (1242016 effective words) took 19.8s, 62813 effective words/s\n",
      "2023-04-04 13:54:07,665 : INFO : EPOCH 2 - PROGRESS: at 3.91% examples, 46569 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:08,820 : INFO : EPOCH 2 - PROGRESS: at 10.61% examples, 60818 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:10,074 : INFO : EPOCH 2 - PROGRESS: at 17.32% examples, 63015 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:11,089 : INFO : EPOCH 2 - PROGRESS: at 22.91% examples, 64491 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:54:12,349 : INFO : EPOCH 2 - PROGRESS: at 29.05% examples, 63869 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:13,636 : INFO : EPOCH 2 - PROGRESS: at 35.75% examples, 63822 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:14,642 : INFO : EPOCH 2 - PROGRESS: at 40.78% examples, 63721 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:15,678 : INFO : EPOCH 2 - PROGRESS: at 46.37% examples, 63989 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:16,806 : INFO : EPOCH 2 - PROGRESS: at 52.51% examples, 64300 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:54:18,069 : INFO : EPOCH 2 - PROGRESS: at 59.22% examples, 64180 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:19,093 : INFO : EPOCH 2 - PROGRESS: at 65.36% examples, 64911 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:20,108 : INFO : EPOCH 2 - PROGRESS: at 70.95% examples, 65171 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:21,112 : INFO : EPOCH 2 - PROGRESS: at 77.09% examples, 66046 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:22,259 : INFO : EPOCH 2 - PROGRESS: at 82.68% examples, 65582 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:23,275 : INFO : EPOCH 2 - PROGRESS: at 87.71% examples, 65350 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:24,357 : INFO : EPOCH 2 - PROGRESS: at 92.74% examples, 64871 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:25,629 : INFO : EPOCH 2 - PROGRESS: at 97.77% examples, 63829 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:54:25,932 : INFO : EPOCH 2: training on 1788017 raw words (1241637 effective words) took 19.3s, 64178 effective words/s\n",
      "2023-04-04 13:54:27,028 : INFO : EPOCH 3 - PROGRESS: at 3.35% examples, 41589 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:28,210 : INFO : EPOCH 3 - PROGRESS: at 8.94% examples, 51705 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:29,214 : INFO : EPOCH 3 - PROGRESS: at 14.53% examples, 57253 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:30,240 : INFO : EPOCH 3 - PROGRESS: at 18.99% examples, 56789 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:31,426 : INFO : EPOCH 3 - PROGRESS: at 24.02% examples, 56084 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:32,686 : INFO : EPOCH 3 - PROGRESS: at 29.05% examples, 55011 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:33,706 : INFO : EPOCH 3 - PROGRESS: at 33.52% examples, 54771 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:34,709 : INFO : EPOCH 3 - PROGRESS: at 37.43% examples, 54032 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:35,770 : INFO : EPOCH 3 - PROGRESS: at 41.90% examples, 53886 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:36,917 : INFO : EPOCH 3 - PROGRESS: at 47.49% examples, 54561 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:37,917 : INFO : EPOCH 3 - PROGRESS: at 53.63% examples, 56227 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:39,095 : INFO : EPOCH 3 - PROGRESS: at 59.22% examples, 56252 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:40,377 : INFO : EPOCH 3 - PROGRESS: at 65.92% examples, 56924 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:41,408 : INFO : EPOCH 3 - PROGRESS: at 70.95% examples, 57196 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:42,419 : INFO : EPOCH 3 - PROGRESS: at 74.86% examples, 56684 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:43,474 : INFO : EPOCH 3 - PROGRESS: at 79.33% examples, 56466 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:44,615 : INFO : EPOCH 3 - PROGRESS: at 84.36% examples, 56356 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:45,838 : INFO : EPOCH 3 - PROGRESS: at 89.39% examples, 56035 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:46,871 : INFO : EPOCH 3 - PROGRESS: at 94.41% examples, 56234 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:47,878 : INFO : EPOCH 3 - PROGRESS: at 99.44% examples, 56445 words/s, in_qsize 1, out_qsize 1\n",
      "2023-04-04 13:54:47,937 : INFO : EPOCH 3: training on 1788017 raw words (1242146 effective words) took 21.9s, 56606 effective words/s\n",
      "2023-04-04 13:54:49,021 : INFO : EPOCH 4 - PROGRESS: at 2.23% examples, 28743 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:50,154 : INFO : EPOCH 4 - PROGRESS: at 7.26% examples, 43603 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:51,199 : INFO : EPOCH 4 - PROGRESS: at 12.29% examples, 49222 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:52,401 : INFO : EPOCH 4 - PROGRESS: at 16.20% examples, 46933 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:53,612 : INFO : EPOCH 4 - PROGRESS: at 21.23% examples, 48149 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:54,630 : INFO : EPOCH 4 - PROGRESS: at 25.70% examples, 49250 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:55,649 : INFO : EPOCH 4 - PROGRESS: at 30.73% examples, 50810 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:54:56,804 : INFO : EPOCH 4 - PROGRESS: at 36.31% examples, 52009 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:57,926 : INFO : EPOCH 4 - PROGRESS: at 43.02% examples, 54573 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:54:59,109 : INFO : EPOCH 4 - PROGRESS: at 49.72% examples, 56244 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:00,235 : INFO : EPOCH 4 - PROGRESS: at 56.42% examples, 57616 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:01,295 : INFO : EPOCH 4 - PROGRESS: at 61.45% examples, 57536 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:02,557 : INFO : EPOCH 4 - PROGRESS: at 65.36% examples, 55856 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:03,774 : INFO : EPOCH 4 - PROGRESS: at 70.39% examples, 55507 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:04,801 : INFO : EPOCH 4 - PROGRESS: at 75.42% examples, 55900 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:05,956 : INFO : EPOCH 4 - PROGRESS: at 80.45% examples, 55794 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:07,198 : INFO : EPOCH 4 - PROGRESS: at 87.15% examples, 56515 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:08,520 : INFO : EPOCH 4 - PROGRESS: at 93.85% examples, 56917 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:09,548 : INFO : EPOCH 4 - PROGRESS: at 100.00% examples, 57686 words/s, in_qsize 0, out_qsize 1\n",
      "2023-04-04 13:55:09,550 : INFO : EPOCH 4: training on 1788017 raw words (1242083 effective words) took 21.5s, 57682 effective words/s\n",
      "2023-04-04 13:55:09,550 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6209876 effective words) took 102.9s, 60354 effective words/s', 'datetime': '2023-04-04T13:55:09.550961', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:55:09,552 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:55:09.552969', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:55:09,570 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:55:09,851 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:55:10,478 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:55:10,480 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:55:10,647 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:55:10.647369', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:55:10,649 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:55:10.649365', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:55:10,851 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:55:10,859 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:55:10,861 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:55:10.860615', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:55:10,882 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 13:55:12,118 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 13:55:12,455 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 13:55:12,457 : INFO : resetting layer weights\n",
      "2023-04-04 13:55:12,482 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:55:12.482333', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:55:12,484 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:55:12,490 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:55:12.490944', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:55:13,815 : INFO : EPOCH 0 - PROGRESS: at 3.91% examples, 40261 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:14,850 : INFO : EPOCH 0 - PROGRESS: at 9.50% examples, 53250 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:15,986 : INFO : EPOCH 0 - PROGRESS: at 13.97% examples, 51841 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:17,154 : INFO : EPOCH 0 - PROGRESS: at 20.67% examples, 57229 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:18,185 : INFO : EPOCH 0 - PROGRESS: at 26.26% examples, 59259 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:19,383 : INFO : EPOCH 0 - PROGRESS: at 32.40% examples, 59934 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:20,522 : INFO : EPOCH 0 - PROGRESS: at 37.43% examples, 59177 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:21,599 : INFO : EPOCH 0 - PROGRESS: at 42.46% examples, 59081 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:22,837 : INFO : EPOCH 0 - PROGRESS: at 47.49% examples, 58016 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:23,855 : INFO : EPOCH 0 - PROGRESS: at 51.40% examples, 57019 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:55:25,071 : INFO : EPOCH 0 - PROGRESS: at 55.87% examples, 55739 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:26,149 : INFO : EPOCH 0 - PROGRESS: at 59.22% examples, 54255 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:27,187 : INFO : EPOCH 0 - PROGRESS: at 64.25% examples, 54561 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:28,217 : INFO : EPOCH 0 - PROGRESS: at 69.27% examples, 54973 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:29,291 : INFO : EPOCH 0 - PROGRESS: at 74.30% examples, 55225 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:30,391 : INFO : EPOCH 0 - PROGRESS: at 79.89% examples, 55728 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:31,437 : INFO : EPOCH 0 - PROGRESS: at 86.59% examples, 57072 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:32,437 : INFO : EPOCH 0 - PROGRESS: at 93.30% examples, 58369 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:33,490 : INFO : EPOCH 0 - PROGRESS: at 98.32% examples, 58440 words/s, in_qsize 3, out_qsize 0\n",
      "2023-04-04 13:55:34,025 : INFO : EPOCH 0: training on 1788017 raw words (1241781 effective words) took 21.5s, 57871 effective words/s\n",
      "2023-04-04 13:55:35,650 : INFO : EPOCH 1 - PROGRESS: at 0.56% examples, 6313 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:55:36,938 : INFO : EPOCH 1 - PROGRESS: at 5.59% examples, 29086 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:38,216 : INFO : EPOCH 1 - PROGRESS: at 10.61% examples, 36171 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:39,250 : INFO : EPOCH 1 - PROGRESS: at 16.76% examples, 44538 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:40,354 : INFO : EPOCH 1 - PROGRESS: at 18.99% examples, 41019 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:41,914 : INFO : EPOCH 1 - PROGRESS: at 24.02% examples, 40886 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:42,926 : INFO : EPOCH 1 - PROGRESS: at 27.93% examples, 41887 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:43,955 : INFO : EPOCH 1 - PROGRESS: at 32.40% examples, 43072 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:44,976 : INFO : EPOCH 1 - PROGRESS: at 37.43% examples, 44819 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:46,053 : INFO : EPOCH 1 - PROGRESS: at 42.46% examples, 46079 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:47,076 : INFO : EPOCH 1 - PROGRESS: at 47.49% examples, 47269 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:48,100 : INFO : EPOCH 1 - PROGRESS: at 52.51% examples, 48188 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:49,153 : INFO : EPOCH 1 - PROGRESS: at 58.66% examples, 49720 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:50,204 : INFO : EPOCH 1 - PROGRESS: at 62.57% examples, 49388 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:51,241 : INFO : EPOCH 1 - PROGRESS: at 67.60% examples, 50009 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:52,283 : INFO : EPOCH 1 - PROGRESS: at 70.95% examples, 49465 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:53,284 : INFO : EPOCH 1 - PROGRESS: at 75.42% examples, 49853 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:54,450 : INFO : EPOCH 1 - PROGRESS: at 80.45% examples, 50079 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:55,616 : INFO : EPOCH 1 - PROGRESS: at 85.47% examples, 50232 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:55:56,685 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 50033 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:57,750 : INFO : EPOCH 1 - PROGRESS: at 92.74% examples, 49516 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:58,785 : INFO : EPOCH 1 - PROGRESS: at 96.09% examples, 49135 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:55:59,690 : INFO : EPOCH 1: training on 1788017 raw words (1241410 effective words) took 25.2s, 49227 effective words/s\n",
      "2023-04-04 13:56:00,893 : INFO : EPOCH 2 - PROGRESS: at 2.23% examples, 26297 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:01,942 : INFO : EPOCH 2 - PROGRESS: at 7.26% examples, 43468 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:02,965 : INFO : EPOCH 2 - PROGRESS: at 11.73% examples, 47309 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:04,150 : INFO : EPOCH 2 - PROGRESS: at 17.32% examples, 50534 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:05,489 : INFO : EPOCH 2 - PROGRESS: at 24.02% examples, 53527 words/s, in_qsize 3, out_qsize 2\n",
      "2023-04-04 13:56:06,755 : INFO : EPOCH 2 - PROGRESS: at 29.05% examples, 52937 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:08,071 : INFO : EPOCH 2 - PROGRESS: at 34.08% examples, 51910 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:09,601 : INFO : EPOCH 2 - PROGRESS: at 39.11% examples, 50244 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:10,874 : INFO : EPOCH 2 - PROGRESS: at 44.13% examples, 50064 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:11,903 : INFO : EPOCH 2 - PROGRESS: at 49.16% examples, 50973 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:13,096 : INFO : EPOCH 2 - PROGRESS: at 55.87% examples, 52432 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:14,337 : INFO : EPOCH 2 - PROGRESS: at 62.57% examples, 53469 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:15,363 : INFO : EPOCH 2 - PROGRESS: at 68.16% examples, 54378 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:16,392 : INFO : EPOCH 2 - PROGRESS: at 73.18% examples, 54830 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:17,523 : INFO : EPOCH 2 - PROGRESS: at 78.21% examples, 54916 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:18,600 : INFO : EPOCH 2 - PROGRESS: at 83.80% examples, 55452 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:19,768 : INFO : EPOCH 2 - PROGRESS: at 87.71% examples, 54653 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:20,801 : INFO : EPOCH 2 - PROGRESS: at 93.30% examples, 55256 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:22,016 : INFO : EPOCH 2 - PROGRESS: at 97.77% examples, 54755 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:56:22,330 : INFO : EPOCH 2: training on 1788017 raw words (1242675 effective words) took 22.5s, 55153 effective words/s\n",
      "2023-04-04 13:56:23,433 : INFO : EPOCH 3 - PROGRESS: at 3.35% examples, 41686 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:24,714 : INFO : EPOCH 3 - PROGRESS: at 8.94% examples, 49451 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:26,040 : INFO : EPOCH 3 - PROGRESS: at 13.97% examples, 48658 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:27,206 : INFO : EPOCH 3 - PROGRESS: at 17.32% examples, 45726 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:28,425 : INFO : EPOCH 3 - PROGRESS: at 22.35% examples, 47012 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:29,497 : INFO : EPOCH 3 - PROGRESS: at 27.37% examples, 48919 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:30,499 : INFO : EPOCH 3 - PROGRESS: at 32.40% examples, 50451 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:31,526 : INFO : EPOCH 3 - PROGRESS: at 38.55% examples, 53192 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:32,576 : INFO : EPOCH 3 - PROGRESS: at 44.13% examples, 54496 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:33,609 : INFO : EPOCH 3 - PROGRESS: at 49.16% examples, 55038 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:34,638 : INFO : EPOCH 3 - PROGRESS: at 55.31% examples, 56428 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:35,756 : INFO : EPOCH 3 - PROGRESS: at 61.45% examples, 57191 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:36,875 : INFO : EPOCH 3 - PROGRESS: at 67.04% examples, 57495 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:37,901 : INFO : EPOCH 3 - PROGRESS: at 70.39% examples, 56426 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:39,119 : INFO : EPOCH 3 - PROGRESS: at 74.86% examples, 55675 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:40,324 : INFO : EPOCH 3 - PROGRESS: at 79.89% examples, 55426 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:41,327 : INFO : EPOCH 3 - PROGRESS: at 84.36% examples, 55435 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:42,382 : INFO : EPOCH 3 - PROGRESS: at 88.83% examples, 55280 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:43,548 : INFO : EPOCH 3 - PROGRESS: at 93.30% examples, 54849 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:44,559 : INFO : EPOCH 3 - PROGRESS: at 98.32% examples, 55189 words/s, in_qsize 3, out_qsize 0\n",
      "2023-04-04 13:56:44,792 : INFO : EPOCH 3: training on 1788017 raw words (1241989 effective words) took 22.4s, 55467 effective words/s\n",
      "2023-04-04 13:56:46,246 : INFO : EPOCH 4 - PROGRESS: at 3.91% examples, 36716 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:47,283 : INFO : EPOCH 4 - PROGRESS: at 8.94% examples, 47576 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:48,400 : INFO : EPOCH 4 - PROGRESS: at 13.97% examples, 50269 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:49,520 : INFO : EPOCH 4 - PROGRESS: at 18.99% examples, 51915 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:50,553 : INFO : EPOCH 4 - PROGRESS: at 22.91% examples, 51160 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:51,657 : INFO : EPOCH 4 - PROGRESS: at 27.93% examples, 52251 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:52,811 : INFO : EPOCH 4 - PROGRESS: at 34.64% examples, 54977 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:53,901 : INFO : EPOCH 4 - PROGRESS: at 40.78% examples, 56897 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:55,139 : INFO : EPOCH 4 - PROGRESS: at 46.37% examples, 56717 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:56:56,282 : INFO : EPOCH 4 - PROGRESS: at 51.40% examples, 56494 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:57,461 : INFO : EPOCH 4 - PROGRESS: at 56.42% examples, 55948 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:56:58,525 : INFO : EPOCH 4 - PROGRESS: at 60.34% examples, 54977 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:00,223 : INFO : EPOCH 4 - PROGRESS: at 64.80% examples, 52457 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:57:01,356 : INFO : EPOCH 4 - PROGRESS: at 69.83% examples, 52653 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:02,577 : INFO : EPOCH 4 - PROGRESS: at 76.54% examples, 53773 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:57:03,759 : INFO : EPOCH 4 - PROGRESS: at 83.24% examples, 54843 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:04,791 : INFO : EPOCH 4 - PROGRESS: at 89.39% examples, 55852 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:05,944 : INFO : EPOCH 4 - PROGRESS: at 93.85% examples, 55407 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:57:07,036 : INFO : EPOCH 4 - PROGRESS: at 97.77% examples, 54889 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:57:07,421 : INFO : EPOCH 4: training on 1788017 raw words (1242306 effective words) took 22.5s, 55114 effective words/s\n",
      "2023-04-04 13:57:07,422 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210161 effective words) took 114.9s, 54034 effective words/s', 'datetime': '2023-04-04T13:57:07.422582', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:57:07,425 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:57:07.425595', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:57:07,453 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:57:07,914 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #22: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 109.1268162727356, 'train_time_std': 6.534056513501884}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 13:57:09,361 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:57:09,365 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:57:09,818 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:57:09.817097', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:57:09,819 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:57:09.819111', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:57:10,294 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:57:10,302 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:57:10,310 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:57:10.310017', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:57:10,346 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 13:57:12,478 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 13:57:12,931 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 13:57:12,932 : INFO : resetting layer weights\n",
      "2023-04-04 13:57:12,961 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:57:12.961733', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:57:12,962 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:57:12,963 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:57:12.963717', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:57:14,437 : INFO : EPOCH 0 - PROGRESS: at 2.23% examples, 21251 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:57:15,692 : INFO : EPOCH 0 - PROGRESS: at 7.26% examples, 35783 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:57:17,021 : INFO : EPOCH 0 - PROGRESS: at 12.29% examples, 39821 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:57:18,243 : INFO : EPOCH 0 - PROGRESS: at 17.32% examples, 42663 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:19,647 : INFO : EPOCH 0 - PROGRESS: at 22.35% examples, 43204 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:20,772 : INFO : EPOCH 0 - PROGRESS: at 26.82% examples, 44252 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:21,846 : INFO : EPOCH 0 - PROGRESS: at 31.84% examples, 45861 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:22,985 : INFO : EPOCH 0 - PROGRESS: at 37.43% examples, 47586 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:24,049 : INFO : EPOCH 0 - PROGRESS: at 42.46% examples, 48672 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:57:25,231 : INFO : EPOCH 0 - PROGRESS: at 47.49% examples, 49077 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:26,826 : INFO : EPOCH 0 - PROGRESS: at 52.51% examples, 47830 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:27,865 : INFO : EPOCH 0 - PROGRESS: at 56.42% examples, 47650 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:29,169 : INFO : EPOCH 0 - PROGRESS: at 60.89% examples, 47093 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:30,225 : INFO : EPOCH 0 - PROGRESS: at 64.80% examples, 46995 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:31,303 : INFO : EPOCH 0 - PROGRESS: at 68.72% examples, 46875 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:32,351 : INFO : EPOCH 0 - PROGRESS: at 72.07% examples, 46524 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:33,376 : INFO : EPOCH 0 - PROGRESS: at 74.86% examples, 45906 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:57:34,438 : INFO : EPOCH 0 - PROGRESS: at 79.89% examples, 46558 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:35,498 : INFO : EPOCH 0 - PROGRESS: at 85.47% examples, 47447 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:57:36,669 : INFO : EPOCH 0 - PROGRESS: at 90.50% examples, 47776 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:37,713 : INFO : EPOCH 0 - PROGRESS: at 95.53% examples, 48261 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:57:38,505 : INFO : EPOCH 0: training on 1788017 raw words (1242444 effective words) took 25.4s, 48887 effective words/s\n",
      "2023-04-04 13:57:39,652 : INFO : EPOCH 1 - PROGRESS: at 2.23% examples, 27546 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:40,700 : INFO : EPOCH 1 - PROGRESS: at 7.26% examples, 44483 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:41,864 : INFO : EPOCH 1 - PROGRESS: at 12.29% examples, 48084 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:42,998 : INFO : EPOCH 1 - PROGRESS: at 17.32% examples, 50083 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:44,004 : INFO : EPOCH 1 - PROGRESS: at 21.79% examples, 51187 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:45,008 : INFO : EPOCH 1 - PROGRESS: at 26.26% examples, 52019 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:46,024 : INFO : EPOCH 1 - PROGRESS: at 31.28% examples, 53173 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:47,086 : INFO : EPOCH 1 - PROGRESS: at 36.31% examples, 53882 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:57:48,184 : INFO : EPOCH 1 - PROGRESS: at 40.78% examples, 53601 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:49,319 : INFO : EPOCH 1 - PROGRESS: at 45.81% examples, 53657 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:50,772 : INFO : EPOCH 1 - PROGRESS: at 50.84% examples, 52355 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:51,777 : INFO : EPOCH 1 - PROGRESS: at 56.42% examples, 53426 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:57:52,886 : INFO : EPOCH 1 - PROGRESS: at 62.57% examples, 54405 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:53,895 : INFO : EPOCH 1 - PROGRESS: at 68.72% examples, 55797 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:54,997 : INFO : EPOCH 1 - PROGRESS: at 74.30% examples, 56342 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:56,016 : INFO : EPOCH 1 - PROGRESS: at 79.33% examples, 56677 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:57,196 : INFO : EPOCH 1 - PROGRESS: at 85.47% examples, 57155 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:57:58,229 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 56657 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:57:59,349 : INFO : EPOCH 1 - PROGRESS: at 92.74% examples, 55586 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:00,360 : INFO : EPOCH 1 - PROGRESS: at 97.21% examples, 55564 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:01,075 : INFO : EPOCH 1: training on 1788017 raw words (1241943 effective words) took 22.5s, 55272 effective words/s\n",
      "2023-04-04 13:58:02,257 : INFO : EPOCH 2 - PROGRESS: at 2.23% examples, 25958 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:03,269 : INFO : EPOCH 2 - PROGRESS: at 7.82% examples, 47226 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:04,277 : INFO : EPOCH 2 - PROGRESS: at 13.41% examples, 54401 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:05,449 : INFO : EPOCH 2 - PROGRESS: at 18.99% examples, 56014 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:06,822 : INFO : EPOCH 2 - PROGRESS: at 25.70% examples, 57329 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:07,869 : INFO : EPOCH 2 - PROGRESS: at 30.73% examples, 57647 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:08,901 : INFO : EPOCH 2 - PROGRESS: at 35.75% examples, 58009 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:09,966 : INFO : EPOCH 2 - PROGRESS: at 40.78% examples, 58184 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:10,996 : INFO : EPOCH 2 - PROGRESS: at 45.81% examples, 58337 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:12,223 : INFO : EPOCH 2 - PROGRESS: at 50.84% examples, 57509 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:13,360 : INFO : EPOCH 2 - PROGRESS: at 57.54% examples, 58673 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:14,373 : INFO : EPOCH 2 - PROGRESS: at 63.13% examples, 59247 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:15,432 : INFO : EPOCH 2 - PROGRESS: at 67.60% examples, 58710 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:16,525 : INFO : EPOCH 2 - PROGRESS: at 73.18% examples, 59126 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:17,824 : INFO : EPOCH 2 - PROGRESS: at 78.21% examples, 58330 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:18,918 : INFO : EPOCH 2 - PROGRESS: at 82.68% examples, 57852 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:20,049 : INFO : EPOCH 2 - PROGRESS: at 87.15% examples, 57327 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:21,084 : INFO : EPOCH 2 - PROGRESS: at 90.50% examples, 56464 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:22,117 : INFO : EPOCH 2 - PROGRESS: at 95.53% examples, 56634 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:22,903 : INFO : EPOCH 2: training on 1788017 raw words (1241515 effective words) took 21.8s, 57069 effective words/s\n",
      "2023-04-04 13:58:24,246 : INFO : EPOCH 3 - PROGRESS: at 3.91% examples, 39164 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:25,512 : INFO : EPOCH 3 - PROGRESS: at 10.61% examples, 53265 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:26,666 : INFO : EPOCH 3 - PROGRESS: at 15.64% examples, 53641 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:27,694 : INFO : EPOCH 3 - PROGRESS: at 21.23% examples, 56936 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:28,891 : INFO : EPOCH 3 - PROGRESS: at 25.70% examples, 54901 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:30,010 : INFO : EPOCH 3 - PROGRESS: at 30.73% examples, 54985 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:31,214 : INFO : EPOCH 3 - PROGRESS: at 35.75% examples, 54495 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:32,455 : INFO : EPOCH 3 - PROGRESS: at 40.78% examples, 54013 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 13:58:33,465 : INFO : EPOCH 3 - PROGRESS: at 45.81% examples, 54710 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:34,789 : INFO : EPOCH 3 - PROGRESS: at 50.84% examples, 53790 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:36,054 : INFO : EPOCH 3 - PROGRESS: at 57.54% examples, 54748 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:37,070 : INFO : EPOCH 3 - PROGRESS: at 63.13% examples, 55563 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:38,148 : INFO : EPOCH 3 - PROGRESS: at 68.16% examples, 55704 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:39,462 : INFO : EPOCH 3 - PROGRESS: at 73.18% examples, 55118 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:40,528 : INFO : EPOCH 3 - PROGRESS: at 77.09% examples, 54625 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:41,648 : INFO : EPOCH 3 - PROGRESS: at 82.12% examples, 54631 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:42,728 : INFO : EPOCH 3 - PROGRESS: at 87.15% examples, 54832 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:43,730 : INFO : EPOCH 3 - PROGRESS: at 92.18% examples, 55194 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:44,992 : INFO : EPOCH 3 - PROGRESS: at 97.77% examples, 55188 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:58:45,334 : INFO : EPOCH 3: training on 1788017 raw words (1241906 effective words) took 22.4s, 55511 effective words/s\n",
      "2023-04-04 13:58:46,457 : INFO : EPOCH 4 - PROGRESS: at 2.23% examples, 27117 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:47,533 : INFO : EPOCH 4 - PROGRESS: at 7.26% examples, 43669 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:48,824 : INFO : EPOCH 4 - PROGRESS: at 12.29% examples, 45719 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:50,307 : INFO : EPOCH 4 - PROGRESS: at 17.32% examples, 44800 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:51,537 : INFO : EPOCH 4 - PROGRESS: at 22.35% examples, 46176 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:52,568 : INFO : EPOCH 4 - PROGRESS: at 27.37% examples, 48417 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:53,608 : INFO : EPOCH 4 - PROGRESS: at 32.96% examples, 50627 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:54,678 : INFO : EPOCH 4 - PROGRESS: at 39.11% examples, 53094 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:55,948 : INFO : EPOCH 4 - PROGRESS: at 44.69% examples, 53227 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 13:58:57,058 : INFO : EPOCH 4 - PROGRESS: at 49.16% examples, 52913 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:58:58,144 : INFO : EPOCH 4 - PROGRESS: at 53.63% examples, 52599 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:58:59,306 : INFO : EPOCH 4 - PROGRESS: at 58.66% examples, 52516 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:00,342 : INFO : EPOCH 4 - PROGRESS: at 63.13% examples, 52480 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:01,816 : INFO : EPOCH 4 - PROGRESS: at 68.16% examples, 51551 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:03,023 : INFO : EPOCH 4 - PROGRESS: at 73.18% examples, 51619 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:04,053 : INFO : EPOCH 4 - PROGRESS: at 78.21% examples, 52167 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:05,221 : INFO : EPOCH 4 - PROGRESS: at 83.80% examples, 52584 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:06,402 : INFO : EPOCH 4 - PROGRESS: at 88.83% examples, 52607 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:07,632 : INFO : EPOCH 4 - PROGRESS: at 93.85% examples, 52491 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:08,805 : INFO : EPOCH 4 - PROGRESS: at 97.77% examples, 51954 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:59:09,211 : INFO : EPOCH 4: training on 1788017 raw words (1241974 effective words) took 23.8s, 52166 effective words/s\n",
      "2023-04-04 13:59:09,213 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6209782 effective words) took 116.2s, 53418 effective words/s', 'datetime': '2023-04-04T13:59:09.213163', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:59:09,215 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T13:59:09.215164', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 13:59:09,244 : INFO : collecting all words and their counts\n",
      "2023-04-04 13:59:09,711 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 13:59:11,012 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 13:59:11,013 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 13:59:11,365 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T13:59:11.365154', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:59:11,366 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T13:59:11.366153', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:59:11,728 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 13:59:11,734 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 13:59:11,738 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T13:59:11.738236', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 13:59:11,762 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 13:59:13,240 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 13:59:13,601 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 13:59:13,603 : INFO : resetting layer weights\n",
      "2023-04-04 13:59:13,623 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T13:59:13.623446', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 13:59:13,626 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 13:59:13,627 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T13:59:13.627954', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 13:59:15,098 : INFO : EPOCH 0 - PROGRESS: at 2.23% examples, 21750 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:16,151 : INFO : EPOCH 0 - PROGRESS: at 7.82% examples, 42045 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:17,188 : INFO : EPOCH 0 - PROGRESS: at 13.41% examples, 49760 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:18,289 : INFO : EPOCH 0 - PROGRESS: at 17.32% examples, 48589 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:19,517 : INFO : EPOCH 0 - PROGRESS: at 20.67% examples, 45614 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:20,539 : INFO : EPOCH 0 - PROGRESS: at 24.58% examples, 45975 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:21,801 : INFO : EPOCH 0 - PROGRESS: at 29.05% examples, 45801 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:22,813 : INFO : EPOCH 0 - PROGRESS: at 33.52% examples, 46679 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:23,844 : INFO : EPOCH 0 - PROGRESS: at 37.99% examples, 47442 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:24,846 : INFO : EPOCH 0 - PROGRESS: at 43.02% examples, 48772 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:25,982 : INFO : EPOCH 0 - PROGRESS: at 47.49% examples, 48775 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:27,164 : INFO : EPOCH 0 - PROGRESS: at 52.51% examples, 49051 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:28,364 : INFO : EPOCH 0 - PROGRESS: at 57.54% examples, 49123 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:29,423 : INFO : EPOCH 0 - PROGRESS: at 61.45% examples, 48787 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:30,476 : INFO : EPOCH 0 - PROGRESS: at 65.36% examples, 48605 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:31,477 : INFO : EPOCH 0 - PROGRESS: at 68.72% examples, 48184 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:32,516 : INFO : EPOCH 0 - PROGRESS: at 72.63% examples, 48143 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:33,571 : INFO : EPOCH 0 - PROGRESS: at 76.54% examples, 48091 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:34,669 : INFO : EPOCH 0 - PROGRESS: at 80.45% examples, 47880 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:35,950 : INFO : EPOCH 0 - PROGRESS: at 85.47% examples, 47909 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:37,113 : INFO : EPOCH 0 - PROGRESS: at 90.50% examples, 48235 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:38,118 : INFO : EPOCH 0 - PROGRESS: at 93.85% examples, 47917 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:39,282 : INFO : EPOCH 0 - PROGRESS: at 97.77% examples, 47651 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 13:59:39,747 : INFO : EPOCH 0: training on 1788017 raw words (1241863 effective words) took 26.0s, 47803 effective words/s\n",
      "2023-04-04 13:59:41,212 : INFO : EPOCH 1 - PROGRESS: at 2.23% examples, 21319 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:42,323 : INFO : EPOCH 1 - PROGRESS: at 5.59% examples, 29158 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:43,559 : INFO : EPOCH 1 - PROGRESS: at 10.61% examples, 36759 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:44,609 : INFO : EPOCH 1 - PROGRESS: at 16.20% examples, 43321 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:45,759 : INFO : EPOCH 1 - PROGRESS: at 20.67% examples, 44494 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:46,759 : INFO : EPOCH 1 - PROGRESS: at 24.58% examples, 45188 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:47,784 : INFO : EPOCH 1 - PROGRESS: at 28.49% examples, 45591 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:48,938 : INFO : EPOCH 1 - PROGRESS: at 30.73% examples, 42713 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:50,156 : INFO : EPOCH 1 - PROGRESS: at 34.08% examples, 41710 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:51,230 : INFO : EPOCH 1 - PROGRESS: at 37.99% examples, 42049 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:52,243 : INFO : EPOCH 1 - PROGRESS: at 42.46% examples, 43098 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:53,323 : INFO : EPOCH 1 - PROGRESS: at 47.49% examples, 44255 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:54,490 : INFO : EPOCH 1 - PROGRESS: at 52.51% examples, 44916 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:55,499 : INFO : EPOCH 1 - PROGRESS: at 57.54% examples, 45843 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:56,695 : INFO : EPOCH 1 - PROGRESS: at 62.57% examples, 46158 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 13:59:57,857 : INFO : EPOCH 1 - PROGRESS: at 64.25% examples, 44328 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 13:59:59,248 : INFO : EPOCH 1 - PROGRESS: at 67.60% examples, 43262 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:00,273 : INFO : EPOCH 1 - PROGRESS: at 72.07% examples, 43872 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:01,307 : INFO : EPOCH 1 - PROGRESS: at 75.98% examples, 44062 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:02,376 : INFO : EPOCH 1 - PROGRESS: at 81.56% examples, 45020 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:03,800 : INFO : EPOCH 1 - PROGRESS: at 87.15% examples, 45270 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:04,935 : INFO : EPOCH 1 - PROGRESS: at 92.74% examples, 45982 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:05,982 : INFO : EPOCH 1 - PROGRESS: at 97.21% examples, 46269 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:06,632 : INFO : EPOCH 1: training on 1788017 raw words (1241925 effective words) took 26.8s, 46389 effective words/s\n",
      "2023-04-04 14:00:07,718 : INFO : EPOCH 2 - PROGRESS: at 2.23% examples, 28332 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:08,931 : INFO : EPOCH 2 - PROGRESS: at 7.26% examples, 41690 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:10,329 : INFO : EPOCH 2 - PROGRESS: at 10.61% examples, 37397 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 14:00:11,489 : INFO : EPOCH 2 - PROGRESS: at 15.08% examples, 39892 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:12,694 : INFO : EPOCH 2 - PROGRESS: at 18.99% examples, 40184 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:13,803 : INFO : EPOCH 2 - PROGRESS: at 24.02% examples, 42831 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:14,810 : INFO : EPOCH 2 - PROGRESS: at 30.17% examples, 47043 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:15,924 : INFO : EPOCH 2 - PROGRESS: at 35.75% examples, 48779 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:17,218 : INFO : EPOCH 2 - PROGRESS: at 42.46% examples, 50716 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:18,223 : INFO : EPOCH 2 - PROGRESS: at 48.60% examples, 52926 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:19,281 : INFO : EPOCH 2 - PROGRESS: at 52.51% examples, 52226 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:20,436 : INFO : EPOCH 2 - PROGRESS: at 57.54% examples, 52223 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:21,506 : INFO : EPOCH 2 - PROGRESS: at 62.57% examples, 52519 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:22,643 : INFO : EPOCH 2 - PROGRESS: at 65.92% examples, 51370 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:23,717 : INFO : EPOCH 2 - PROGRESS: at 69.27% examples, 50592 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:24,740 : INFO : EPOCH 2 - PROGRESS: at 74.30% examples, 51226 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:25,793 : INFO : EPOCH 2 - PROGRESS: at 79.89% examples, 52055 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:26,958 : INFO : EPOCH 2 - PROGRESS: at 85.47% examples, 52471 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:28,361 : INFO : EPOCH 2 - PROGRESS: at 91.06% examples, 52318 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:29,625 : INFO : EPOCH 2 - PROGRESS: at 96.09% examples, 52149 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:30,331 : INFO : EPOCH 2: training on 1788017 raw words (1242331 effective words) took 23.6s, 52571 effective words/s\n",
      "2023-04-04 14:00:31,438 : INFO : EPOCH 3 - PROGRESS: at 2.23% examples, 27798 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:32,620 : INFO : EPOCH 3 - PROGRESS: at 7.26% examples, 41949 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:33,743 : INFO : EPOCH 3 - PROGRESS: at 12.29% examples, 46863 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:34,852 : INFO : EPOCH 3 - PROGRESS: at 17.88% examples, 51024 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:35,991 : INFO : EPOCH 3 - PROGRESS: at 24.02% examples, 54451 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:37,151 : INFO : EPOCH 3 - PROGRESS: at 29.61% examples, 55543 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:38,250 : INFO : EPOCH 3 - PROGRESS: at 34.64% examples, 55567 words/s, in_qsize 4, out_qsize 1\n",
      "2023-04-04 14:00:39,300 : INFO : EPOCH 3 - PROGRESS: at 37.43% examples, 52910 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:40,574 : INFO : EPOCH 3 - PROGRESS: at 39.66% examples, 49084 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:41,595 : INFO : EPOCH 3 - PROGRESS: at 44.13% examples, 49523 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:42,860 : INFO : EPOCH 3 - PROGRESS: at 48.04% examples, 48410 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 14:00:44,100 : INFO : EPOCH 3 - PROGRESS: at 53.07% examples, 48426 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:45,200 : INFO : EPOCH 3 - PROGRESS: at 58.10% examples, 48897 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:46,330 : INFO : EPOCH 3 - PROGRESS: at 63.69% examples, 49663 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:47,332 : INFO : EPOCH 3 - PROGRESS: at 69.27% examples, 50828 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:48,423 : INFO : EPOCH 3 - PROGRESS: at 74.86% examples, 51653 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:49,518 : INFO : EPOCH 3 - PROGRESS: at 79.89% examples, 51977 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:50,588 : INFO : EPOCH 3 - PROGRESS: at 83.24% examples, 51289 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:51,741 : INFO : EPOCH 3 - PROGRESS: at 87.71% examples, 51139 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:52,912 : INFO : EPOCH 3 - PROGRESS: at 92.74% examples, 51231 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:53,958 : INFO : EPOCH 3 - PROGRESS: at 97.21% examples, 51325 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:00:54,702 : INFO : EPOCH 3: training on 1788017 raw words (1242348 effective words) took 24.3s, 51121 effective words/s\n",
      "2023-04-04 14:00:55,810 : INFO : EPOCH 4 - PROGRESS: at 2.23% examples, 27629 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:56,857 : INFO : EPOCH 4 - PROGRESS: at 7.26% examples, 44537 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:58,345 : INFO : EPOCH 4 - PROGRESS: at 12.29% examples, 43739 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:00:59,443 : INFO : EPOCH 4 - PROGRESS: at 16.76% examples, 45507 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:00,743 : INFO : EPOCH 4 - PROGRESS: at 18.99% examples, 40347 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:01,855 : INFO : EPOCH 4 - PROGRESS: at 22.91% examples, 40992 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:02,989 : INFO : EPOCH 4 - PROGRESS: at 27.37% examples, 42219 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:04,021 : INFO : EPOCH 4 - PROGRESS: at 31.28% examples, 42619 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:05,133 : INFO : EPOCH 4 - PROGRESS: at 34.64% examples, 42088 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:06,204 : INFO : EPOCH 4 - PROGRESS: at 39.11% examples, 43073 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:07,211 : INFO : EPOCH 4 - PROGRESS: at 44.69% examples, 45134 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:08,285 : INFO : EPOCH 4 - PROGRESS: at 50.84% examples, 47161 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:09,415 : INFO : EPOCH 4 - PROGRESS: at 57.54% examples, 48991 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:10,524 : INFO : EPOCH 4 - PROGRESS: at 62.01% examples, 48921 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:11,625 : INFO : EPOCH 4 - PROGRESS: at 65.36% examples, 48194 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:12,678 : INFO : EPOCH 4 - PROGRESS: at 69.83% examples, 48459 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:13,792 : INFO : EPOCH 4 - PROGRESS: at 75.98% examples, 49717 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:14,972 : INFO : EPOCH 4 - PROGRESS: at 81.56% examples, 50217 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:16,008 : INFO : EPOCH 4 - PROGRESS: at 86.59% examples, 50743 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:17,041 : INFO : EPOCH 4 - PROGRESS: at 92.18% examples, 51501 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:18,086 : INFO : EPOCH 4 - PROGRESS: at 97.77% examples, 52169 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 14:01:18,337 : INFO : EPOCH 4: training on 1788017 raw words (1242710 effective words) took 23.6s, 52721 effective words/s\n",
      "2023-04-04 14:01:18,338 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211177 effective words) took 124.7s, 49806 effective words/s', 'datetime': '2023-04-04T14:01:18.338088', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 14:01:18,339 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T14:01:18.339086', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 14:01:18,371 : INFO : collecting all words and their counts\n",
      "2023-04-04 14:01:18,679 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 14:01:19,588 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2023-04-04 14:01:19,590 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 14:01:19,866 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.56% of original 73167, drops 53000)', 'datetime': '2023-04-04T14:01:19.866881', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 14:01:19,867 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.29% of original 1788017, drops 84301)', 'datetime': '2023-04-04T14:01:19.867876', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 14:01:20,288 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2023-04-04 14:01:20,300 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2023-04-04 14:01:20,301 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2023-04-04T14:01:20.301596', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 14:01:20,336 : INFO : constructing a huffman tree from 20167 words\n",
      "2023-04-04 14:01:21,883 : INFO : built huffman tree with maximum node depth 18\n",
      "2023-04-04 14:01:22,226 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2023-04-04 14:01:22,228 : INFO : resetting layer weights\n",
      "2023-04-04 14:01:22,251 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T14:01:22.250889', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 14:01:22,252 : WARNING : Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n",
      "2023-04-04 14:01:22,256 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T14:01:22.256374', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 14:01:23,384 : INFO : EPOCH 0 - PROGRESS: at 2.23% examples, 28133 words/s, in_qsize 5, out_qsize 1\n",
      "2023-04-04 14:01:24,512 : INFO : EPOCH 0 - PROGRESS: at 7.26% examples, 43162 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 14:01:25,536 : INFO : EPOCH 0 - PROGRESS: at 14.53% examples, 57952 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:26,686 : INFO : EPOCH 0 - PROGRESS: at 20.67% examples, 60631 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:27,846 : INFO : EPOCH 0 - PROGRESS: at 27.37% examples, 63225 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:29,016 : INFO : EPOCH 0 - PROGRESS: at 32.96% examples, 62364 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:30,171 : INFO : EPOCH 0 - PROGRESS: at 37.99% examples, 61198 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:31,267 : INFO : EPOCH 0 - PROGRESS: at 44.69% examples, 63021 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:32,352 : INFO : EPOCH 0 - PROGRESS: at 51.40% examples, 64461 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:33,419 : INFO : EPOCH 0 - PROGRESS: at 58.10% examples, 65438 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:34,445 : INFO : EPOCH 0 - PROGRESS: at 65.36% examples, 67192 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:35,448 : INFO : EPOCH 0 - PROGRESS: at 72.07% examples, 68441 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:36,467 : INFO : EPOCH 0 - PROGRESS: at 78.77% examples, 69462 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:37,599 : INFO : EPOCH 0 - PROGRESS: at 85.47% examples, 69748 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:38,637 : INFO : EPOCH 0 - PROGRESS: at 91.62% examples, 70030 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:39,640 : INFO : EPOCH 0 - PROGRESS: at 96.65% examples, 69580 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:40,541 : INFO : EPOCH 0: training on 1788017 raw words (1242628 effective words) took 18.2s, 68341 effective words/s\n",
      "2023-04-04 14:01:41,991 : INFO : EPOCH 1 - PROGRESS: at 3.91% examples, 36974 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:43,024 : INFO : EPOCH 1 - PROGRESS: at 8.94% examples, 47855 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:44,053 : INFO : EPOCH 1 - PROGRESS: at 13.97% examples, 51825 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:45,091 : INFO : EPOCH 1 - PROGRESS: at 17.88% examples, 50973 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:46,191 : INFO : EPOCH 1 - PROGRESS: at 22.35% examples, 50959 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:47,239 : INFO : EPOCH 1 - PROGRESS: at 26.26% examples, 50377 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:48,353 : INFO : EPOCH 1 - PROGRESS: at 30.73% examples, 50212 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:49,367 : INFO : EPOCH 1 - PROGRESS: at 33.52% examples, 48340 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:50,545 : INFO : EPOCH 1 - PROGRESS: at 39.66% examples, 50378 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:51,549 : INFO : EPOCH 1 - PROGRESS: at 45.81% examples, 52662 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:52,574 : INFO : EPOCH 1 - PROGRESS: at 51.40% examples, 53950 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:53,590 : INFO : EPOCH 1 - PROGRESS: at 57.54% examples, 55348 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:54,692 : INFO : EPOCH 1 - PROGRESS: at 63.69% examples, 56278 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:55,887 : INFO : EPOCH 1 - PROGRESS: at 68.72% examples, 55954 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:01:56,938 : INFO : EPOCH 1 - PROGRESS: at 72.07% examples, 54948 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:01:58,226 : INFO : EPOCH 1 - PROGRESS: at 77.09% examples, 54567 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 14:01:59,455 : INFO : EPOCH 1 - PROGRESS: at 82.12% examples, 54255 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:00,497 : INFO : EPOCH 1 - PROGRESS: at 87.15% examples, 54579 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:01,516 : INFO : EPOCH 1 - PROGRESS: at 92.18% examples, 54911 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:02,518 : INFO : EPOCH 1 - PROGRESS: at 96.09% examples, 54607 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:03,029 : INFO : EPOCH 1: training on 1788017 raw words (1242615 effective words) took 22.4s, 55466 effective words/s\n",
      "2023-04-04 14:02:04,243 : INFO : EPOCH 2 - PROGRESS: at 2.79% examples, 30911 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:05,263 : INFO : EPOCH 2 - PROGRESS: at 7.26% examples, 42824 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:06,407 : INFO : EPOCH 2 - PROGRESS: at 12.29% examples, 47243 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:07,680 : INFO : EPOCH 2 - PROGRESS: at 17.32% examples, 47941 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:09,378 : INFO : EPOCH 2 - PROGRESS: at 22.35% examples, 45076 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:10,589 : INFO : EPOCH 2 - PROGRESS: at 27.37% examples, 46300 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:11,661 : INFO : EPOCH 2 - PROGRESS: at 32.96% examples, 48502 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:12,790 : INFO : EPOCH 2 - PROGRESS: at 39.11% examples, 50803 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:13,957 : INFO : EPOCH 2 - PROGRESS: at 44.13% examples, 51025 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:14,960 : INFO : EPOCH 2 - PROGRESS: at 48.04% examples, 50813 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:16,028 : INFO : EPOCH 2 - PROGRESS: at 53.07% examples, 51286 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:17,074 : INFO : EPOCH 2 - PROGRESS: at 56.98% examples, 50827 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:18,204 : INFO : EPOCH 2 - PROGRESS: at 60.89% examples, 50078 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:19,632 : INFO : EPOCH 2 - PROGRESS: at 65.36% examples, 49083 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:20,707 : INFO : EPOCH 2 - PROGRESS: at 68.72% examples, 48424 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:21,744 : INFO : EPOCH 2 - PROGRESS: at 73.74% examples, 49131 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:22,800 : INFO : EPOCH 2 - PROGRESS: at 79.89% examples, 50406 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:23,837 : INFO : EPOCH 2 - PROGRESS: at 85.47% examples, 51216 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:24,869 : INFO : EPOCH 2 - PROGRESS: at 90.50% examples, 51704 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:26,014 : INFO : EPOCH 2 - PROGRESS: at 96.09% examples, 52131 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:26,701 : INFO : EPOCH 2: training on 1788017 raw words (1241980 effective words) took 23.6s, 52599 effective words/s\n",
      "2023-04-04 14:02:28,062 : INFO : EPOCH 3 - PROGRESS: at 2.23% examples, 22763 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:29,315 : INFO : EPOCH 3 - PROGRESS: at 7.26% examples, 36941 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:30,872 : INFO : EPOCH 3 - PROGRESS: at 12.29% examples, 38371 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-04 14:02:32,071 : INFO : EPOCH 3 - PROGRESS: at 17.32% examples, 41658 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:33,096 : INFO : EPOCH 3 - PROGRESS: at 22.35% examples, 44974 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:34,218 : INFO : EPOCH 3 - PROGRESS: at 27.93% examples, 47692 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:35,323 : INFO : EPOCH 3 - PROGRESS: at 34.08% examples, 50336 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:36,584 : INFO : EPOCH 3 - PROGRESS: at 39.11% examples, 50297 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:37,781 : INFO : EPOCH 3 - PROGRESS: at 44.13% examples, 50452 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:39,027 : INFO : EPOCH 3 - PROGRESS: at 49.16% examples, 50429 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:40,146 : INFO : EPOCH 3 - PROGRESS: at 54.19% examples, 50708 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:41,202 : INFO : EPOCH 3 - PROGRESS: at 59.22% examples, 51141 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:42,222 : INFO : EPOCH 3 - PROGRESS: at 64.25% examples, 51729 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:43,253 : INFO : EPOCH 3 - PROGRESS: at 70.39% examples, 53159 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:44,325 : INFO : EPOCH 3 - PROGRESS: at 76.54% examples, 54344 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:45,380 : INFO : EPOCH 3 - PROGRESS: at 82.12% examples, 54951 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:46,397 : INFO : EPOCH 3 - PROGRESS: at 87.15% examples, 55320 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:47,553 : INFO : EPOCH 3 - PROGRESS: at 92.18% examples, 55245 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:48,753 : INFO : EPOCH 3 - PROGRESS: at 97.21% examples, 55071 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:49,445 : INFO : EPOCH 3: training on 1788017 raw words (1242326 effective words) took 22.6s, 54851 effective words/s\n",
      "2023-04-04 14:02:50,695 : INFO : EPOCH 4 - PROGRESS: at 2.23% examples, 24529 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:51,774 : INFO : EPOCH 4 - PROGRESS: at 7.26% examples, 41272 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:52,789 : INFO : EPOCH 4 - PROGRESS: at 12.29% examples, 47849 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:53,976 : INFO : EPOCH 4 - PROGRESS: at 18.99% examples, 54044 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:55,363 : INFO : EPOCH 4 - PROGRESS: at 25.70% examples, 55716 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:56,412 : INFO : EPOCH 4 - PROGRESS: at 31.84% examples, 58249 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:02:57,492 : INFO : EPOCH 4 - PROGRESS: at 36.87% examples, 58182 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:02:58,757 : INFO : EPOCH 4 - PROGRESS: at 40.78% examples, 55575 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:03:00,005 : INFO : EPOCH 4 - PROGRESS: at 46.93% examples, 56138 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:03:01,017 : INFO : EPOCH 4 - PROGRESS: at 50.84% examples, 55408 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:03:02,076 : INFO : EPOCH 4 - PROGRESS: at 56.98% examples, 56602 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:03:03,154 : INFO : EPOCH 4 - PROGRESS: at 62.57% examples, 57004 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:03:04,170 : INFO : EPOCH 4 - PROGRESS: at 68.16% examples, 57746 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:03:05,362 : INFO : EPOCH 4 - PROGRESS: at 73.74% examples, 57853 words/s, in_qsize 6, out_qsize 0\n",
      "2023-04-04 14:03:06,417 : INFO : EPOCH 4 - PROGRESS: at 78.77% examples, 57989 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:03:07,430 : INFO : EPOCH 4 - PROGRESS: at 83.24% examples, 57808 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:03:08,516 : INFO : EPOCH 4 - PROGRESS: at 87.71% examples, 57440 words/s, in_qsize 5, out_qsize 1\n",
      "2023-04-04 14:03:09,525 : INFO : EPOCH 4 - PROGRESS: at 92.74% examples, 57655 words/s, in_qsize 5, out_qsize 0\n",
      "2023-04-04 14:03:10,764 : INFO : EPOCH 4 - PROGRESS: at 97.77% examples, 57251 words/s, in_qsize 4, out_qsize 0\n",
      "2023-04-04 14:03:11,189 : INFO : EPOCH 4: training on 1788017 raw words (1242503 effective words) took 21.7s, 57338 effective words/s\n",
      "2023-04-04 14:03:11,191 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212052 effective words) took 108.9s, 57028 effective words/s', 'datetime': '2023-04-04T14:03:11.191709', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 14:03:11,192 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=20167, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T14:03:11.192709', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #23: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 121.25435598691304, 'train_time_std': 6.657785280488426}\n",
      "   train_data  compute_loss  sg  hs  train_time_mean  train_time_std\n",
      "4        25kB          True   1   0         1.246770        0.055282\n",
      "5        25kB         False   1   0         1.043255        0.009498\n",
      "6        25kB          True   1   1         2.120964        0.160401\n",
      "7        25kB         False   1   1         2.052032        0.166635\n",
      "0        25kB          True   0   0         0.614572        0.022986\n",
      "1        25kB         False   0   0         0.696086        0.065797\n",
      "2        25kB          True   0   1         1.573305        0.179429\n",
      "3        25kB         False   0   1         1.061319        0.015410\n",
      "12        1MB          True   1   0         3.221910        0.201046\n",
      "13        1MB         False   1   0         3.467192        0.271561\n",
      "14        1MB          True   1   1         7.286693        0.068792\n",
      "15        1MB         False   1   1         9.320667        0.435220\n",
      "8         1MB          True   0   0         1.494255        0.234566\n",
      "9         1MB         False   0   0         1.453677        0.280245\n",
      "10        1MB          True   0   1         2.534656        0.159342\n",
      "11        1MB         False   0   1         2.688864        0.014530\n",
      "20       10MB          True   1   0        45.668505        0.479163\n",
      "21       10MB         False   1   0        48.660869        1.245325\n",
      "22       10MB          True   1   1       109.126816        6.534057\n",
      "23       10MB         False   1   1       121.254356        6.657785\n",
      "16       10MB          True   0   0        16.541063        0.225543\n",
      "17       10MB         False   0   0        17.175948        0.692592\n",
      "18       10MB          True   0   1        33.426352        1.346472\n",
      "19       10MB         False   0   1        33.801252        3.760423\n"
     ]
    }
   ],
   "source": [
    "# Temporarily reduce logging verbosity\n",
    "logging.root.level = logging.ERROR\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_time_values = []\n",
    "seed_val = 42\n",
    "sg_values = [0, 1]\n",
    "hs_values = [0, 1]\n",
    "\n",
    "fast = True\n",
    "if fast:\n",
    "    input_data_subset = input_data[:3]\n",
    "else:\n",
    "    input_data_subset = input_data\n",
    "\n",
    "\n",
    "for data in input_data_subset:\n",
    "    for sg_val in sg_values:\n",
    "        for hs_val in hs_values:\n",
    "            for loss_flag in [True, False]:\n",
    "                time_taken_list = []\n",
    "                for i in range(3):\n",
    "                    start_time = time.time()\n",
    "                    w2v_model = gensim.models.Word2Vec(\n",
    "                        data,\n",
    "                        compute_loss=loss_flag,\n",
    "                        sg=sg_val,\n",
    "                        hs=hs_val,\n",
    "                        seed=seed_val,\n",
    "                    )\n",
    "                    time_taken_list.append(time.time() - start_time)\n",
    "\n",
    "                time_taken_list = np.array(time_taken_list)\n",
    "                time_mean = np.mean(time_taken_list)\n",
    "                time_std = np.std(time_taken_list)\n",
    "\n",
    "                model_result = {\n",
    "                    'train_data': data.name,\n",
    "                    'compute_loss': loss_flag,\n",
    "                    'sg': sg_val,\n",
    "                    'hs': hs_val,\n",
    "                    'train_time_mean': time_mean,\n",
    "                    'train_time_std': time_std,\n",
    "                }\n",
    "                print(\"Word2vec model #%i: %s\" % (len(train_time_values), model_result))\n",
    "                train_time_values.append(model_result)\n",
    "\n",
    "train_times_table = pd.DataFrame(train_time_values)\n",
    "train_times_table = train_times_table.sort_values(\n",
    "    by=['train_data', 'sg', 'hs', 'compute_loss'],\n",
    "    ascending=[False, False, True, False],\n",
    ")\n",
    "print(train_times_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "text",
         "text": [
          "the",
          "to",
          "of",
          "in",
          "and",
          "he",
          "is",
          "for",
          "on",
          "said",
          "that",
          "has",
          "says",
          "was",
          "have",
          "it",
          "be",
          "are",
          "with",
          "will",
          "at",
          "mr",
          "from",
          "by",
          "we",
          "been",
          "as",
          "an",
          "not",
          "his",
          "but",
          "they",
          "after",
          "were",
          "had",
          "there",
          "new",
          "this",
          "australia",
          "australian",
          "who",
          "palestinian",
          "people",
          "their",
          "government",
          "two",
          "up",
          "south",
          "us",
          "which",
          "year",
          "one",
          "about",
          "out",
          "if",
          "also",
          "more",
          "when",
          "its",
          "into",
          "would",
          "first",
          "last",
          "against",
          "israeli",
          "minister",
          "arafat",
          "over",
          "all",
          "three",
          "afghanistan",
          "united",
          "world",
          "no",
          "or",
          "police",
          "than",
          "attacks",
          "fire",
          "before",
          "some",
          "security",
          "day",
          "you",
          "states",
          "could",
          "them",
          "say",
          "today",
          "now",
          "told",
          "time",
          "any",
          "laden",
          "very",
          "bin",
          "just",
          "can",
          "sydney",
          "what",
          "still",
          "company",
          "president",
          "man",
          "four",
          "taliban",
          "killed",
          "our",
          "forces",
          "al",
          "around",
          "being",
          "days",
          "west",
          "old",
          "other",
          "officials",
          "where",
          "so",
          "test",
          "qaeda",
          "israel",
          "think",
          "per",
          "general",
          "next",
          "federal",
          "force",
          "cent",
          "she",
          "leader",
          "yesterday",
          "workers",
          "take",
          "him",
          "hamas",
          "under",
          "state",
          "those",
          "years",
          "meeting",
          "bank",
          "suicide",
          "back",
          "action",
          "commission",
          "made",
          "down",
          "morning",
          "re",
          "pakistan",
          "international",
          "city",
          "attack",
          "centre",
          "group",
          "afghan",
          "members",
          "while",
          "military",
          "well",
          "number",
          "through",
          "qantas",
          "five",
          "local",
          "called",
          "area",
          "union",
          "gaza",
          "week",
          "national",
          "since",
          "wales",
          "including",
          "hours",
          "september",
          "another",
          "east",
          "night",
          "report",
          "off",
          "north",
          "should",
          "get",
          "second",
          "go",
          "earlier",
          "war",
          "staff",
          "six",
          "these",
          "between",
          "islamic",
          "months",
          "further",
          "end",
          "defence",
          "do",
          "sharon",
          "near",
          "team",
          "foreign",
          "power",
          "areas",
          "work",
          "going",
          "authority",
          "because",
          "way",
          "eight",
          "india",
          "only",
          "know",
          "month",
          "during",
          "died",
          "many",
          "match",
          "make",
          "air",
          "metres",
          "left",
          "claims",
          "spokesman",
          "ve",
          "former",
          "melbourne",
          "northern",
          "good",
          "authorities",
          "most",
          "osama",
          "support",
          "prime",
          "peace",
          "like",
          "set",
          "ago",
          "expected",
          "saying",
          "given",
          "am",
          "come",
          "looking",
          "militants",
          "bora",
          "tora",
          "put",
          "place",
          "several",
          "fighters",
          "children",
          "arrested",
          "injured",
          "found",
          "river",
          "royal",
          "groups",
          "africa",
          "unions",
          "christmas",
          "troops",
          "meanwhile",
          "indian",
          "child",
          "hospital",
          "terrorist",
          "interim",
          "part",
          "reports",
          "talks",
          "official",
          "whether",
          "then",
          "yasser",
          "statement",
          "leaders",
          "economy",
          "mountains",
          "how",
          "industrial",
          "third",
          "terrorism",
          "senior",
          "start",
          "don",
          "early",
          "radio",
          "john",
          "hit",
          "trying",
          "weather",
          "public",
          "both",
          "believe",
          "family",
          "pay",
          "million",
          "army",
          "court",
          "dr",
          "long",
          "best",
          "control",
          "help",
          "however",
          "lead",
          "adelaide",
          "asked",
          "following",
          "chief",
          "pressure",
          "agreement",
          "does",
          "service",
          "firefighters",
          "close",
          "few",
          "services",
          "labor",
          "play",
          "better",
          "community",
          "taken",
          "want",
          "arrest",
          "queensland",
          "house",
          "need",
          "overnight",
          "australians",
          "high",
          "confirmed",
          "process",
          "information",
          "came",
          "believed",
          "williams",
          "must",
          "opposition",
          "detainees",
          "won",
          "secretary",
          "did",
          "peter",
          "party",
          "held",
          "damage",
          "governor",
          "maintenance",
          "released",
          "win",
          "pentagon",
          "possible",
          "her",
          "brought",
          "hicks",
          "much",
          "shot",
          "took",
          "accused",
          "nations",
          "british",
          "weekend",
          "lot",
          "violence",
          "building",
          "despite",
          "council",
          "return",
          "got",
          "airline",
          "asylum",
          "york",
          "dead",
          "kandahar",
          "conditions",
          "across",
          "hill",
          "winds",
          "safety",
          "even",
          "such",
          "change",
          "cut",
          "eastern",
          "without",
          "director",
          "armed",
          "working",
          "aircraft",
          "call",
          "here",
          "see",
          "palestinians",
          "december",
          "economic",
          "news",
          "american",
          "too",
          "home",
          "men",
          "seekers",
          "strip",
          "lee",
          "waugh",
          "role",
          "country",
          "region",
          "trade",
          "emergency",
          "crew",
          "strong",
          "race",
          "captured",
          "david",
          "southern",
          "fighting",
          "continuing",
          "fires",
          "monday",
          "far",
          "anti",
          "board",
          "cricket",
          "training",
          "key",
          "plans",
          "bush",
          "bureau",
          "act",
          "industry",
          "george",
          "head",
          "past",
          "water",
          "charged",
          "used",
          "administration",
          "received",
          "offer",
          "alliance",
          "rate",
          "zinni",
          "health",
          "least",
          "leading",
          "person",
          "captain",
          "your",
          "town",
          "boat",
          "large",
          "decision",
          "stop",
          "known",
          "airport",
          "operations",
          "may",
          "line",
          "within",
          "risk",
          "use",
          "downer",
          "israelis",
          "soldiers",
          "major",
          "britain",
          "final",
          "parliament",
          "department",
          "zealand",
          "hundreds",
          "issue",
          "strikes",
          "hih",
          "station",
          "legal",
          "shane",
          "plane",
          "might",
          "series",
          "interest",
          "un",
          "laws",
          "policy",
          "right",
          "ahead",
          "hollingworth",
          "tomorrow",
          "network",
          "pm",
          "able",
          "due",
          "kabul",
          "latest",
          "death",
          "homes",
          "weapons",
          "behind",
          "great",
          "coast",
          "western",
          "position",
          "give",
          "later",
          "late",
          "half",
          "officers",
          "my",
          "taking",
          "every",
          "remain",
          "campaign",
          "seen",
          "thought",
          "bill",
          "timor",
          "special",
          "side",
          "failed",
          "same",
          "flight",
          "along",
          "jobs",
          "storm",
          "me",
          "forced",
          "life",
          "others",
          "continue",
          "hard",
          "event",
          "abuse",
          "cup",
          "victory",
          "jihad",
          "guilty",
          "point",
          "towards",
          "really",
          "concerned",
          "heard",
          "already",
          "territory",
          "washington",
          "deaths",
          "mcgrath",
          "helicopters",
          "envoy",
          "canyoning",
          "capital",
          "bus",
          "bichel",
          "november",
          "likely",
          "details",
          "case",
          "member",
          "launched",
          "innings",
          "according",
          "enough",
          "bombings",
          "weeks",
          "countries",
          "again",
          "detention",
          "move",
          "woomera",
          "seven",
          "cabinet",
          "bowler",
          "buildings",
          "hour",
          "mark",
          "matter",
          "middle",
          "bombing",
          "th",
          "sunday",
          "situation",
          "rates",
          "space",
          "important",
          "warne",
          "dispute",
          "caught",
          "jail",
          "claimed",
          "wants",
          "perth",
          "adventure",
          "targets",
          "run",
          "swiss",
          "asio",
          "added",
          "commonwealth",
          "raids",
          "office",
          "evidence",
          "deal",
          "guides",
          "disease",
          "show",
          "boy",
          "women",
          "own",
          "freeze",
          "opened",
          "human",
          "forward",
          "carried",
          "african",
          "mission",
          "movement",
          "based",
          "sure",
          "reported",
          "immediately",
          "political",
          "warplanes",
          "young",
          "rule",
          "ms",
          "blue",
          "top",
          "justice",
          "money",
          "aedt",
          "cancer",
          "crash",
          "march",
          "banks",
          "border",
          "using",
          "although",
          "access",
          "financial",
          "allegations",
          "certainly",
          "planning",
          "probably",
          "break",
          "find",
          "wicket",
          "ground",
          "beat",
          "prepared",
          "burning",
          "become",
          "always",
          "job",
          "proposed",
          "each",
          "full",
          "reached",
          "collapse",
          "growth",
          "order",
          "island",
          "sector",
          "flying",
          "carrying",
          "result",
          "face",
          "investigation",
          "times",
          "relations",
          "militant",
          "road",
          "sex",
          "needs",
          "organisation",
          "until",
          "serious",
          "program",
          "fight",
          "calls",
          "stage",
          "getting",
          "lives",
          "responsibility",
          "reserve",
          "thursday",
          "comes",
          "management",
          "sent",
          "drop",
          "surrender",
          "allow",
          "soon",
          "afp",
          "tried",
          "post",
          "killing",
          "radical",
          "hewitt",
          "himself",
          "senator",
          "executive",
          "outside",
          "believes",
          "inquiry",
          "short",
          "caves",
          "different",
          "flights",
          "immigration",
          "tourists",
          "future",
          "inside",
          "bid",
          "energy",
          "clear",
          "trees",
          "thousands",
          "argentina",
          "militia",
          "suspected",
          "making",
          "bowling",
          "ariel",
          "went",
          "alleged",
          "rejected",
          "howard",
          "quickly",
          "wave",
          "harrison",
          "travel",
          "opening",
          "ansett",
          "kilometres",
          "declared",
          "running",
          "measures",
          "biggest",
          "list",
          "figures",
          "rise",
          "residents",
          "sea",
          "form",
          "annual",
          "anything",
          "attempt",
          "open",
          "parties",
          "available",
          "announced",
          "shortly",
          "among",
          "currently",
          "bombers",
          "circumstances",
          "accident",
          "donald",
          "ministers",
          "look",
          "brisbane",
          "decided",
          "ruddock",
          "changes",
          "yet",
          "issues",
          "address",
          "destroyed",
          "actually",
          "rights",
          "increase",
          "terms",
          "school",
          "rural",
          "fighter",
          "quite",
          "happened",
          "wounded",
          "victoria",
          "television",
          "nine",
          "something",
          "try",
          "parts",
          "white",
          "response",
          "done",
          "wickets",
          "witnesses",
          "refused",
          "karzai",
          "sentence",
          "ended",
          "tanks",
          "gunmen",
          "sources",
          "kallis",
          "agency",
          "july",
          "jewish",
          "warned",
          "directors",
          "understand",
          "meet",
          "means",
          "returned",
          "offices",
          "yacht",
          "source",
          "alexander",
          "ll",
          "fact",
          "difficult",
          "though",
          "period",
          "confidence",
          "wage",
          "airlines",
          "virus",
          "advice",
          "caused",
          "musharraf",
          "allan",
          "recession",
          "less",
          "ensure",
          "strike",
          "appeared",
          "islands",
          "crowd",
          "suharto",
          "highway",
          "afternoon",
          "step",
          "commanders",
          "began",
          "gave",
          "worst",
          "glenn",
          "bomb",
          "commissioner",
          "powell",
          "having",
          "beginning",
          "intelligence",
          "rafter",
          "prevent",
          "gives",
          "expressed",
          "huge",
          "ever",
          "big",
          "business",
          "ses",
          "media",
          "friday",
          "pacific",
          "robert",
          "expect",
          "blake",
          "runs",
          "involved",
          "followed",
          "deputy",
          "hobart",
          "whose",
          "market",
          "tour",
          "rather",
          "attorney",
          "elected",
          "beyond",
          "arrived",
          "away",
          "facility",
          "commander",
          "total",
          "law",
          "field",
          "supporters",
          "struck",
          "car",
          "cost",
          "sir",
          "negotiations",
          "nauru",
          "tennis",
          "massive",
          "entered",
          "threat",
          "plan",
          "explosives",
          "debt",
          "entitlements",
          "criticism",
          "decide",
          "quarter",
          "saturday",
          "assistance",
          "labour",
          "geoff",
          "together",
          "finished",
          "chance",
          "endeavour",
          "chairman",
          "main",
          "heavy",
          "base",
          "places",
          "tragedy",
          "sort",
          "vote",
          "giving",
          "jenin",
          "front",
          "powers",
          "anglican",
          "son",
          "zimbabwe",
          "themselves",
          "conflict",
          "yes",
          "muslim",
          "lockett",
          "daryl",
          "helicopter",
          "current",
          "fast",
          "complex",
          "terror",
          "smoke",
          "france",
          "anthony",
          "calling",
          "hearings",
          "population",
          "tasmania",
          "game",
          "jacques",
          "placed",
          "denied",
          "reid",
          "pakistani",
          "indonesia",
          "bring",
          "ballot",
          "played",
          "protect",
          "level",
          "conference",
          "organisations",
          "martin",
          "employees",
          "feel",
          "costs",
          "changed",
          "study",
          "survey",
          "brett",
          "potential",
          "macgill",
          "cannot",
          "crean",
          "lost",
          "storms",
          "round",
          "russian",
          "trip",
          "crisis",
          "nearly",
          "americans",
          "speaking",
          "ambush",
          "never",
          "significant",
          "boxing",
          "longer",
          "low",
          "tribal",
          "deadly",
          "record",
          "problem",
          "professor",
          "hayden",
          "fleeing",
          "absolutely",
          "continues",
          "fired",
          "rumsfeld",
          "claim",
          "ramallah",
          "hold",
          "anyone",
          "election",
          "construction",
          "technology",
          "doubles",
          "cities",
          "companies",
          "research",
          "whole",
          "efforts",
          "needed",
          "small",
          "moved",
          "confident",
          "land",
          "proposals",
          "sign",
          "little",
          "affected",
          "tape",
          "ruled",
          "environment",
          "everything",
          "severe",
          "led",
          "closed",
          "forecast",
          "pilot",
          "overall",
          "gillespie",
          "signed",
          "coming",
          "receive",
          "rival",
          "provide",
          "representation",
          "simon",
          "accept",
          "sides",
          "mountain",
          "receiving",
          "mean",
          "secret",
          "injuries",
          "dozens",
          "steve",
          "payment",
          "hope",
          "battle",
          "shuttle",
          "gun",
          "central",
          "bomber",
          "starting",
          "activity",
          "damaged",
          "bonn",
          "disaster",
          "problems",
          "verdict",
          "flames",
          "condition",
          "french",
          "tony",
          "resolution",
          "rest",
          "coalition",
          "richard",
          "treatment",
          "recorded",
          "grant",
          "stopped",
          "hotel",
          "insurance",
          "carry",
          "rain",
          "almost",
          "ice",
          "continued",
          "greater",
          "global",
          "share",
          "direct",
          "nation",
          "paid",
          "vaughan",
          "statistics",
          "fellow",
          "winner",
          "civil",
          "review",
          "private",
          "gas",
          "twice",
          "interlaken",
          "concern",
          "cars",
          "started",
          "red",
          "fell",
          "disappointed",
          "debate",
          "determined",
          "michael",
          "seles",
          "begin",
          "krishna",
          "didn",
          "refugees",
          "remaining",
          "tough",
          "ceremony",
          "property",
          "january",
          "qc",
          "stand",
          "operation",
          "territories",
          "above",
          "lower",
          "respond",
          "reduce",
          "resolve",
          "victims",
          "strategic",
          "asic",
          "alongside",
          "include",
          "revealed",
          "august",
          "season",
          "charge",
          "completed",
          "seeking",
          "bit",
          "park",
          "lines",
          "heritage",
          "traditional",
          "enter",
          "tuesday",
          "guard",
          "ray",
          "avoid",
          "markets",
          "visit",
          "europe",
          "winning",
          "playing",
          "self",
          "yachts",
          "met",
          "charges",
          "vice",
          "cease",
          "roads",
          "factory",
          "america",
          "itself",
          "created",
          "wake",
          "levels",
          "fall",
          "related",
          "outlook",
          "ministry",
          "lung",
          "hearing",
          "non",
          "volunteers",
          "civilians",
          "voted",
          "liquidation",
          "search",
          "provisional",
          "rescue",
          "victorian",
          "table",
          "successful",
          "track",
          "conducted",
          "heading",
          "spread",
          "accompanied",
          "delhi",
          "operating",
          "wanted",
          "expects",
          "leg",
          "ponting",
          "pulled",
          "knew",
          "heart",
          "coach",
          "confirm",
          "ball",
          "virgin",
          "press",
          "suffered",
          "illawarra",
          "approach",
          "manslaughter",
          "costello",
          "showed",
          "threatened",
          "warning",
          "helped",
          "resume",
          "japan",
          "individuals",
          "mayor",
          "giuliani",
          "friedli",
          "wind",
          "served",
          "andy",
          "range",
          "responsible",
          "unemployment",
          "mckenzie",
          "initial",
          "keep",
          "families",
          "lord",
          "incident",
          "october",
          "finance",
          "treated",
          "ian",
          "why",
          "solution",
          "apparently",
          "body",
          "club",
          "crackdown",
          "reach",
          "officer",
          "institute",
          "shaun",
          "pollock",
          "hopes",
          "structure",
          "data",
          "nice",
          "food",
          "seriously",
          "suspended",
          "attacked",
          "jason",
          "elections",
          "edge",
          "affairs",
          "nothing",
          "questions",
          "mid",
          "built",
          "negotiating",
          "peacekeepers",
          "saw",
          "issued",
          "spokeswoman",
          "assisting",
          "remains",
          "finding",
          "recovery",
          "woman",
          "gang",
          "kashmir",
          "farmers",
          "oil",
          "networks",
          "sheikh",
          "adequate",
          "doubt",
          "products",
          "secure",
          "beatle",
          "single",
          "options",
          "clearly",
          "blaze",
          "present",
          "ford",
          "cfmeu",
          "tailenders",
          "fatah",
          "scene",
          "co",
          "lording",
          "factions",
          "st",
          "raid",
          "career",
          "streets",
          "butterfly",
          "amin",
          "outcome",
          "traveland",
          "peres",
          "inappropriate",
          "austar",
          "scored",
          "champion",
          "races",
          "cave",
          "scheduled",
          "clean",
          "nearby",
          "philip",
          "shows",
          "invasion",
          "aboard",
          "coup",
          "senate",
          "doug",
          "solomon",
          "eve",
          "sarah",
          "holiday",
          "mohammad",
          "university",
          "murder",
          "whiting",
          "gorge",
          "tensions",
          "manufacturing",
          "wayne",
          "yallourn",
          "diplomatic",
          "drug",
          "promised",
          "cause",
          "natural",
          "afroz",
          "ethnic",
          "singles",
          "crews",
          "meetings",
          "toll",
          "apra",
          "administrators",
          "corporation",
          "leadership",
          "canberra",
          "exchange",
          "nuclear",
          "germany",
          "numbers",
          "attacking",
          "largest",
          "petrol",
          "customers",
          "prior",
          "internet",
          "awards",
          "extremists",
          "attempting",
          "personnel",
          "hand",
          "criminal",
          "mandate",
          "things",
          "deployed",
          "follows",
          "unrest",
          "dropped",
          "manager",
          "injury",
          "settlement",
          "roof",
          "honours",
          "appears",
          "metre",
          "boats",
          "often",
          "speech",
          "squad",
          "fair",
          "budget",
          "ready",
          "ask",
          "band",
          "proteas",
          "king",
          "grand",
          "recent",
          "happens",
          "classic",
          "suburbs",
          "resign",
          "swept",
          "collapsed",
          "true",
          "agreed",
          "batsmen",
          "presence",
          "felt",
          "billion",
          "resistance",
          "giant",
          "increased",
          "described",
          "unit",
          "create",
          "concerns",
          "protection",
          "targeted",
          "boys",
          "saudi",
          "leave",
          "unity",
          "planes",
          "halt",
          "read",
          "marine",
          "neil",
          "walk",
          "crossed",
          "fleet",
          "knowledge",
          "minute",
          "greatest",
          "extensive",
          "backed",
          "ocean",
          "assa",
          "ricky",
          "abloy",
          "light",
          "premier",
          "names",
          "explanation",
          "wall",
          "possibility",
          "real",
          "live",
          "switzerland",
          "japanese",
          "shopping",
          "reveal",
          "fierce",
          "tree",
          "elders",
          "blame",
          "tension",
          "employment",
          "detain",
          "positive",
          "income",
          "haifa",
          "jerusalem",
          "pre",
          "programs",
          "jets",
          "transport",
          "regional",
          "save",
          "hunt",
          "advance",
          "gone",
          "battling",
          "suspect",
          "representing",
          "investigating",
          "reduced",
          "acting",
          "projects",
          "investment",
          "spencer",
          "findings",
          "students",
          "nablus",
          "actions",
          "trial",
          "declaration",
          "handed",
          "custody",
          "growing",
          "system",
          "prisoners",
          "domestic",
          "education",
          "society",
          "summit",
          "assault",
          "langer",
          "matthew",
          "requested",
          "westpac",
          "doctor",
          "wing",
          "republic",
          "searching",
          "eliminated",
          "approval",
          "anz",
          "term",
          "bargaining",
          "various",
          "balls",
          "klusener",
          "boucher",
          "humanity",
          "suggested",
          "adding",
          "history",
          "normal",
          "cuts",
          "signs",
          "gunships",
          "blasted",
          "turn",
          "hare",
          "smaller",
          "guess",
          "benares",
          "ashes",
          "path",
          "terrorists",
          "blazes",
          "hijacked",
          "adam",
          "follow",
          "comment",
          "aware",
          "connection",
          "underway",
          "kieren",
          "rabbani",
          "completely",
          "tonight",
          "understanding",
          "infected",
          "masood",
          "treasurer",
          "crime",
          "gambier",
          "henderson",
          "returning",
          "results",
          "kingham",
          "question",
          "kissinger",
          "gerber",
          "stuart",
          "launceston",
          "sergeant",
          "flood",
          "committee",
          "hundred",
          "goshen",
          "handling",
          "church",
          "thing",
          "escaped",
          "injuring",
          "slightly",
          "francs",
          "hunter",
          "ahmed",
          "actor",
          "wednesday",
          "aged",
          "centrelink",
          "threatening",
          "sultan",
          "improve",
          "passed",
          "stability",
          "project",
          "dollars",
          "decades",
          "course",
          "ill",
          "faces",
          "chosen",
          "bob",
          "hamid",
          "passengers",
          "davis",
          "neville",
          "ways",
          "pace",
          "whatever",
          "headed",
          "launch",
          "replied",
          "hopefully",
          "determine",
          "archbishop",
          "unable",
          "throughout",
          "average",
          "unidentified",
          "survived",
          "approached",
          "convicted",
          "cooperation",
          "redundancy",
          "waiting",
          "request",
          "paying",
          "observers",
          "aboriginal",
          "procedures",
          "reject",
          "document",
          "improved",
          "holding",
          "mass",
          "unfortunately",
          "welcomed",
          "whereabouts",
          "appropriate",
          "lack",
          "delay",
          "trapped",
          "facilities",
          "decisions",
          "prepare",
          "medical",
          "necessary",
          "spinner",
          "examination",
          "losing",
          "channel",
          "occupation",
          "title",
          "consumers",
          "firm",
          "creditors",
          "fine",
          "vehicle",
          "staying",
          "relationship",
          "delivered",
          "begun",
          "hot",
          "coroner",
          "temperatures",
          "containment",
          "cross",
          "contested",
          "strongly",
          "experts",
          "celebrations",
          "focus",
          "named",
          "sometimes",
          "marines",
          "player",
          "jalalabad",
          "games",
          "breaking",
          "contained",
          "counts",
          "stay",
          "allowed",
          "temporary",
          "assembly",
          "draft",
          "understood",
          "toowoomba",
          "voice",
          "twenty",
          "strachan",
          "harris",
          "discussions",
          "hopman",
          "crashed",
          "farm",
          "violent",
          "communities",
          "kilometre",
          "doctors",
          "hoping",
          "ban",
          "colin",
          "effective",
          "success",
          "offered",
          "positions",
          "abu",
          "worked",
          "documents",
          "tell",
          "phillips",
          "retired",
          "choosing",
          "responding",
          "allegedly",
          "indonesian",
          "detail",
          "free",
          "bringing",
          "hiv",
          "proposal",
          "doesn",
          "mining",
          "embassy",
          "heights",
          "mt",
          "trading",
          "room",
          "fund",
          "impact",
          "male",
          "mohammed",
          "interests",
          "effort",
          "antarctic",
          "previous",
          "target",
          "words",
          "publicly",
          "walked",
          "credit",
          "provided",
          "investigate",
          "telephone",
          "eventually",
          "leaving",
          "banking",
          "interview",
          "headquarters",
          "clashes",
          "doing",
          "fear",
          "predicted",
          "picked",
          "happy",
          "visa",
          "tie",
          "putting",
          "escalating",
          "hoped",
          "landed",
          "sharing",
          "mind",
          "skipper",
          "gary",
          "soft",
          "became",
          "sending",
          "shoes",
          "paris",
          "required",
          "seemed",
          "cameron",
          "ability",
          "locked",
          "travelled",
          "finally",
          "separate",
          "owen"
         ],
         "type": "scatter",
         "x": [
          67.65857696533203,
          69.41801452636719,
          69.28298950195312,
          69.18158721923828,
          69.56907653808594,
          65.34490203857422,
          69.00169372558594,
          69.21319580078125,
          69.90988159179688,
          66.49942779541016,
          67.608154296875,
          69.91500091552734,
          69.12689208984375,
          67.43939208984375,
          68.92963409423828,
          65.96743774414062,
          66.21795654296875,
          69.21856689453125,
          69.63339233398438,
          68.7721176147461,
          69.84840393066406,
          67.57792663574219,
          69.47521209716797,
          69.59858703613281,
          68.4791259765625,
          65.23654174804688,
          68.73503875732422,
          68.94235229492188,
          66.15231323242188,
          68.57764434814453,
          68.34796905517578,
          68.0045394897461,
          69.94342041015625,
          69.41165161132812,
          67.8636245727539,
          65.39534759521484,
          68.7769546508789,
          68.27665710449219,
          65.99136352539062,
          67.38512420654297,
          68.36661529541016,
          67.00911712646484,
          65.73505401611328,
          68.60565948486328,
          65.2210693359375,
          69.87313079833984,
          67.6294937133789,
          68.85900115966797,
          66.65251922607422,
          68.06036376953125,
          67.94220733642578,
          64.6227035522461,
          66.9203109741211,
          67.97750854492188,
          66.74674224853516,
          65.91548919677734,
          67.44751739501953,
          67.8775405883789,
          66.85778045654297,
          68.64295196533203,
          66.8400650024414,
          66.38887786865234,
          66.56995391845703,
          65.67915344238281,
          67.0496597290039,
          68.15888977050781,
          63.817928314208984,
          67.11618041992188,
          63.671875,
          65.46185302734375,
          63.137062072753906,
          61.8315544128418,
          64.96726989746094,
          63.310699462890625,
          65.69857788085938,
          63.585723876953125,
          64.26396179199219,
          62.060760498046875,
          63.861148834228516,
          66.85871887207031,
          62.50386428833008,
          62.924800872802734,
          61.407814025878906,
          66.42230987548828,
          61.896888732910156,
          64.01353454589844,
          62.4271125793457,
          62.202369689941406,
          65.97733306884766,
          63.297115325927734,
          65.20219421386719,
          59.10179901123047,
          64.2501220703125,
          61.01020812988281,
          60.9886474609375,
          62.84935760498047,
          61.330875396728516,
          61.204139709472656,
          62.73065185546875,
          60.29288864135742,
          60.9763298034668,
          62.48002243041992,
          63.64748764038086,
          45.631553649902344,
          63.404850006103516,
          60.91730880737305,
          51.40855407714844,
          59.57094192504883,
          55.15463638305664,
          60.91593933105469,
          58.35748291015625,
          62.12459945678711,
          58.6619987487793,
          53.104949951171875,
          52.412254333496094,
          54.531150817871094,
          55.93544006347656,
          60.93291473388672,
          56.39421081542969,
          57.5955696105957,
          56.373348236083984,
          54.252899169921875,
          57.16511154174805,
          54.97438430786133,
          63.08226013183594,
          56.384952545166016,
          44.81596374511719,
          53.97922134399414,
          53.75196838378906,
          47.20368576049805,
          49.71965789794922,
          58.366905212402344,
          61.80777359008789,
          43.878440856933594,
          52.21343231201172,
          58.63371276855469,
          52.81483840942383,
          51.138519287109375,
          53.580787658691406,
          43.307769775390625,
          51.41278839111328,
          51.20579528808594,
          52.144508361816406,
          45.754356384277344,
          54.7103157043457,
          53.355899810791016,
          49.31318283081055,
          59.39595031738281,
          44.457366943359375,
          49.238616943359375,
          57.25065994262695,
          53.079002380371094,
          55.6600227355957,
          47.77387619018555,
          51.34758758544922,
          57.00776672363281,
          53.79071044921875,
          52.178916931152344,
          55.69327163696289,
          54.94974136352539,
          42.992958068847656,
          42.750553131103516,
          53.43333053588867,
          53.89359664916992,
          56.42259216308594,
          60.44979476928711,
          41.59615707397461,
          46.28202819824219,
          56.797908782958984,
          48.57189178466797,
          43.73933029174805,
          56.768341064453125,
          54.96548843383789,
          38.62677001953125,
          57.936302185058594,
          48.722415924072266,
          37.45716857910156,
          48.827796936035156,
          51.724365234375,
          47.2421875,
          43.09780502319336,
          50.768165588378906,
          47.96576690673828,
          47.28287124633789,
          48.41628646850586,
          53.940921783447266,
          42.47938919067383,
          47.68510818481445,
          40.28889465332031,
          46.277923583984375,
          48.13022994995117,
          42.74999237060547,
          57.16737365722656,
          57.445743560791016,
          45.151039123535156,
          43.47677993774414,
          36.44706344604492,
          42.31070327758789,
          38.68376922607422,
          40.09598922729492,
          52.82839584350586,
          39.64797592163086,
          49.19691848754883,
          42.728145599365234,
          48.23238754272461,
          38.146759033203125,
          35.91868209838867,
          38.544837951660156,
          44.96271514892578,
          34.20430374145508,
          42.49091720581055,
          41.07876968383789,
          38.96921920776367,
          39.2418212890625,
          43.355438232421875,
          48.24641418457031,
          46.19184494018555,
          37.52389144897461,
          35.743370056152344,
          43.08607482910156,
          45.68271255493164,
          49.48344039916992,
          40.01811981201172,
          40.25178527832031,
          39.88215255737305,
          40.03837966918945,
          43.14398193359375,
          41.932010650634766,
          37.92646026611328,
          36.782264709472656,
          35.65992736816406,
          42.866573333740234,
          43.51472854614258,
          38.500606536865234,
          37.3087043762207,
          37.68547439575195,
          38.26526641845703,
          39.62940216064453,
          39.904903411865234,
          34.24614334106445,
          34.27892303466797,
          39.07923126220703,
          40.7145881652832,
          35.40064239501953,
          36.569271087646484,
          38.03179168701172,
          42.678985595703125,
          41.46925354003906,
          35.32697677612305,
          40.10509490966797,
          49.41203308105469,
          37.31058883666992,
          38.415321350097656,
          30.433988571166992,
          25.89706802368164,
          36.979007720947266,
          31.01569175720215,
          39.23590850830078,
          36.90748977661133,
          33.1434326171875,
          36.81700134277344,
          39.128353118896484,
          32.82137680053711,
          40.047996520996094,
          39.39345169067383,
          39.83987808227539,
          34.2376708984375,
          25.451416015625,
          20.115211486816406,
          34.89943313598633,
          36.027549743652344,
          41.4539794921875,
          37.75992202758789,
          39.58719253540039,
          39.26803207397461,
          37.24285125732422,
          39.613189697265625,
          33.372074127197266,
          18.331342697143555,
          36.19339370727539,
          37.330657958984375,
          38.843055725097656,
          40.648536682128906,
          34.48033142089844,
          36.1769905090332,
          33.27797317504883,
          35.49149703979492,
          24.301767349243164,
          36.697906494140625,
          37.77021026611328,
          38.61442184448242,
          31.6514835357666,
          38.11375427246094,
          37.12770462036133,
          43.75642776489258,
          28.810182571411133,
          36.27546691894531,
          37.43312454223633,
          24.284242630004883,
          22.70795440673828,
          36.478424072265625,
          38.219974517822266,
          40.730613708496094,
          18.195682525634766,
          32.264251708984375,
          36.447322845458984,
          37.04276657104492,
          30.666305541992188,
          37.82242202758789,
          35.07819747924805,
          37.511024475097656,
          42.31081771850586,
          33.41542053222656,
          35.296173095703125,
          30.768077850341797,
          34.61726760864258,
          34.95724105834961,
          37.70716857910156,
          31.913009643554688,
          35.947540283203125,
          33.22536849975586,
          32.81599426269531,
          33.937129974365234,
          29.64031410217285,
          24.683225631713867,
          28.277145385742188,
          35.804447174072266,
          40.37668228149414,
          30.15863800048828,
          31.21994972229004,
          36.87995529174805,
          29.223369598388672,
          37.215232849121094,
          34.49623489379883,
          32.20793151855469,
          32.868431091308594,
          31.70220947265625,
          16.9000301361084,
          27.808513641357422,
          32.66632080078125,
          34.26603698730469,
          36.22337341308594,
          36.40064239501953,
          39.52726745605469,
          19.13834571838379,
          41.73567199707031,
          26.991680145263672,
          32.652400970458984,
          24.603607177734375,
          22.27198600769043,
          36.99824142456055,
          29.36699104309082,
          35.906410217285156,
          15.760576248168945,
          28.343372344970703,
          35.79465866088867,
          23.330730438232422,
          27.7097110748291,
          31.89649200439453,
          15.545424461364746,
          30.670063018798828,
          13.68550968170166,
          24.547073364257812,
          29.97968101501465,
          17.823196411132812,
          23.36410903930664,
          24.129920959472656,
          34.97950744628906,
          29.6569766998291,
          29.00554847717285,
          21.627086639404297,
          29.94904327392578,
          34.11544418334961,
          35.383209228515625,
          12.595866203308105,
          32.288230895996094,
          27.363452911376953,
          32.58688735961914,
          34.33414077758789,
          26.352352142333984,
          33.622825622558594,
          29.507566452026367,
          30.52251434326172,
          24.861034393310547,
          33.267845153808594,
          17.48291778564453,
          13.565025329589844,
          35.540653228759766,
          35.99111557006836,
          28.936342239379883,
          17.72136878967285,
          35.06293869018555,
          16.425504684448242,
          16.91645050048828,
          20.96615219116211,
          19.814971923828125,
          24.795917510986328,
          31.610029220581055,
          33.97526931762695,
          11.304296493530273,
          35.291099548339844,
          21.799442291259766,
          18.31340789794922,
          32.2122688293457,
          20.712160110473633,
          32.14900588989258,
          36.206703186035156,
          26.142301559448242,
          22.902795791625977,
          23.436717987060547,
          23.238739013671875,
          26.540895462036133,
          33.68393325805664,
          29.488872528076172,
          33.67339324951172,
          16.859113693237305,
          25.380041122436523,
          19.533151626586914,
          12.324974060058594,
          10.458066940307617,
          26.553760528564453,
          30.12016487121582,
          5.754475116729736,
          25.36762046813965,
          20.851442337036133,
          10.812211036682129,
          32.24503707885742,
          22.865726470947266,
          22.68768310546875,
          23.949363708496094,
          33.54878234863281,
          21.74312973022461,
          29.097501754760742,
          20.665592193603516,
          11.754862785339355,
          20.96481704711914,
          10.595219612121582,
          24.663280487060547,
          26.621814727783203,
          31.142595291137695,
          29.838178634643555,
          33.70991516113281,
          26.959434509277344,
          32.92836380004883,
          32.55264663696289,
          34.58679962158203,
          0.16165593266487122,
          25.303897857666016,
          11.676466941833496,
          36.45074462890625,
          40.72079086303711,
          16.147125244140625,
          23.641048431396484,
          20.716039657592773,
          23.45568084716797,
          20.218395233154297,
          20.97093963623047,
          13.879051208496094,
          12.401878356933594,
          27.674964904785156,
          31.705251693725586,
          22.152650833129883,
          14.403491020202637,
          19.146814346313477,
          12.404572486877441,
          20.55844497680664,
          13.290095329284668,
          34.8574104309082,
          20.528615951538086,
          17.382171630859375,
          19.725322723388672,
          25.271413803100586,
          12.250612258911133,
          10.915501594543457,
          15.620882034301758,
          29.344730377197266,
          31.15570831298828,
          35.4114990234375,
          24.956953048706055,
          32.675838470458984,
          22.978036880493164,
          9.02694320678711,
          -0.49645230174064636,
          28.660085678100586,
          19.82094955444336,
          22.537466049194336,
          21.782886505126953,
          23.063976287841797,
          21.021696090698242,
          21.814620971679688,
          26.109981536865234,
          23.24257469177246,
          14.089136123657227,
          11.027854919433594,
          24.79885482788086,
          23.359254837036133,
          14.821953773498535,
          18.074609756469727,
          12.60660457611084,
          12.77002239227295,
          33.431236267089844,
          12.960766792297363,
          12.515045166015625,
          12.311671257019043,
          22.59103775024414,
          27.17308807373047,
          22.763212203979492,
          15.464120864868164,
          21.71524429321289,
          21.0694637298584,
          6.468864917755127,
          18.804288864135742,
          21.94942855834961,
          12.051261901855469,
          8.685100555419922,
          -1.9503774642944336,
          0.28108373284339905,
          18.742881774902344,
          22.7410888671875,
          19.314163208007812,
          24.194232940673828,
          24.35923194885254,
          24.626134872436523,
          24.41219139099121,
          33.29401397705078,
          16.465126037597656,
          13.550790786743164,
          -2.5034830570220947,
          10.199614524841309,
          24.61451530456543,
          23.871057510375977,
          14.481918334960938,
          15.086348533630371,
          23.62676239013672,
          28.00084114074707,
          33.866981506347656,
          13.353367805480957,
          13.22236442565918,
          13.426778793334961,
          11.628037452697754,
          23.550268173217773,
          17.24923324584961,
          18.476478576660156,
          20.27250099182129,
          11.282509803771973,
          2.948634624481201,
          22.359949111938477,
          23.824111938476562,
          21.119306564331055,
          32.201297760009766,
          15.127443313598633,
          27.561153411865234,
          5.765256881713867,
          16.233394622802734,
          18.42274284362793,
          24.846853256225586,
          15.653467178344727,
          -2.2950143814086914,
          -0.12109670042991638,
          15.971956253051758,
          23.214799880981445,
          17.14533233642578,
          23.012954711914062,
          14.11180305480957,
          -0.07328221201896667,
          21.63100814819336,
          24.11087417602539,
          17.09432029724121,
          1.5888677835464478,
          23.62053871154785,
          3.0634539127349854,
          22.202260971069336,
          11.983317375183105,
          35.483516693115234,
          19.751325607299805,
          20.472585678100586,
          29.14080238342285,
          1.461008071899414,
          20.57353973388672,
          22.97945213317871,
          25.829652786254883,
          -0.6862329244613647,
          16.14777183532715,
          30.070457458496094,
          23.40882682800293,
          14.987621307373047,
          19.54904556274414,
          24.02044677734375,
          24.18573760986328,
          16.603378295898438,
          14.731316566467285,
          20.573894500732422,
          15.215981483459473,
          4.998029708862305,
          20.568187713623047,
          16.06791877746582,
          23.19717788696289,
          19.221595764160156,
          1.6002341508865356,
          3.6969451904296875,
          17.208194732666016,
          -27.442171096801758,
          4.608526706695557,
          2.7334177494049072,
          20.705791473388672,
          21.438879013061523,
          16.99664878845215,
          -0.8061845302581787,
          21.9985294342041,
          7.523796081542969,
          25.140060424804688,
          16.303586959838867,
          -2.605865001678467,
          2.6830878257751465,
          7.5016961097717285,
          24.385347366333008,
          21.752187728881836,
          21.665679931640625,
          10.350476264953613,
          -12.373699188232422,
          4.47782564163208,
          17.949365615844727,
          24.171825408935547,
          21.68124008178711,
          2.6927194595336914,
          16.38016128540039,
          18.01119613647461,
          16.664939880371094,
          15.114479064941406,
          10.625951766967773,
          12.484184265136719,
          24.491430282592773,
          13.106955528259277,
          -2.6909470558166504,
          19.88892364501953,
          -0.07167015224695206,
          12.160484313964844,
          13.757295608520508,
          -1.8877859115600586,
          18.316450119018555,
          15.348312377929688,
          15.519917488098145,
          16.65144920349121,
          -0.7519659996032715,
          10.354747772216797,
          9.068048477172852,
          -1.622620701789856,
          13.553485870361328,
          9.695343971252441,
          0.6446384191513062,
          2.4340662956237793,
          4.785726070404053,
          12.936891555786133,
          20.513700485229492,
          14.605892181396484,
          16.266738891601562,
          19.04477882385254,
          23.307649612426758,
          24.416101455688477,
          22.971664428710938,
          2.620291233062744,
          -10.01830768585205,
          22.01102066040039,
          -1.1635637283325195,
          18.04245376586914,
          11.99790096282959,
          1.181535005569458,
          17.433822631835938,
          11.272435188293457,
          19.411245346069336,
          17.60016441345215,
          10.782177925109863,
          2.8749289512634277,
          4.250439167022705,
          -2.220949649810791,
          -1.4976261854171753,
          13.909626007080078,
          -0.017795003950595856,
          -0.5510820150375366,
          6.742824077606201,
          10.634481430053711,
          -16.958786010742188,
          -1.4352028369903564,
          -5.501780033111572,
          2.5298712253570557,
          -3.4402923583984375,
          -0.5512891411781311,
          1.372578740119934,
          3.036069631576538,
          3.7166781425476074,
          7.73613977432251,
          0.3470982015132904,
          19.916519165039062,
          -1.3339474201202393,
          3.572627544403076,
          -0.4065278470516205,
          11.53523063659668,
          14.375981330871582,
          0.3562606871128082,
          -0.9828207492828369,
          23.192567825317383,
          -0.9168946743011475,
          22.77515983581543,
          17.38545036315918,
          0.09582705795764923,
          1.0792617797851562,
          22.288667678833008,
          0.8497012257575989,
          16.506309509277344,
          9.267069816589355,
          7.997431755065918,
          5.086019515991211,
          -26.275270462036133,
          11.91435432434082,
          -0.45650461316108704,
          19.54757308959961,
          0.006875417195260525,
          17.60126495361328,
          2.894109010696411,
          1.1970863342285156,
          -0.02528221532702446,
          0.09176052361726761,
          -0.37381237745285034,
          12.748536109924316,
          -2.996121883392334,
          -46.338558197021484,
          7.685907363891602,
          17.75615692138672,
          0.5434800982475281,
          0.9465302228927612,
          8.149006843566895,
          11.054094314575195,
          14.946979522705078,
          9.76899528503418,
          -1.4130569696426392,
          -0.4105776250362396,
          0.6427839994430542,
          0.12581758201122284,
          -0.7714679837226868,
          9.930194854736328,
          -2.0233356952667236,
          18.833959579467773,
          -1.3009518384933472,
          1.583733320236206,
          4.198923587799072,
          2.0162479877471924,
          4.517285346984863,
          -0.20539286732673645,
          2.007535219192505,
          21.935945510864258,
          -0.7255651950836182,
          -1.757766604423523,
          -1.612441062927246,
          4.498409271240234,
          14.070169448852539,
          5.052759170532227,
          8.110037803649902,
          0.5626576542854309,
          0.22518673539161682,
          18.383596420288086,
          -1.5397213697433472,
          0.24015873670578003,
          0.6350048780441284,
          -0.4986307621002197,
          -0.11325690895318985,
          3.6569156646728516,
          -22.786882400512695,
          0.6154741048812866,
          13.052702903747559,
          -32.958003997802734,
          0.6339464783668518,
          3.695513963699341,
          0.09068488329648972,
          -0.4086027443408966,
          17.125783920288086,
          -1.3784180879592896,
          14.603134155273438,
          -0.07373207807540894,
          -9.19187068939209,
          6.0870866775512695,
          -0.24561281502246857,
          -1.9888266324996948,
          3.1321778297424316,
          -25.113487243652344,
          -0.42640694975852966,
          -1.9431085586547852,
          10.372490882873535,
          -1.0717339515686035,
          1.210977554321289,
          -0.6191701889038086,
          0.29112058877944946,
          1.4678399562835693,
          3.127829074859619,
          -1.0645065307617188,
          0.6609445810317993,
          -19.931467056274414,
          -12.880985260009766,
          14.309842109680176,
          13.084365844726562,
          20.912025451660156,
          2.069477081298828,
          0.7603132724761963,
          22.464746475219727,
          13.89038372039795,
          -0.7174940705299377,
          -21.49727439880371,
          -2.667354106903076,
          2.4749016761779785,
          1.0487340688705444,
          -1.4086182117462158,
          0.4260198175907135,
          6.9516496658325195,
          2.880314350128174,
          -35.45818328857422,
          -24.720914840698242,
          -1.4722031354904175,
          4.073564529418945,
          -23.035160064697266,
          16.77804946899414,
          -1.5710129737854004,
          8.825155258178711,
          1.8759565353393555,
          1.8738787174224854,
          -24.022605895996094,
          14.72769832611084,
          -37.17506408691406,
          -2.9673960208892822,
          -1.9735547304153442,
          0.46193137764930725,
          0.7875659465789795,
          0.5775685906410217,
          1.7542649507522583,
          2.901862859725952,
          4.117784023284912,
          0.42871156334877014,
          -9.338611602783203,
          0.37277835607528687,
          1.1995606422424316,
          -1.2364777326583862,
          -5.821591377258301,
          9.549861907958984,
          -0.7863514423370361,
          10.618104934692383,
          -42.718143463134766,
          -2.6167895793914795,
          -23.89661407470703,
          -1.008531093597412,
          -1.6258127689361572,
          0.31403595209121704,
          -10.7280912399292,
          -1.717618465423584,
          -0.324166864156723,
          -4.069635391235352,
          -0.8328933119773865,
          -2.8788254261016846,
          -2.454281806945801,
          0.3882896304130554,
          -6.389466762542725,
          10.748140335083008,
          -17.414085388183594,
          -2.8035295009613037,
          -0.6700605750083923,
          -26.15566635131836,
          0.9938442707061768,
          -0.5680928826332092,
          -1.269790530204773,
          -0.5539544820785522,
          11.269700050354004,
          -25.881441116333008,
          -30.9453125,
          -3.0637731552124023,
          -2.2091352939605713,
          -12.130624771118164,
          1.0871202945709229,
          1.8798465728759766,
          0.6202957034111023,
          -1.1791183948516846,
          -0.6343761682510376,
          -26.98444938659668,
          1.1301249265670776,
          -8.816271781921387,
          -2.0753910541534424,
          4.284494400024414,
          0.26784345507621765,
          0.7214450240135193,
          6.327466011047363,
          -0.6166829466819763,
          10.913239479064941,
          0.07210475206375122,
          1.0132137537002563,
          -29.745288848876953,
          2.886021375656128,
          -33.33330154418945,
          -26.50958251953125,
          1.389282464981079,
          1.584256887435913,
          4.174391746520996,
          3.1139063835144043,
          0.9586948752403259,
          0.22836710512638092,
          2.2865169048309326,
          -19.03481101989746,
          -2.503551959991455,
          -1.9995874166488647,
          -36.8511848449707,
          -21.922697067260742,
          -0.45060527324676514,
          1.241760492324829,
          8.32847785949707,
          -0.05727584287524223,
          -2.469259023666382,
          0.909080982208252,
          0.16063587367534637,
          -54.67453384399414,
          -0.5971680879592896,
          -1.6837795972824097,
          -2.0004963874816895,
          -7.49148416519165,
          -0.6083599925041199,
          -0.5008938312530518,
          -2.307971477508545,
          0.6261478066444397,
          -24.874452590942383,
          -1.4342973232269287,
          1.064823031425476,
          -23.1982479095459,
          -1.2108852863311768,
          -1.4171918630599976,
          -9.85470962524414,
          2.515198230743408,
          7.07289457321167,
          -2.8790125846862793,
          -1.7717198133468628,
          3.7402682304382324,
          -22.902446746826172,
          -0.6877750754356384,
          0.4058285653591156,
          3.1319475173950195,
          -1.3453508615493774,
          -3.2570242881774902,
          0.26079854369163513,
          8.854660034179688,
          9.348898887634277,
          2.0274136066436768,
          -53.79924774169922,
          1.2129693031311035,
          -2.042005777359009,
          -19.75811004638672,
          -1.453749418258667,
          -2.2231109142303467,
          0.39753851294517517,
          -0.9365370869636536,
          0.4793567657470703,
          -0.5085709691047668,
          19.29265022277832,
          3.049375534057617,
          -35.729679107666016,
          5.019779205322266,
          -1.9136301279067993,
          -0.5376431345939636,
          -4.686492443084717,
          13.866445541381836,
          -3.1427483558654785,
          18.87527084350586,
          -0.9989634156227112,
          4.56913948059082,
          -25.369205474853516,
          -2.3683838844299316,
          -0.04435352236032486,
          1.2373453378677368,
          -3.0568788051605225,
          2.430976390838623,
          -15.592735290527344,
          -50.8720817565918,
          -0.616655707359314,
          -0.5044055581092834,
          -4.039966583251953,
          7.515359401702881,
          2.6763339042663574,
          -25.64974021911621,
          -19.96038055419922,
          0.5849405527114868,
          -6.198212146759033,
          -20.92503547668457,
          -7.094146728515625,
          -25.736948013305664,
          18.720382690429688,
          -24.08511734008789,
          -52.42533874511719,
          -14.967716217041016,
          -6.441539764404297,
          1.747381567955017,
          -25.59026527404785,
          -5.9089884757995605,
          -27.7392578125,
          1.8025691509246826,
          -35.55903244018555,
          3.560163736343384,
          -5.053398132324219,
          -10.773052215576172,
          -32.43452835083008,
          -13.709053039550781,
          -3.6364543437957764,
          -45.37288284301758,
          1.207119345664978,
          -20.55109977722168,
          -0.4012301564216614,
          -44.411380767822266,
          -27.412370681762695,
          -42.95516586303711,
          -18.024877548217773,
          -37.10759353637695,
          -2.6379785537719727,
          -0.9132502675056458,
          -0.3797546625137329,
          -18.261493682861328,
          -48.21326446533203,
          1.7963767051696777,
          -2.7892062664031982,
          -3.432079315185547,
          -20.03360366821289,
          2.963536262512207,
          2.135228157043457,
          4.756870746612549,
          16.608409881591797,
          -3.3471503257751465,
          -41.89371871948242,
          -17.38079071044922,
          -12.738906860351562,
          -8.632136344909668,
          0.011908767744898796,
          -0.2536747455596924,
          -14.456722259521484,
          -44.47749328613281,
          2.0268759727478027,
          2.692277193069458,
          1.0719261169433594,
          3.211848735809326,
          -30.66351318359375,
          -46.10020065307617,
          -0.4303567707538605,
          -31.03257179260254,
          -8.587963104248047,
          -8.222103118896484,
          -1.8154842853546143,
          -57.982975006103516,
          -2.120396852493286,
          1.177034616470337,
          0.4461278021335602,
          1.4151194095611572,
          -21.42406463623047,
          -35.126338958740234,
          -2.3014416694641113,
          -0.09361636638641357,
          -26.149124145507812,
          -2.61728572845459,
          -18.731264114379883,
          -2.946834087371826,
          -8.017702102661133,
          -1.4342470169067383,
          -12.210565567016602,
          -29.811647415161133,
          -7.688523292541504,
          -9.916804313659668,
          -17.321487426757812,
          0.049009595066308975,
          -14.3638334274292,
          -1.905029296875,
          -2.8807644844055176,
          -19.001256942749023,
          -22.77046012878418,
          -3.970376491546631,
          -0.6090938448905945,
          -2.438225269317627,
          1.2652531862258911,
          5.634211540222168,
          -42.3107795715332,
          -4.234745025634766,
          -15.780834197998047,
          -33.38306427001953,
          -32.71500015258789,
          0.2870785593986511,
          0.37358129024505615,
          1.6097303628921509,
          2.19494891166687,
          -25.05792808532715,
          -0.6969858407974243,
          -31.978561401367188,
          -0.33516860008239746,
          3.7717502117156982,
          1.906476378440857,
          -11.21977424621582,
          -32.85771560668945,
          -27.855998992919922,
          -10.910672187805176,
          -25.637052536010742,
          1.4110674858093262,
          -63.672569274902344,
          -6.2179718017578125,
          -1.4374382495880127,
          -25.95353126525879,
          3.28578782081604,
          -5.837827205657959,
          1.9495303630828857,
          -23.89106559753418,
          -42.01713943481445,
          -32.37677001953125,
          2.992386817932129,
          -51.394710540771484,
          -0.40026238560676575,
          -24.870346069335938,
          -28.15214729309082,
          -57.834022521972656,
          1.4672133922576904,
          -9.180253982543945,
          -27.75025749206543,
          -21.70440673828125,
          2.082453727722168,
          -28.29978370666504,
          -1.5919454097747803,
          -13.978432655334473,
          -14.216285705566406,
          -7.120874881744385,
          -6.276838302612305,
          -13.103572845458984,
          -6.902421951293945,
          -11.690674781799316,
          -42.151981353759766,
          -2.241472005844116,
          -47.312522888183594,
          -22.70661163330078,
          1.9443391561508179,
          -48.696800231933594,
          -39.95012664794922,
          -62.09553527832031,
          -12.698412895202637,
          -39.97919845581055,
          -0.8955720663070679,
          -26.452831268310547,
          0.07888421416282654,
          -28.586410522460938,
          -38.503936767578125,
          -21.866790771484375,
          -2.651876449584961,
          -43.47300720214844,
          -10.771071434020996,
          -25.380538940429688,
          -32.21110534667969,
          -1.4351036548614502,
          -9.794690132141113,
          -32.99147415161133,
          -8.818865776062012,
          -6.603468894958496,
          -11.266839981079102,
          -48.0175666809082,
          2.493595838546753,
          2.265089988708496,
          0.4923411011695862,
          -24.2969970703125,
          -33.51227569580078,
          0.2594844698905945,
          -31.15080451965332,
          -20.592620849609375,
          3.6584718227386475,
          1.1175175905227661,
          0.2919175326824188,
          -19.572307586669922,
          8.89061164855957,
          -27.5551815032959,
          9.017487525939941,
          -30.961198806762695,
          -1.4297730922698975,
          -51.03990936279297,
          1.817109227180481,
          -28.635833740234375,
          -36.64727783203125,
          0.05390259996056557,
          4.052408218383789,
          -10.277359008789062,
          -30.039138793945312,
          -8.081490516662598,
          1.4811055660247803,
          -12.576462745666504,
          0.16429056227207184,
          2.447619915008545,
          -29.973230361938477,
          -13.887894630432129,
          -11.190906524658203,
          -18.637277603149414,
          -4.301798343658447,
          -26.475215911865234,
          -18.460453033447266,
          2.5184266567230225,
          -17.690614700317383,
          -55.362911224365234,
          -10.022068977355957,
          -5.0934295654296875,
          0.33693984150886536,
          -23.081445693969727,
          -31.159704208374023,
          -23.684337615966797,
          1.0457583665847778,
          -37.470279693603516,
          -12.631122589111328,
          -24.539064407348633,
          -22.007179260253906,
          -54.22319793701172,
          2.905991315841675,
          -32.28556823730469,
          -41.43199920654297,
          -2.2889859676361084,
          -0.4890219569206238,
          -52.75661087036133,
          -1.4495803117752075,
          -0.35434484481811523,
          -25.723047256469727,
          -54.26279830932617,
          -35.64305877685547,
          -22.681297302246094,
          2.1607718467712402,
          -1.5820292234420776,
          -16.744779586791992,
          -33.55047607421875,
          -4.514831066131592,
          -34.430030822753906,
          -3.456413984298706,
          -20.521806716918945,
          -24.931936264038086,
          -21.09436798095703,
          -56.38657760620117,
          -27.441843032836914,
          -2.002441644668579,
          -0.19835828244686127,
          -0.1856309324502945,
          1.5945130586624146,
          -23.419113159179688,
          2.9884073734283447,
          -10.1318998336792,
          -51.02329635620117,
          -50.21891784667969,
          -31.633255004882812,
          -28.233015060424805,
          -30.185869216918945,
          0.29664069414138794,
          4.988540172576904,
          -16.702533721923828,
          -22.2579288482666,
          -47.36125564575195,
          -50.626522064208984,
          -24.224763870239258,
          -65.03779602050781,
          -4.125303745269775,
          -42.54180145263672,
          -61.253841400146484,
          -52.653717041015625,
          -13.32909107208252,
          1.8871525526046753,
          0.23349221050739288,
          -64.81019592285156,
          -0.7207417488098145,
          2.04205322265625,
          -1.7183579206466675,
          -44.591949462890625,
          -61.83828353881836,
          -44.18630599975586,
          -23.00359535217285,
          -9.679850578308105,
          -37.4226188659668,
          -18.01032257080078,
          -30.764598846435547,
          -29.810523986816406,
          -49.87955856323242,
          -56.87492370605469,
          -35.63783264160156,
          -27.5965576171875,
          -13.776752471923828,
          -18.979324340820312,
          -26.81977081298828,
          -1.9636764526367188,
          -54.1273307800293,
          -29.459102630615234,
          -55.101654052734375,
          -8.102020263671875,
          -50.1811637878418,
          -26.750850677490234,
          -48.98596954345703,
          -41.368160247802734,
          -23.938722610473633,
          -31.597883224487305,
          -28.95282554626465,
          -17.695878982543945,
          -53.313209533691406,
          -43.298980712890625,
          -37.01719665527344,
          -37.66227340698242,
          -3.900956869125366,
          1.2557992935180664,
          -5.197650909423828,
          -24.52781867980957,
          -24.812435150146484,
          -34.101253509521484,
          -53.21831130981445,
          -10.185728073120117,
          -27.629613876342773,
          -10.471442222595215,
          2.5960307121276855,
          -60.37038040161133,
          -57.780147552490234,
          -62.13126754760742,
          -1.1928861141204834,
          -34.67100143432617,
          -57.464962005615234,
          -0.8034327626228333,
          -44.69240188598633,
          -29.006664276123047,
          -47.90616226196289,
          -43.26520538330078,
          -30.788850784301758,
          -30.76947784423828,
          -48.36296844482422,
          -26.646484375,
          1.2569804191589355,
          -29.820833206176758,
          -28.821395874023438,
          -0.49743494391441345,
          -19.34469985961914,
          -14.249706268310547,
          -20.94467544555664,
          -7.0912089347839355,
          -50.224266052246094,
          -35.99131393432617,
          -63.2949333190918,
          -32.675254821777344,
          -31.074682235717773,
          -39.83286666870117,
          -46.9051399230957,
          -20.576696395874023,
          -53.63362503051758,
          -2.8762404918670654,
          -40.18208694458008,
          -38.92792510986328,
          -18.453628540039062,
          -32.44289779663086,
          -27.182514190673828,
          -47.003318786621094,
          -63.35349655151367,
          -17.218435287475586,
          3.3195888996124268,
          0.40243595838546753,
          -65.95415496826172,
          4.01845645904541,
          -38.84840774536133,
          -18.2460880279541,
          -60.95521545410156,
          -24.85597801208496,
          -52.87415313720703,
          -23.310176849365234,
          -27.372133255004883,
          -46.42497634887695,
          -26.009729385375977,
          -18.139005661010742,
          -0.1546400487422943,
          -26.91937828063965,
          -7.489840984344482,
          -23.344179153442383,
          -19.920183181762695,
          -21.524324417114258,
          -5.468709468841553,
          -31.2366943359375,
          -37.05009841918945,
          -29.616226196289062,
          -21.48485565185547,
          -49.624412536621094,
          -34.26053237915039,
          -56.14908981323242,
          -61.03622817993164,
          -46.86128616333008,
          -51.254310607910156,
          -65.20624542236328,
          -25.991689682006836,
          -53.16602325439453,
          -38.64210891723633,
          -20.59559440612793,
          -26.71941375732422,
          -61.089820861816406,
          -21.172117233276367,
          -33.938255310058594,
          -19.409128189086914,
          -33.936553955078125,
          -58.238319396972656,
          -41.866600036621094,
          -38.695674896240234,
          -27.942821502685547,
          -66.52279663085938,
          -0.10119383037090302,
          -50.10405731201172,
          -32.42317581176758,
          -4.073795318603516,
          -51.82756805419922,
          -64.58504486083984,
          -39.991329193115234,
          -55.45092010498047,
          -41.05253601074219,
          -54.69552993774414,
          -9.299616813659668,
          -57.91032028198242,
          -24.18267822265625,
          -23.196552276611328,
          -26.546600341796875,
          -20.853879928588867,
          1.0816631317138672,
          -16.102127075195312,
          -16.03643798828125,
          3.1804521083831787,
          -22.522180557250977,
          -30.280603408813477,
          -30.846410751342773,
          -16.762746810913086,
          -62.87126922607422,
          -1.8755916357040405,
          -6.97126579284668,
          3.969926357269287,
          -4.735994815826416,
          -37.59368133544922,
          -16.21868324279785,
          -33.792606353759766,
          -37.43174362182617,
          -16.955562591552734,
          -51.73018264770508,
          -59.00550842285156,
          -47.77365493774414,
          -29.785259246826172,
          -52.56675720214844,
          -27.391305923461914,
          -30.908634185791016,
          -0.4008956849575043,
          -15.962658882141113,
          -27.86629295349121,
          -26.370731353759766,
          -30.366178512573242,
          0.6082648634910583,
          -39.358707427978516,
          -34.71894454956055,
          -29.64044761657715,
          -12.289304733276367,
          -36.5148811340332,
          -22.263769149780273,
          -44.32335662841797,
          -20.200212478637695,
          -37.82971954345703,
          -12.718708992004395,
          -61.92010498046875,
          -32.11528396606445,
          -52.189579010009766,
          -33.413047790527344,
          -40.64430618286133,
          -15.775904655456543,
          -27.55355453491211,
          -29.033428192138672,
          -22.994979858398438,
          -21.934059143066406,
          -40.704715728759766,
          -27.3719482421875,
          -55.99309158325195,
          -64.27161407470703,
          -24.087373733520508,
          -48.17621612548828,
          -62.945831298828125,
          -49.6215705871582,
          -26.415969848632812,
          -53.572059631347656,
          -55.50391387939453,
          -24.861244201660156,
          -26.58673667907715,
          -39.51424026489258,
          -34.162906646728516,
          -10.808326721191406,
          -53.63995361328125,
          -27.231056213378906,
          1.3499854803085327,
          -5.151871204376221,
          -6.418097496032715,
          -19.67656898498535,
          -54.327396392822266,
          -23.562658309936523,
          -6.3375563621521,
          -29.11977195739746,
          -62.7512321472168,
          -22.114553451538086,
          -38.5377197265625,
          -27.567785263061523,
          -34.049373626708984,
          -26.614303588867188,
          -35.01185989379883,
          -52.95496368408203,
          -24.6245174407959,
          -20.72531509399414,
          -63.04983901977539,
          -19.168771743774414,
          -52.80248260498047,
          -54.67930221557617,
          -28.726085662841797,
          -7.397973537445068,
          -63.097591400146484,
          -33.93130111694336,
          -16.929832458496094,
          -57.23928451538086,
          -37.15330505371094,
          -60.846160888671875,
          -34.24761199951172,
          -50.74797058105469,
          -66.06937408447266,
          -21.358749389648438,
          -65.41246795654297,
          -58.65324020385742,
          -31.75824546813965,
          -14.555891036987305,
          -36.1912956237793,
          -61.549591064453125,
          -56.88228988647461,
          -64.04117584228516,
          -57.271976470947266,
          -38.44853973388672,
          -60.53999328613281,
          -46.776973724365234,
          -26.187576293945312,
          -28.57681655883789,
          -29.143674850463867,
          -27.093730926513672,
          -17.831771850585938,
          -43.31077575683594,
          -27.83889389038086,
          -21.99906349182129,
          -62.28582763671875,
          -42.32041549682617,
          -15.890235900878906,
          -59.58487319946289,
          -58.037784576416016,
          -56.09922790527344,
          2.39100980758667,
          -55.23739242553711,
          -9.288338661193848,
          -49.442623138427734,
          -29.71524429321289,
          -31.22238540649414,
          -29.087291717529297,
          -62.788238525390625,
          -66.59609985351562,
          -6.988204479217529,
          -60.99859619140625,
          -20.84716033935547,
          -45.396541595458984,
          -1.4046489000320435,
          -15.596888542175293,
          -17.822622299194336,
          -63.28293991088867,
          -65.61539459228516,
          -52.12105941772461,
          -6.093835353851318,
          -30.913097381591797,
          -35.69634246826172,
          -65.55376434326172,
          -35.132450103759766,
          -44.85443878173828,
          -42.50178146362305,
          -48.19870376586914,
          -63.63154983520508,
          -46.206661224365234,
          -28.76487159729004,
          -8.52045726776123,
          -29.296924591064453,
          -29.48387336730957,
          -44.69129180908203,
          -52.74003982543945,
          -9.372781753540039,
          -2.0279946327209473,
          -16.874202728271484,
          -0.4771023690700531,
          -19.468944549560547,
          -28.857954025268555,
          -11.15005874633789,
          -33.37112045288086,
          -19.244972229003906,
          -27.298614501953125,
          -43.139060974121094,
          -52.772647857666016,
          -24.65019989013672,
          -23.125959396362305,
          -52.0272216796875,
          -32.997230529785156,
          -51.37317657470703,
          -48.332481384277344,
          -53.38039016723633,
          -47.470863342285156,
          -55.441307067871094,
          -39.571895599365234,
          -64.29695129394531,
          -41.11383056640625,
          -1.2680079936981201,
          -51.74498748779297,
          -35.736488342285156,
          -7.962940216064453,
          -38.264461517333984,
          -51.80280303955078,
          -53.98884582519531,
          -59.42874526977539,
          -64.5079116821289,
          -44.80669403076172,
          -55.46623992919922,
          -35.70244598388672,
          -47.5301399230957,
          -49.85493850708008,
          -56.73971176147461,
          -55.439430236816406,
          -41.60988998413086,
          -58.19895553588867,
          -49.46501541137695,
          -8.364484786987305,
          -24.465599060058594,
          -47.63282775878906,
          -44.177860260009766,
          -65.24940490722656,
          -37.36215591430664,
          -55.541690826416016,
          -55.05917739868164,
          -59.089717864990234,
          -21.41656494140625,
          -65.51966857910156,
          -62.23854064941406,
          -27.855998992919922,
          -32.322025299072266,
          -54.19940948486328,
          -36.096771240234375,
          -63.22633743286133,
          -61.42945861816406,
          -23.914562225341797,
          -11.27316665649414,
          -56.558353424072266,
          -25.78115463256836,
          -45.587501525878906,
          -58.56957244873047,
          -44.89455032348633,
          -55.967105865478516,
          -30.703296661376953,
          -58.68805694580078,
          -52.012508392333984,
          -23.38524055480957,
          -66.2469711303711,
          -34.49683380126953,
          -63.5001106262207,
          -19.830307006835938,
          -24.65318489074707,
          -56.64393615722656,
          -24.055912017822266,
          -21.68225860595703,
          -6.992921829223633,
          -60.243812561035156,
          -38.45002746582031,
          -20.17288589477539,
          -59.892852783203125,
          -45.73798751831055,
          -27.503467559814453,
          -32.912261962890625,
          -21.000864028930664,
          -31.077823638916016,
          -51.43962097167969,
          -30.474964141845703,
          -55.3199462890625,
          -30.954662322998047,
          -48.989540100097656,
          -25.89114761352539,
          -13.781683921813965,
          -57.794368743896484,
          -27.743579864501953,
          -47.112403869628906,
          -42.07280349731445,
          -46.09733581542969,
          -59.46648406982422,
          -13.550910949707031,
          -62.55950164794922,
          -54.84550857543945,
          -63.392478942871094,
          -39.740665435791016,
          -26.363330841064453,
          -24.428319931030273,
          -31.539274215698242,
          -34.892730712890625,
          -58.625980377197266,
          -63.97700881958008,
          -46.392826080322266,
          -30.375957489013672,
          -59.94116973876953,
          -45.30947494506836,
          -11.852530479431152,
          -28.815534591674805,
          -37.220096588134766,
          -42.81981658935547,
          -42.13364028930664,
          -50.12867736816406,
          -59.11370849609375,
          -66.93099212646484,
          -29.507522583007812,
          -42.728721618652344,
          -61.87859344482422,
          -66.77777099609375,
          -28.08407211303711,
          -45.629180908203125,
          -41.242916107177734,
          -60.487335205078125,
          -28.303817749023438,
          -27.652740478515625,
          -53.31910705566406,
          -59.39405059814453,
          -61.98940658569336,
          -57.37356948852539,
          -35.328636169433594,
          -41.11159133911133,
          -52.08084487915039,
          -60.52226257324219,
          -28.391677856445312,
          -54.528709411621094,
          -63.09794235229492,
          -28.843841552734375,
          -10.791891098022461,
          -60.84964370727539,
          -66.24417877197266,
          -59.26331329345703,
          -60.580013275146484,
          -60.01472091674805,
          -64.16288757324219,
          -66.34117126464844,
          -25.988475799560547,
          -45.45164489746094,
          -61.442649841308594,
          -53.330604553222656,
          -46.783294677734375,
          -18.861309051513672,
          -47.710208892822266,
          -58.39929962158203,
          -63.44858932495117,
          -59.31199264526367,
          -64.58607482910156,
          -57.92015838623047,
          -11.7380952835083,
          -65.29116821289062,
          -46.53392791748047,
          -59.934932708740234,
          -48.43385696411133,
          -42.93384552001953,
          -1.717584490776062
         ],
         "y": [
          1.735641360282898,
          7.182398319244385,
          5.349972724914551,
          5.19887638092041,
          6.6800947189331055,
          -2.6191365718841553,
          5.745700359344482,
          6.184183120727539,
          7.4797868728637695,
          0.39871975779533386,
          2.198091983795166,
          7.569417953491211,
          5.697879791259766,
          1.771393060684204,
          5.964029312133789,
          -1.2387527227401733,
          -0.7275226712226868,
          6.600334167480469,
          7.374517440795898,
          5.374703407287598,
          7.076833724975586,
          2.5325217247009277,
          6.946719169616699,
          7.394769668579102,
          5.531894683837891,
          -3.142343044281006,
          4.874432563781738,
          5.315820217132568,
          -0.9150426387786865,
          4.441558361053467,
          4.0280327796936035,
          3.8552825450897217,
          7.653477191925049,
          6.456045150756836,
          2.6470539569854736,
          -2.515205144882202,
          3.719376564025879,
          3.5265870094299316,
          -1.7412689924240112,
          1.4241008758544922,
          4.147469997406006,
          1.6978532075881958,
          -2.2780604362487793,
          4.841280937194824,
          -3.0754518508911133,
          7.069218635559082,
          2.1324098110198975,
          3.5564987659454346,
          -0.21931177377700806,
          3.0470595359802246,
          1.6680079698562622,
          -4.200329303741455,
          0.10684747993946075,
          2.9584171772003174,
          0.31372562050819397,
          -1.733917236328125,
          0.6793761849403381,
          2.619253635406494,
          -0.003017986658960581,
          4.697454452514648,
          0.43870753049850464,
          -1.14594304561615,
          -0.9138671159744263,
          -2.4373207092285156,
          1.0702697038650513,
          3.655911684036255,
          -6.241745948791504,
          0.6688761115074158,
          -5.798802375793457,
          -2.8010494709014893,
          -6.751121997833252,
          -9.4113187789917,
          -3.552686929702759,
          -6.384718418121338,
          -1.9999207258224487,
          -5.9595184326171875,
          -4.859402656555176,
          -8.226459503173828,
          -5.557089328765869,
          0.2279672920703888,
          -7.497984886169434,
          -6.991823673248291,
          -8.739903450012207,
          -0.42292630672454834,
          -9.07283878326416,
          -5.282426357269287,
          -7.570653915405273,
          -7.923629283905029,
          -1.6909780502319336,
          -6.434677600860596,
          -3.131195306777954,
          -10.854835510253906,
          -4.872349262237549,
          -9.907697677612305,
          -9.146927833557129,
          -7.960171222686768,
          -8.897527694702148,
          -8.888818740844727,
          -7.238419055938721,
          -9.817962646484375,
          -9.187539100646973,
          -7.470051288604736,
          -5.846661567687988,
          -11.052074432373047,
          -6.149162292480469,
          -9.267770767211914,
          -13.517753601074219,
          -10.468718528747559,
          -13.150712966918945,
          -9.58475112915039,
          -11.421069145202637,
          -8.022844314575195,
          -11.199295043945312,
          -12.75898551940918,
          -14.45858383178711,
          -13.332630157470703,
          -12.888928413391113,
          -9.324236869812012,
          -12.713699340820312,
          -12.039298057556152,
          -13.586457252502441,
          -12.855415344238281,
          -12.520817756652832,
          -14.096269607543945,
          -6.7598066329956055,
          -12.48674201965332,
          -10.415064811706543,
          -13.23083782196045,
          -14.390417098999023,
          -11.984434127807617,
          -13.323434829711914,
          -11.4190092086792,
          -8.34378719329834,
          -9.645219802856445,
          -13.383796691894531,
          -11.212273597717285,
          -13.509037017822266,
          -13.290119171142578,
          -13.527027130126953,
          -8.806547164916992,
          -13.348335266113281,
          -13.654779434204102,
          -13.443571090698242,
          -11.130791664123535,
          -13.287127494812012,
          -13.570125579833984,
          -13.039515495300293,
          -10.616053581237793,
          -10.030670166015625,
          -12.457239151000977,
          -12.173595428466797,
          -13.431922912597656,
          -12.645139694213867,
          -12.308797836303711,
          -13.259971618652344,
          -12.141483306884766,
          -13.710285186767578,
          -13.37851619720459,
          -12.871371269226074,
          -13.07669448852539,
          -8.252129554748535,
          -9.070691108703613,
          -13.384648323059082,
          -13.572379112243652,
          -12.63829231262207,
          -9.681622505187988,
          -7.002124786376953,
          -11.49135684967041,
          -12.361930847167969,
          -13.30583667755127,
          -9.166224479675293,
          -12.395033836364746,
          -13.12459659576416,
          2.731884717941284,
          -11.709555625915527,
          -12.715041160583496,
          1.1452736854553223,
          -12.829412460327148,
          -13.525339126586914,
          -12.174235343933105,
          -9.344234466552734,
          -13.235048294067383,
          -12.734953880310059,
          -12.093995094299316,
          -12.393857955932617,
          -13.259859085083008,
          -8.221565246582031,
          -12.430817604064941,
          -4.717762470245361,
          -11.48372745513916,
          -12.487975120544434,
          -8.279841423034668,
          -12.110169410705566,
          -11.991190910339355,
          -10.688116073608398,
          -9.040762901306152,
          7.963531970977783,
          -8.408764839172363,
          -0.803036630153656,
          -5.580637454986572,
          -13.458524703979492,
          -2.388577461242676,
          -12.9948091506958,
          -8.257889747619629,
          -12.513606071472168,
          0.8747462034225464,
          6.232028484344482,
          -0.0037797605618834496,
          -10.541990280151367,
          13.805891990661621,
          -8.71257495880127,
          -6.081099033355713,
          -1.7845336198806763,
          -1.9049322605133057,
          -8.803363800048828,
          -12.693157196044922,
          -11.437618255615234,
          2.2186715602874756,
          10.291152954101562,
          -8.392044067382812,
          -11.088629722595215,
          -12.992600440979004,
          -3.5424063205718994,
          -4.664063453674316,
          -4.754735946655273,
          -3.234058380126953,
          -9.085814476013184,
          -7.407098293304443,
          1.7985079288482666,
          5.314983367919922,
          7.215017318725586,
          -8.86277961730957,
          -10.15800666809082,
          -0.5461871027946472,
          0.4565531015396118,
          2.135197877883911,
          0.45766952633857727,
          -3.7813339233398438,
          -3.0734896659851074,
          14.452078819274902,
          13.998557090759277,
          -2.756359815597534,
          -5.370961666107178,
          11.306166648864746,
          5.529196739196777,
          0.9698668718338013,
          -9.404895782470703,
          -6.013034343719482,
          9.619644165039062,
          -4.110032081604004,
          -12.926542282104492,
          1.7397154569625854,
          -0.3368566036224365,
          23.474393844604492,
          28.321847915649414,
          4.840431213378906,
          19.983522415161133,
          -2.495558261871338,
          5.721330165863037,
          20.108299255371094,
          5.017350673675537,
          -3.200141429901123,
          16.74408531188965,
          -4.122570514678955,
          -3.3540561199188232,
          -4.159183502197266,
          14.324858665466309,
          29.390104293823242,
          30.074539184570312,
          10.976008415222168,
          9.111379623413086,
          -6.630013465881348,
          1.2832154035568237,
          -3.5230607986450195,
          -3.5853748321533203,
          7.702596664428711,
          -2.6529457569122314,
          17.468116760253906,
          30.722721099853516,
          8.304644584655762,
          3.4615652561187744,
          -2.6798064708709717,
          -5.076521396636963,
          13.445359230041504,
          7.344383716583252,
          16.557872772216797,
          7.933481693267822,
          28.219524383544922,
          6.1283769607543945,
          1.4372631311416626,
          -0.8675364255905151,
          20.88003921508789,
          1.044026255607605,
          3.745957612991333,
          -9.5623779296875,
          24.517114639282227,
          7.121443271636963,
          2.6805925369262695,
          29.25328254699707,
          -15.144668579101562,
          7.438107013702393,
          0.00805997010320425,
          -5.2765936851501465,
          31.919282913208008,
          17.826143264770508,
          6.542314052581787,
          4.253659248352051,
          21.22197723388672,
          1.760037899017334,
          10.439292907714844,
          2.7392001152038574,
          -7.855705261230469,
          15.944955825805664,
          10.335969924926758,
          22.8857364654541,
          10.898571014404297,
          11.65859317779541,
          1.9228403568267822,
          19.044933319091797,
          7.418882369995117,
          17.651758193969727,
          18.269702911376953,
          14.053025245666504,
          24.36391830444336,
          27.523040771484375,
          24.756261825561523,
          8.003626823425293,
          -4.380068302154541,
          22.175893783569336,
          19.976720809936523,
          4.691504001617432,
          23.506620407104492,
          3.4959487915039062,
          13.797696113586426,
          19.485929489135742,
          16.868947982788086,
          18.195064544677734,
          32.700904846191406,
          25.506513595581055,
          17.385679244995117,
          16.764284133911133,
          7.432416915893555,
          5.261027812957764,
          -2.702068567276001,
          31.415624618530273,
          -6.963833808898926,
          25.99310874938965,
          19.021137237548828,
          29.003196716308594,
          29.248727798461914,
          4.09567928314209,
          25.023672103881836,
          9.499035835266113,
          31.756805419921875,
          23.7816162109375,
          9.649519920349121,
          -17.05443572998047,
          26.386184692382812,
          20.44150161743164,
          33.044654846191406,
          20.363475799560547,
          30.87084197998047,
          29.464447021484375,
          22.290666580200195,
          32.64830017089844,
          -19.86457633972168,
          28.091402053833008,
          11.625324249267578,
          23.402822494506836,
          24.005035400390625,
          -20.1605167388916,
          23.004560470581055,
          14.989023208618164,
          9.074828147888184,
          33.83269119262695,
          18.17414665222168,
          26.96902847290039,
          17.27759552001953,
          13.690142631530762,
          28.57636833190918,
          14.970367431640625,
          24.29800796508789,
          22.465702056884766,
          28.069381713867188,
          18.724435806274414,
          31.50334930419922,
          33.97320556640625,
          8.991387367248535,
          7.957767963409424,
          25.744762420654297,
          31.24301528930664,
          10.318156242370605,
          31.251689910888672,
          30.85123634338379,
          -23.236513137817383,
          30.941574096679688,
          28.043527603149414,
          20.677988052368164,
          16.44373321533203,
          32.627952575683594,
          10.816603660583496,
          30.349061965942383,
          31.004310607910156,
          20.53606414794922,
          -25.403093338012695,
          17.845264434814453,
          6.742674350738525,
          27.369678497314453,
          -17.125022888183594,
          28.41766929626465,
          -20.915616989135742,
          27.65300941467285,
          15.611824035644531,
          23.344758987426758,
          16.770442962646484,
          31.20002555847168,
          28.708362579345703,
          -24.082956314086914,
          32.70413589477539,
          31.660058975219727,
          26.182247161865234,
          23.149036407470703,
          -28.21907615661621,
          26.867368698120117,
          -20.35051155090332,
          32.82589340209961,
          20.87135124206543,
          29.82638931274414,
          -16.15599250793457,
          -15.375040054321289,
          15.668071746826172,
          30.070070266723633,
          24.220184326171875,
          29.64978790283203,
          33.375492095947266,
          -24.629011154174805,
          32.66594314575195,
          -15.396551132202148,
          26.07636070251465,
          21.30912208557129,
          23.625667572021484,
          17.771703720092773,
          27.096328735351562,
          17.618806838989258,
          19.306354522705078,
          12.876686096191406,
          -20.44599151611328,
          28.39542007446289,
          31.81942367553711,
          5.956504821777344,
          -4.970758438110352,
          31.087055206298828,
          -15.743395805358887,
          30.193519592285156,
          -16.303667068481445,
          -24.434322357177734,
          -22.46613311767578,
          31.213829040527344,
          31.901411056518555,
          26.56974983215332,
          19.478071212768555,
          -16.731918334960938,
          33.109519958496094,
          30.622459411621094,
          31.965707778930664,
          31.55281639099121,
          -30.290328979492188,
          11.525778770446777,
          30.803756713867188,
          -26.660476684570312,
          -26.19445037841797,
          26.941843032836914,
          -30.50958251953125,
          -31.420591354370117,
          -29.165374755859375,
          24.96113395690918,
          21.611608505249023,
          8.799291610717773,
          27.891916275024414,
          18.605581283569336,
          -17.96385955810547,
          -30.031869888305664,
          -22.877473831176758,
          24.828691482543945,
          31.68728256225586,
          -20.96756362915039,
          -20.472702026367188,
          -16.410062789916992,
          29.82554817199707,
          29.061542510986328,
          27.245349884033203,
          -21.4649658203125,
          32.52738952636719,
          -31.308712005615234,
          29.03619384765625,
          -17.705730438232422,
          32.06355667114258,
          31.924518585205078,
          31.99809455871582,
          31.043529510498047,
          17.312829971313477,
          32.62882614135742,
          31.18124008178711,
          32.84440231323242,
          -17.44063949584961,
          26.71802520751953,
          -19.626384735107422,
          32.885780334472656,
          -22.5003662109375,
          -21.43885040283203,
          -28.63113784790039,
          -23.71935272216797,
          30.426185607910156,
          31.30183982849121,
          -31.455190658569336,
          -20.89138412475586,
          7.5643310546875,
          -24.77048683166504,
          -19.088632583618164,
          -26.896169662475586,
          -19.075912475585938,
          -16.293912887573242,
          -18.81972885131836,
          -14.936238288879395,
          18.387977600097656,
          -26.25588035583496,
          31.398170471191406,
          -9.67534065246582,
          -30.061471939086914,
          28.20980453491211,
          -17.89568328857422,
          31.898460388183594,
          32.83780288696289,
          -15.001946449279785,
          24.514890670776367,
          14.84166145324707,
          33.010616302490234,
          33.081817626953125,
          32.27922439575195,
          33.096622467041016,
          28.974884033203125,
          30.535614013671875,
          -25.994176864624023,
          30.55436897277832,
          32.39180374145508,
          -29.644716262817383,
          -19.57228660583496,
          -17.366731643676758,
          31.184579849243164,
          20.101966857910156,
          -27.54266357421875,
          25.569747924804688,
          -29.165367126464844,
          33.0778923034668,
          30.992839813232422,
          -16.75741195678711,
          -27.448169708251953,
          -21.308876037597656,
          -13.99035930633545,
          31.93610191345215,
          -18.07167625427246,
          32.202632904052734,
          -15.701116561889648,
          -29.213275909423828,
          -9.318072319030762,
          -20.37588882446289,
          -16.332027435302734,
          30.55159568786621,
          -23.472837448120117,
          -18.583765029907227,
          -28.61543846130371,
          -17.85529136657715,
          -28.370271682739258,
          10.874558448791504,
          -24.73692512512207,
          -21.20905303955078,
          24.173429489135742,
          -1.2593134641647339,
          30.72943115234375,
          -18.42303466796875,
          27.26650047302246,
          -23.197128295898438,
          -29.490520477294922,
          24.142505645751953,
          29.226369857788086,
          -29.952131271362305,
          30.608760833740234,
          -19.62969398498535,
          -17.41840171813965,
          -27.822568893432617,
          31.42001724243164,
          -22.40554428100586,
          -28.812969207763672,
          -30.391124725341797,
          -25.383438110351562,
          -28.740341186523438,
          -20.0793514251709,
          -23.24313735961914,
          -27.185422897338867,
          -27.666393280029297,
          -29.06728172302246,
          9.996942520141602,
          -29.855894088745117,
          -26.350154876708984,
          -20.916372299194336,
          -19.331037521362305,
          -25.909255981445312,
          -12.380099296569824,
          -22.306713104248047,
          -28.742530822753906,
          27.73493766784668,
          -27.389680862426758,
          -13.510350227355957,
          -25.42075538635254,
          -29.497934341430664,
          -17.47067642211914,
          -20.905771255493164,
          -19.180551528930664,
          -28.9679012298584,
          20.53605842590332,
          -28.638559341430664,
          -25.44788932800293,
          28.82526969909668,
          -21.62024688720703,
          -27.91364097595215,
          -28.569204330444336,
          -27.076683044433594,
          31.054460525512695,
          -28.801433563232422,
          31.861257553100586,
          -30.728418350219727,
          -16.897335052490234,
          32.154029846191406,
          -20.144987106323242,
          30.306941986083984,
          -8.405871391296387,
          -29.17523956298828,
          -28.892730712890625,
          -5.506521224975586,
          -25.47267723083496,
          31.882457733154297,
          -26.847980499267578,
          -27.362768173217773,
          -3.66603946685791,
          -31.229890823364258,
          -28.051008224487305,
          -16.936054229736328,
          32.31870651245117,
          -30.031497955322266,
          -23.32623863220215,
          6.084774971008301,
          -30.169755935668945,
          -28.619089126586914,
          -24.04109764099121,
          32.80069351196289,
          -28.068138122558594,
          -25.7181339263916,
          -19.0559024810791,
          -17.96834945678711,
          -18.639123916625977,
          -27.169063568115234,
          19.158721923828125,
          -17.989944458007812,
          -22.044832229614258,
          -26.818384170532227,
          -29.337793350219727,
          -25.939931869506836,
          31.698001861572266,
          -28.369115829467773,
          -22.957077026367188,
          -25.95400619506836,
          -29.579059600830078,
          -1.1425681114196777,
          -27.267488479614258,
          -15.01543140411377,
          -22.51764678955078,
          -27.876598358154297,
          -15.919997215270996,
          -19.38258934020996,
          -30.137338638305664,
          -30.08995819091797,
          15.187898635864258,
          -12.952849388122559,
          16.192773818969727,
          -25.677005767822266,
          -20.80837059020996,
          -7.1812262535095215,
          -3.61592698097229,
          -26.968578338623047,
          9.946601867675781,
          -31.515762329101562,
          -26.249950408935547,
          -23.52895736694336,
          -9.674466133117676,
          -28.205270767211914,
          -14.692170143127441,
          -28.262451171875,
          -27.827686309814453,
          -14.03217601776123,
          -10.931182861328125,
          -17.215002059936523,
          -23.471298217773438,
          -20.827808380126953,
          -26.963008880615234,
          -21.32710075378418,
          -3.5432937145233154,
          -21.344253540039062,
          -8.721151351928711,
          -28.94192123413086,
          -30.408950805664062,
          -28.233509063720703,
          -29.39112091064453,
          5.366730213165283,
          -30.459993362426758,
          -12.223764419555664,
          29.946996688842773,
          -3.0835981369018555,
          -28.26333999633789,
          -1.3537217378616333,
          9.035228729248047,
          -24.546918869018555,
          -1.8268433809280396,
          -15.954585075378418,
          -28.442514419555664,
          -11.603012084960938,
          -11.5103759765625,
          -30.822776794433594,
          -25.24367332458496,
          -6.011133670806885,
          -24.934499740600586,
          -30.034347534179688,
          -31.215368270874023,
          -28.122339248657227,
          -29.841590881347656,
          -15.328736305236816,
          -17.068655014038086,
          -27.199546813964844,
          2.7911648750305176,
          -11.0541410446167,
          -31.26322364807129,
          -11.440716743469238,
          -25.5772647857666,
          -13.605563163757324,
          -25.988162994384766,
          -27.753398895263672,
          1.7901997566223145,
          -27.07455825805664,
          -3.575500011444092,
          -0.0935896709561348,
          -19.979482650756836,
          -19.73668098449707,
          -14.393446922302246,
          10.521893501281738,
          -28.33072853088379,
          -29.24501609802246,
          -28.859872817993164,
          -29.10210609436035,
          2.2553725242614746,
          -15.537883758544922,
          -26.78216552734375,
          -16.221771240234375,
          -2.4438633918762207,
          -27.140932083129883,
          -11.99191951751709,
          -5.821395397186279,
          -1.817177176475525,
          8.649747848510742,
          -22.161142349243164,
          -29.918779373168945,
          -4.229680061340332,
          -25.61725425720215,
          -29.936546325683594,
          -10.012751579284668,
          -8.432439804077148,
          -25.20198631286621,
          -18.90831184387207,
          -28.25536346435547,
          -25.336605072021484,
          15.912932395935059,
          -28.439706802368164,
          -24.699100494384766,
          -21.059185028076172,
          7.6519293785095215,
          10.247003555297852,
          15.982287406921387,
          17.495847702026367,
          -30.31688690185547,
          -23.893299102783203,
          -25.73927879333496,
          9.127035140991211,
          -24.70124053955078,
          5.935776233673096,
          -0.7242749929428101,
          -7.927272319793701,
          -25.074560165405273,
          8.01701831817627,
          17.658226013183594,
          -29.98561668395996,
          31.781757354736328,
          -19.983652114868164,
          -29.10269546508789,
          -7.22918176651001,
          -17.22917366027832,
          -29.313535690307617,
          -9.939618110656738,
          13.657977104187012,
          -9.364885330200195,
          1.8913079500198364,
          -12.722254753112793,
          -24.793136596679688,
          -7.68479585647583,
          -29.774364471435547,
          -2.8102025985717773,
          -10.190690994262695,
          10.446944236755371,
          -19.253355026245117,
          -28.979347229003906,
          6.109312534332275,
          32.38117980957031,
          12.809752464294434,
          -30.072492599487305,
          9.212651252746582,
          -25.1507568359375,
          8.422215461730957,
          -30.251075744628906,
          -9.243515968322754,
          -19.25796890258789,
          -22.0965518951416,
          4.298635959625244,
          -12.092887878417969,
          -6.859236717224121,
          4.0791544914245605,
          -29.7412166595459,
          -29.83360481262207,
          -9.93264389038086,
          19.83002281188965,
          -1.020037055015564,
          -24.837907791137695,
          14.99825668334961,
          18.76936912536621,
          -28.4210147857666,
          -9.880537033081055,
          32.58967971801758,
          -8.466654777526855,
          -21.873254776000977,
          12.180092811584473,
          -14.0172758102417,
          -10.89797592163086,
          -1.3530665636062622,
          16.188295364379883,
          -7.467169761657715,
          0.5269630551338196,
          15.264205932617188,
          3.574150800704956,
          14.550435066223145,
          -12.566797256469727,
          -12.234539985656738,
          20.125337600708008,
          -28.48406219482422,
          10.981051445007324,
          -16.274620056152344,
          -8.03364372253418,
          2.6837832927703857,
          8.570662498474121,
          7.070242881774902,
          -23.792949676513672,
          -5.133358001708984,
          32.315670013427734,
          6.35216760635376,
          -3.2116997241973877,
          -9.107884407043457,
          -10.599565505981445,
          18.324872970581055,
          -9.060760498046875,
          4.0427727699279785,
          -12.31342887878418,
          -17.068431854248047,
          -20.180967330932617,
          9.55820083618164,
          10.7279634475708,
          14.996768951416016,
          12.6881103515625,
          5.150139331817627,
          4.345326900482178,
          -1.832120418548584,
          -29.71876335144043,
          -16.863340377807617,
          -30.205284118652344,
          -25.534318923950195,
          -24.465328216552734,
          -2.648829221725464,
          -2.475494384765625,
          -2.0928268432617188,
          7.775960922241211,
          11.272541999816895,
          -11.286895751953125,
          5.196899890899658,
          -0.26311174035072327,
          1.7704241275787354,
          1.650128722190857,
          0.8574631810188293,
          14.680523872375488,
          -17.046777725219727,
          -21.03080940246582,
          -7.304313659667969,
          10.346055030822754,
          -10.342813491821289,
          -10.02628231048584,
          -30.07730484008789,
          10.254145622253418,
          -19.593183517456055,
          3.9271514415740967,
          -19.670177459716797,
          -6.177830696105957,
          5.0862531661987305,
          -19.32229232788086,
          -18.002010345458984,
          18.14251708984375,
          -21.252408981323242,
          -18.386798858642578,
          -10.157184600830078,
          -2.7027368545532227,
          6.851766109466553,
          11.490328788757324,
          3.3745875358581543,
          6.586488723754883,
          -8.74865436553955,
          -10.32693099975586,
          16.624359130859375,
          12.504788398742676,
          -28.070241928100586,
          -17.753997802734375,
          8.831262588500977,
          3.6736531257629395,
          11.177635192871094,
          -25.241363525390625,
          10.80714225769043,
          7.422320365905762,
          -19.909530639648438,
          15.720442771911621,
          -10.78830623626709,
          -31.5447998046875,
          -29.089189529418945,
          -3.128173351287842,
          -4.233945369720459,
          -7.336618423461914,
          -8.56334114074707,
          12.496079444885254,
          -17.733047485351562,
          -6.1550517082214355,
          -22.729902267456055,
          -6.389270782470703,
          -4.606468677520752,
          -3.5375025272369385,
          -26.09827995300293,
          4.1515326499938965,
          -9.066004753112793,
          -28.770265579223633,
          -5.324825286865234,
          -7.233496189117432,
          17.43854522705078,
          -30.123764038085938,
          14.903369903564453,
          -24.74650764465332,
          -20.144033432006836,
          -28.18085289001465,
          12.543378829956055,
          -12.770752906799316,
          15.000421524047852,
          3.364081621170044,
          15.695708274841309,
          6.484275817871094,
          16.574350357055664,
          -6.863672256469727,
          2.3085474967956543,
          -21.728439331054688,
          14.561519622802734,
          -30.807125091552734,
          6.418302536010742,
          4.660369396209717,
          14.416434288024902,
          12.854944229125977,
          14.252376556396484,
          12.406790733337402,
          17.710262298583984,
          9.722150802612305,
          -25.85719871520996,
          5.630206108093262,
          -8.46196460723877,
          17.817703247070312,
          15.40408992767334,
          -8.246891975402832,
          1.191173791885376,
          13.48697280883789,
          3.2988076210021973,
          8.774523735046387,
          -8.041666984558105,
          -28.843204498291016,
          17.368528366088867,
          21.052471160888672,
          -7.1507673263549805,
          18.896942138671875,
          16.197689056396484,
          -9.387308120727539,
          7.1812520027160645,
          13.953465461730957,
          11.565773963928223,
          -7.938084602355957,
          -0.08088063448667526,
          -12.958375930786133,
          13.016139030456543,
          -6.434439182281494,
          16.35396385192871,
          -9.178550720214844,
          10.229949951171875,
          12.79198932647705,
          -8.057771682739258,
          8.559324264526367,
          10.229228973388672,
          17.320945739746094,
          13.123831748962402,
          8.08818244934082,
          10.446688652038574,
          -30.4165096282959,
          -28.406192779541016,
          13.038477897644043,
          -10.035426139831543,
          15.636959075927734,
          20.455707550048828,
          19.02963638305664,
          -6.5972771644592285,
          -14.415245056152344,
          14.219542503356934,
          -11.003541946411133,
          2.8819057941436768,
          3.66770339012146,
          1.9273595809936523,
          4.934467315673828,
          -1.809154748916626,
          -10.931357383728027,
          -25.85857582092285,
          -9.446808815002441,
          20.605514526367188,
          18.043132781982422,
          7.629074573516846,
          -2.1960396766662598,
          14.906732559204102,
          0.9235325455665588,
          5.585403919219971,
          -5.282473087310791,
          13.758034706115723,
          -6.530067443847656,
          -15.445625305175781,
          3.3765909671783447,
          -2.763425827026367,
          -16.126638412475586,
          16.934246063232422,
          14.008330345153809,
          16.46647071838379,
          12.53818416595459,
          19.005538940429688,
          -5.009090423583984,
          20.243160247802734,
          15.281058311462402,
          12.729381561279297,
          7.670867443084717,
          17.1082820892334,
          9.813109397888184,
          -15.213857650756836,
          12.038390159606934,
          10.589621543884277,
          13.157872200012207,
          12.845795631408691,
          -16.408262252807617,
          0.7350339293479919,
          -29.474821090698242,
          -11.718507766723633,
          15.48658275604248,
          16.91604995727539,
          -7.044911861419678,
          -9.04479694366455,
          -0.3428201973438263,
          14.081622123718262,
          -1.0352833271026611,
          -2.400451898574829,
          -3.223658561706543,
          8.000752449035645,
          -1.3196779489517212,
          -9.005880355834961,
          -27.473661422729492,
          1.9389020204544067,
          18.805335998535156,
          -8.033381462097168,
          1.6611183881759644,
          21.075946807861328,
          -0.17636793851852417,
          9.692421913146973,
          2.975482702255249,
          18.29659080505371,
          15.180672645568848,
          8.90335464477539,
          10.255383491516113,
          16.927642822265625,
          2.587768793106079,
          8.44845199584961,
          -11.950289726257324,
          -2.5299572944641113,
          2.586890697479248,
          -6.249433517456055,
          -18.363643646240234,
          8.489839553833008,
          -0.048271264880895615,
          -2.637840509414673,
          4.6243133544921875,
          16.895124435424805,
          -0.15827873349189758,
          12.186981201171875,
          -1.8525350093841553,
          7.74022102355957,
          -7.247063636779785,
          17.996885299682617,
          16.03249168395996,
          19.65786361694336,
          18.030031204223633,
          16.113975524902344,
          16.19017219543457,
          19.47186279296875,
          -7.792626857757568,
          13.35338306427002,
          -12.723688125610352,
          14.884377479553223,
          5.4722490310668945,
          -8.215906143188477,
          -11.60930061340332,
          0.6000919342041016,
          17.639484405517578,
          -11.253679275512695,
          -22.247644424438477,
          7.862364292144775,
          11.769451141357422,
          -2.6449685096740723,
          -8.59389591217041,
          9.230488777160645,
          12.354130744934082,
          -10.58874797821045,
          17.953432083129883,
          7.999058723449707,
          -3.8517518043518066,
          13.633068084716797,
          18.024295806884766,
          -6.460742473602295,
          17.1133975982666,
          16.322566986083984,
          17.856115341186523,
          -12.287131309509277,
          9.869866371154785,
          -4.414822578430176,
          -11.546417236328125,
          11.130188941955566,
          -5.65168571472168,
          13.741731643676758,
          -5.074069023132324,
          15.068650245666504,
          3.8756263256073,
          10.632871627807617,
          -23.28560447692871,
          9.189112663269043,
          -29.056764602661133,
          -3.1218862533569336,
          -29.328105926513672,
          0.04897941276431084,
          -6.644769191741943,
          -8.588356971740723,
          -5.9267258644104,
          -3.3088936805725098,
          -9.777528762817383,
          8.161184310913086,
          1.6542452573776245,
          19.627443313598633,
          -0.4570651650428772,
          18.919004440307617,
          7.038595676422119,
          17.966318130493164,
          -23.603408813476562,
          2.235623836517334,
          -3.930405616760254,
          19.456871032714844,
          19.69580841064453,
          13.530729293823242,
          17.11013412475586,
          7.216124534606934,
          10.49123764038086,
          8.905542373657227,
          14.2090425491333,
          -5.033754825592041,
          19.91672706604004,
          18.269989013671875,
          9.558331489562988,
          10.526613235473633,
          -7.759783744812012,
          9.643060684204102,
          7.811359882354736,
          -8.04407787322998,
          19.86263656616211,
          11.444540977478027,
          7.663875102996826,
          -4.0683064460754395,
          0.7225781083106995,
          -1.7160305976867676,
          -11.278511047363281,
          -12.056344032287598,
          9.062745094299316,
          -8.59330940246582,
          7.334203243255615,
          -22.14989471435547,
          -1.8610068559646606,
          -8.039210319519043,
          -10.040494918823242,
          12.733755111694336,
          11.222646713256836,
          10.153867721557617,
          14.3572416305542,
          -6.192142963409424,
          14.316709518432617,
          -6.628612041473389,
          13.123394012451172,
          9.679086685180664,
          13.634101867675781,
          12.155390739440918,
          -3.320855140686035,
          -3.8829345703125,
          -20.200027465820312,
          5.968723297119141,
          -6.155409812927246,
          -5.69950008392334,
          6.115879535675049,
          1.7124388217926025,
          18.51012420654297,
          -4.680210590362549,
          -8.513611793518066,
          -3.3767127990722656,
          0.016715215519070625,
          2.003873586654663,
          -16.999107360839844,
          4.140839099884033,
          15.293700218200684,
          14.621776580810547,
          -8.470364570617676,
          -9.30115032196045,
          4.238299369812012,
          6.50708532333374,
          11.851863861083984,
          -11.563215255737305,
          0.3131040930747986,
          -3.4490408897399902,
          18.574167251586914,
          0.20636306703090668,
          -6.064156532287598,
          5.120077133178711,
          15.172467231750488,
          8.197235107421875,
          15.148300170898438,
          -11.947823524475098,
          2.449552297592163,
          -12.389097213745117,
          12.671080589294434,
          18.079391479492188,
          -10.567025184631348,
          11.130126953125,
          -4.130402088165283,
          -6.3521294593811035,
          -7.726385116577148,
          -2.763244867324829,
          -11.231351852416992,
          7.8517656326293945,
          18.537975311279297,
          13.608415603637695,
          0.8695192337036133,
          -15.486300468444824,
          -7.954296588897705,
          -3.3677780628204346,
          -7.2785725593566895,
          16.678537368774414,
          -11.564949035644531,
          1.3002521991729736,
          -6.79778528213501,
          -12.627767562866211,
          9.612163543701172,
          -3.618194103240967,
          3.1498825550079346,
          15.395407676696777,
          -7.5964035987854,
          -10.717901229858398,
          -9.195384979248047,
          -9.560256004333496,
          15.104300498962402,
          9.928762435913086,
          15.928909301757812,
          7.649730682373047,
          11.705695152282715,
          -10.39688491821289,
          -2.808406114578247,
          18.045454025268555,
          6.471303939819336,
          17.03453254699707,
          12.461481094360352,
          0.9140745401382446,
          -0.5817347168922424,
          5.152626037597656,
          -16.766782760620117,
          -5.865133285522461,
          0.8378266096115112,
          12.87220573425293,
          -13.715971946716309,
          1.2292044162750244,
          -12.406059265136719,
          -11.577040672302246,
          -4.727160930633545,
          -3.226412057876587,
          -8.99348258972168,
          0.4810429811477661,
          7.037015914916992,
          0.27867192029953003,
          -4.811863422393799,
          9.174407005310059,
          14.019140243530273,
          17.296823501586914,
          9.032203674316406,
          18.357227325439453,
          -10.259580612182617,
          -7.15833044052124,
          4.7794671058654785,
          -8.61828899383545,
          -6.139187335968018,
          -11.706964492797852,
          -10.40929889678955,
          13.030158996582031,
          -5.51170539855957,
          10.33674144744873,
          -9.947155952453613,
          -11.360279083251953,
          14.911725997924805,
          -6.0206122398376465,
          1.6487371921539307,
          -10.349498748779297,
          5.397541522979736,
          17.6856689453125,
          2.385141611099243,
          8.789698600769043,
          6.966601848602295,
          3.0491533279418945,
          -10.573698043823242,
          11.049549102783203,
          1.270965814590454,
          13.547670364379883,
          -6.231499671936035,
          5.462351322174072,
          9.897124290466309,
          -13.068432807922363,
          -3.087031602859497,
          15.770827293395996,
          -2.4285922050476074,
          -4.2058305740356445,
          14.988302230834961,
          13.696999549865723,
          10.81096363067627,
          10.529365539550781,
          16.31368637084961,
          -7.008412837982178,
          -8.745302200317383,
          -1.6039915084838867,
          12.62464427947998,
          -8.151501655578613,
          -4.181075096130371,
          -5.7697577476501465,
          1.0399903059005737,
          -11.656743049621582,
          -5.097140789031982,
          6.06613826751709,
          -1.339036464691162,
          -6.5703444480896,
          -6.476625442504883,
          10.369129180908203,
          10.6033935546875,
          2.6037144660949707,
          14.176546096801758,
          -8.022924423217773,
          16.682498931884766,
          -3.675039052963257,
          -2.0664851665496826,
          -8.7634859085083,
          -8.912681579589844,
          -1.7934261560440063,
          7.526803016662598,
          2.090129852294922,
          -5.171795845031738,
          -6.050704479217529,
          19.630998611450195,
          -8.103646278381348,
          3.796490430831909,
          -9.287589073181152,
          -3.745117664337158,
          -13.185900688171387,
          -6.750227451324463,
          17.201452255249023,
          -1.4890369176864624,
          9.874855995178223,
          12.136228561401367,
          4.928591728210449,
          9.148083686828613,
          -9.049237251281738,
          14.01098346710205,
          12.640750885009766,
          10.439215660095215,
          11.260611534118652,
          -2.274075508117676,
          -3.123100519180298,
          14.60676097869873,
          4.4021992683410645,
          17.407257080078125,
          16.87938690185547,
          5.254757881164551,
          18.60306739807129,
          -10.633279800415039,
          16.200586318969727,
          -6.849496841430664,
          -8.588987350463867,
          13.784758567810059,
          -5.359262466430664,
          0.6353601813316345,
          -11.598578453063965,
          4.422555923461914,
          -6.33329439163208,
          -1.6930935382843018,
          -4.789739608764648,
          11.270730972290039,
          15.41317367553711,
          -0.5294869542121887,
          -5.470694541931152,
          -7.34291934967041,
          12.459693908691406,
          -8.56721305847168,
          -7.780171871185303,
          -1.390990138053894,
          15.084861755371094,
          -8.718332290649414,
          7.38089656829834,
          -12.612783432006836,
          15.795747756958008,
          -11.05583667755127,
          16.684541702270508,
          4.800833702087402,
          -4.886940002441406,
          -5.882748126983643,
          -5.091859340667725,
          -12.22791576385498,
          14.37110710144043,
          5.21095609664917,
          -6.9626383781433105,
          9.34056568145752,
          12.193835258483887,
          -8.02704906463623,
          -1.3837432861328125,
          -4.497095584869385,
          4.089738368988037,
          4.345913410186768,
          -9.230588912963867,
          3.4182779788970947,
          -10.284414291381836,
          6.121289253234863,
          -3.8330445289611816,
          -2.588992118835449,
          5.888871669769287,
          10.99128532409668,
          -9.40084457397461,
          -10.790745735168457,
          17.818307876586914,
          -7.654120445251465,
          7.848167896270752,
          -0.339521199464798,
          18.074111938476562,
          14.87211799621582,
          9.125638008117676,
          -3.9802074432373047,
          7.607451915740967,
          19.903152465820312,
          -0.8620360493659973,
          1.805676817893982,
          12.624170303344727,
          -10.369573593139648,
          -2.4939005374908447,
          -4.978275775909424,
          6.656164646148682,
          -5.5371317863464355,
          -7.500277519226074,
          2.1927883625030518,
          15.385416030883789,
          3.1474056243896484,
          16.435420989990234,
          -4.8877129554748535,
          -5.969909191131592,
          1.589290976524353,
          14.982165336608887,
          4.517645835876465,
          -8.569204330444336,
          17.685144424438477,
          0.6585708856582642,
          -12.142658233642578,
          4.20700216293335,
          -8.771297454833984,
          -9.156856536865234,
          7.405279159545898,
          11.368929862976074,
          6.926969528198242,
          -2.9511687755584717,
          -1.181413173675537,
          18.28303337097168,
          -5.931913375854492,
          3.489035129547119,
          -1.8000340461730957,
          5.4276533126831055,
          -2.787590265274048,
          -12.375359535217285,
          -0.3464111089706421,
          -9.387301445007324,
          -1.0878448486328125,
          -5.677570819854736,
          1.233275055885315,
          -2.426344871520996,
          14.96544361114502,
          -9.508048057556152,
          2.979623556137085,
          8.068782806396484,
          3.9068424701690674,
          -8.750682830810547,
          16.556793212890625,
          0.12230447679758072,
          -0.20081600546836853,
          -3.277921676635742,
          -0.855522096157074,
          -3.4780242443084717,
          18.024030685424805,
          -6.578836917877197,
          -4.449005126953125,
          1.8309165239334106,
          -3.966339111328125,
          5.060880184173584,
          7.717019081115723,
          18.765003204345703,
          3.0220794677734375,
          12.377551078796387,
          -8.145630836486816,
          -5.662277698516846,
          19.320640563964844,
          11.992688179016113,
          5.468421936035156,
          6.440549373626709,
          -3.6470558643341064,
          16.98076820373535,
          -9.388823509216309,
          -7.302094459533691,
          6.627552509307861,
          -7.992072582244873,
          -10.055009841918945,
          -7.699041366577148,
          -12.354296684265137,
          4.100208282470703,
          -13.43835735321045,
          -2.3902511596679688,
          14.320380210876465,
          -0.4363109767436981,
          1.2045772075653076,
          -10.744460105895996,
          -3.6464896202087402,
          15.528726577758789,
          -9.82917308807373,
          16.63888931274414,
          9.633413314819336,
          15.725608825683594,
          -3.4912967681884766,
          18.162567138671875,
          -9.416522979736328,
          11.938117980957031,
          9.684212684631348,
          -9.03542423248291,
          -4.778174877166748,
          5.34044075012207,
          8.546277046203613,
          -7.206191062927246,
          -9.444153785705566,
          -8.202540397644043,
          -9.515714645385742,
          -4.146864414215088,
          -7.592575550079346,
          -3.858961582183838,
          -8.526620864868164,
          3.821094274520874,
          -10.001967430114746,
          12.861048698425293,
          -7.136057376861572,
          -11.097457885742188,
          15.885682106018066,
          -7.874370574951172,
          -5.8837809562683105,
          -4.979372501373291,
          -1.7288713455200195,
          5.976747512817383,
          -10.844013214111328,
          -1.2556605339050293,
          -9.030580520629883,
          -11.122174263000488,
          -6.529136657714844,
          -0.17430362105369568,
          -1.389836072921753,
          -9.674698829650879,
          2.17258620262146,
          -8.8948974609375,
          20.21411895751953,
          8.431112289428711,
          -10.947418212890625,
          -9.874539375305176,
          5.299598217010498,
          -12.264266967773438,
          -7.1093339920043945,
          -2.840860366821289,
          1.5384970903396606,
          10.460433959960938,
          5.906365394592285,
          3.583160638809204,
          -4.1736602783203125,
          -7.142764091491699,
          -3.3661177158355713,
          -7.8798370361328125,
          3.956028461456299,
          2.0266013145446777,
          3.3078603744506836,
          15.444939613342285,
          -4.194111347198486,
          8.008017539978027,
          -7.952826499938965,
          0.996685802936554,
          -13.61886215209961,
          -6.633680820465088,
          -0.9256466031074524,
          -0.06400114297866821,
          -7.142338275909424,
          8.945508003234863,
          7.35276985168457,
          -9.366840362548828,
          5.40056037902832,
          11.229658126831055,
          6.663877487182617,
          -1.2774065732955933,
          12.398787498474121,
          6.450845241546631,
          19.11446762084961,
          -0.40970632433891296,
          -7.4484405517578125,
          10.663776397705078,
          3.4421510696411133,
          -7.740541934967041,
          -2.9848055839538574,
          -8.065303802490234,
          15.27479076385498,
          1.8144760131835938,
          -3.926269292831421,
          -2.46978759765625,
          -4.965546607971191,
          -1.8529564142227173,
          -10.278128623962402,
          11.718366622924805,
          17.10973358154297,
          -4.267834663391113,
          -5.229687690734863,
          -8.066085815429688,
          -10.152583122253418,
          -10.918437004089355,
          2.599374771118164,
          15.90294361114502,
          1.8638449907302856,
          -3.032684087753296,
          2.58538556098938,
          -11.020291328430176,
          1.9112653732299805,
          6.632382869720459,
          -2.599011182785034,
          -9.872811317443848,
          -0.639639675617218,
          3.6661109924316406,
          -8.861452102661133,
          -5.651010990142822,
          2.2228918075561523,
          -9.151947021484375,
          16.48920440673828,
          -1.4935204982757568,
          -10.058372497558594,
          -12.453620910644531,
          -11.302836418151855,
          -8.449735641479492,
          0.849470317363739,
          7.991910457611084,
          -6.0898332595825195,
          -10.362504005432129,
          3.625548839569092,
          7.869830131530762,
          -5.995707035064697,
          -10.635302543640137,
          -8.95701789855957,
          4.120894908905029,
          -1.512418270111084,
          5.24622917175293,
          -3.1122121810913086,
          0.6010280847549438,
          1.29890775680542,
          -1.6297346353530884,
          -8.80595874786377,
          -11.417948722839355,
          -5.301873207092285,
          2.8476405143737793,
          -4.402142524719238,
          -5.402554035186768,
          3.2659525871276855,
          -1.7544447183609009,
          18.770225524902344,
          1.9494585990905762,
          7.3985161781311035,
          1.4299373626708984,
          4.455219268798828,
          -0.9136273264884949,
          6.219705581665039,
          6.943734645843506,
          8.870448112487793,
          -11.966331481933594,
          2.318817138671875,
          -6.1107964515686035,
          -9.48292064666748,
          8.852065086364746,
          -10.306638717651367,
          1.3085702657699585,
          4.512131214141846,
          -0.4018937945365906,
          4.353875160217285,
          -0.43589428067207336,
          16.616785049438477,
          6.155932903289795,
          -11.799840927124023,
          3.1050405502319336,
          -10.339310646057129,
          -13.068232536315918,
          11.666439056396484
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"5a4de08b-deab-4477-aa0b-a380d1b05534\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5a4de08b-deab-4477-aa0b-a380d1b05534\")) {                    Plotly.newPlot(                        \"5a4de08b-deab-4477-aa0b-a380d1b05534\",                        [{\"mode\":\"text\",\"text\":[\"the\",\"to\",\"of\",\"in\",\"and\",\"he\",\"is\",\"for\",\"on\",\"said\",\"that\",\"has\",\"says\",\"was\",\"have\",\"it\",\"be\",\"are\",\"with\",\"will\",\"at\",\"mr\",\"from\",\"by\",\"we\",\"been\",\"as\",\"an\",\"not\",\"his\",\"but\",\"they\",\"after\",\"were\",\"had\",\"there\",\"new\",\"this\",\"australia\",\"australian\",\"who\",\"palestinian\",\"people\",\"their\",\"government\",\"two\",\"up\",\"south\",\"us\",\"which\",\"year\",\"one\",\"about\",\"out\",\"if\",\"also\",\"more\",\"when\",\"its\",\"into\",\"would\",\"first\",\"last\",\"against\",\"israeli\",\"minister\",\"arafat\",\"over\",\"all\",\"three\",\"afghanistan\",\"united\",\"world\",\"no\",\"or\",\"police\",\"than\",\"attacks\",\"fire\",\"before\",\"some\",\"security\",\"day\",\"you\",\"states\",\"could\",\"them\",\"say\",\"today\",\"now\",\"told\",\"time\",\"any\",\"laden\",\"very\",\"bin\",\"just\",\"can\",\"sydney\",\"what\",\"still\",\"company\",\"president\",\"man\",\"four\",\"taliban\",\"killed\",\"our\",\"forces\",\"al\",\"around\",\"being\",\"days\",\"west\",\"old\",\"other\",\"officials\",\"where\",\"so\",\"test\",\"qaeda\",\"israel\",\"think\",\"per\",\"general\",\"next\",\"federal\",\"force\",\"cent\",\"she\",\"leader\",\"yesterday\",\"workers\",\"take\",\"him\",\"hamas\",\"under\",\"state\",\"those\",\"years\",\"meeting\",\"bank\",\"suicide\",\"back\",\"action\",\"commission\",\"made\",\"down\",\"morning\",\"re\",\"pakistan\",\"international\",\"city\",\"attack\",\"centre\",\"group\",\"afghan\",\"members\",\"while\",\"military\",\"well\",\"number\",\"through\",\"qantas\",\"five\",\"local\",\"called\",\"area\",\"union\",\"gaza\",\"week\",\"national\",\"since\",\"wales\",\"including\",\"hours\",\"september\",\"another\",\"east\",\"night\",\"report\",\"off\",\"north\",\"should\",\"get\",\"second\",\"go\",\"earlier\",\"war\",\"staff\",\"six\",\"these\",\"between\",\"islamic\",\"months\",\"further\",\"end\",\"defence\",\"do\",\"sharon\",\"near\",\"team\",\"foreign\",\"power\",\"areas\",\"work\",\"going\",\"authority\",\"because\",\"way\",\"eight\",\"india\",\"only\",\"know\",\"month\",\"during\",\"died\",\"many\",\"match\",\"make\",\"air\",\"metres\",\"left\",\"claims\",\"spokesman\",\"ve\",\"former\",\"melbourne\",\"northern\",\"good\",\"authorities\",\"most\",\"osama\",\"support\",\"prime\",\"peace\",\"like\",\"set\",\"ago\",\"expected\",\"saying\",\"given\",\"am\",\"come\",\"looking\",\"militants\",\"bora\",\"tora\",\"put\",\"place\",\"several\",\"fighters\",\"children\",\"arrested\",\"injured\",\"found\",\"river\",\"royal\",\"groups\",\"africa\",\"unions\",\"christmas\",\"troops\",\"meanwhile\",\"indian\",\"child\",\"hospital\",\"terrorist\",\"interim\",\"part\",\"reports\",\"talks\",\"official\",\"whether\",\"then\",\"yasser\",\"statement\",\"leaders\",\"economy\",\"mountains\",\"how\",\"industrial\",\"third\",\"terrorism\",\"senior\",\"start\",\"don\",\"early\",\"radio\",\"john\",\"hit\",\"trying\",\"weather\",\"public\",\"both\",\"believe\",\"family\",\"pay\",\"million\",\"army\",\"court\",\"dr\",\"long\",\"best\",\"control\",\"help\",\"however\",\"lead\",\"adelaide\",\"asked\",\"following\",\"chief\",\"pressure\",\"agreement\",\"does\",\"service\",\"firefighters\",\"close\",\"few\",\"services\",\"labor\",\"play\",\"better\",\"community\",\"taken\",\"want\",\"arrest\",\"queensland\",\"house\",\"need\",\"overnight\",\"australians\",\"high\",\"confirmed\",\"process\",\"information\",\"came\",\"believed\",\"williams\",\"must\",\"opposition\",\"detainees\",\"won\",\"secretary\",\"did\",\"peter\",\"party\",\"held\",\"damage\",\"governor\",\"maintenance\",\"released\",\"win\",\"pentagon\",\"possible\",\"her\",\"brought\",\"hicks\",\"much\",\"shot\",\"took\",\"accused\",\"nations\",\"british\",\"weekend\",\"lot\",\"violence\",\"building\",\"despite\",\"council\",\"return\",\"got\",\"airline\",\"asylum\",\"york\",\"dead\",\"kandahar\",\"conditions\",\"across\",\"hill\",\"winds\",\"safety\",\"even\",\"such\",\"change\",\"cut\",\"eastern\",\"without\",\"director\",\"armed\",\"working\",\"aircraft\",\"call\",\"here\",\"see\",\"palestinians\",\"december\",\"economic\",\"news\",\"american\",\"too\",\"home\",\"men\",\"seekers\",\"strip\",\"lee\",\"waugh\",\"role\",\"country\",\"region\",\"trade\",\"emergency\",\"crew\",\"strong\",\"race\",\"captured\",\"david\",\"southern\",\"fighting\",\"continuing\",\"fires\",\"monday\",\"far\",\"anti\",\"board\",\"cricket\",\"training\",\"key\",\"plans\",\"bush\",\"bureau\",\"act\",\"industry\",\"george\",\"head\",\"past\",\"water\",\"charged\",\"used\",\"administration\",\"received\",\"offer\",\"alliance\",\"rate\",\"zinni\",\"health\",\"least\",\"leading\",\"person\",\"captain\",\"your\",\"town\",\"boat\",\"large\",\"decision\",\"stop\",\"known\",\"airport\",\"operations\",\"may\",\"line\",\"within\",\"risk\",\"use\",\"downer\",\"israelis\",\"soldiers\",\"major\",\"britain\",\"final\",\"parliament\",\"department\",\"zealand\",\"hundreds\",\"issue\",\"strikes\",\"hih\",\"station\",\"legal\",\"shane\",\"plane\",\"might\",\"series\",\"interest\",\"un\",\"laws\",\"policy\",\"right\",\"ahead\",\"hollingworth\",\"tomorrow\",\"network\",\"pm\",\"able\",\"due\",\"kabul\",\"latest\",\"death\",\"homes\",\"weapons\",\"behind\",\"great\",\"coast\",\"western\",\"position\",\"give\",\"later\",\"late\",\"half\",\"officers\",\"my\",\"taking\",\"every\",\"remain\",\"campaign\",\"seen\",\"thought\",\"bill\",\"timor\",\"special\",\"side\",\"failed\",\"same\",\"flight\",\"along\",\"jobs\",\"storm\",\"me\",\"forced\",\"life\",\"others\",\"continue\",\"hard\",\"event\",\"abuse\",\"cup\",\"victory\",\"jihad\",\"guilty\",\"point\",\"towards\",\"really\",\"concerned\",\"heard\",\"already\",\"territory\",\"washington\",\"deaths\",\"mcgrath\",\"helicopters\",\"envoy\",\"canyoning\",\"capital\",\"bus\",\"bichel\",\"november\",\"likely\",\"details\",\"case\",\"member\",\"launched\",\"innings\",\"according\",\"enough\",\"bombings\",\"weeks\",\"countries\",\"again\",\"detention\",\"move\",\"woomera\",\"seven\",\"cabinet\",\"bowler\",\"buildings\",\"hour\",\"mark\",\"matter\",\"middle\",\"bombing\",\"th\",\"sunday\",\"situation\",\"rates\",\"space\",\"important\",\"warne\",\"dispute\",\"caught\",\"jail\",\"claimed\",\"wants\",\"perth\",\"adventure\",\"targets\",\"run\",\"swiss\",\"asio\",\"added\",\"commonwealth\",\"raids\",\"office\",\"evidence\",\"deal\",\"guides\",\"disease\",\"show\",\"boy\",\"women\",\"own\",\"freeze\",\"opened\",\"human\",\"forward\",\"carried\",\"african\",\"mission\",\"movement\",\"based\",\"sure\",\"reported\",\"immediately\",\"political\",\"warplanes\",\"young\",\"rule\",\"ms\",\"blue\",\"top\",\"justice\",\"money\",\"aedt\",\"cancer\",\"crash\",\"march\",\"banks\",\"border\",\"using\",\"although\",\"access\",\"financial\",\"allegations\",\"certainly\",\"planning\",\"probably\",\"break\",\"find\",\"wicket\",\"ground\",\"beat\",\"prepared\",\"burning\",\"become\",\"always\",\"job\",\"proposed\",\"each\",\"full\",\"reached\",\"collapse\",\"growth\",\"order\",\"island\",\"sector\",\"flying\",\"carrying\",\"result\",\"face\",\"investigation\",\"times\",\"relations\",\"militant\",\"road\",\"sex\",\"needs\",\"organisation\",\"until\",\"serious\",\"program\",\"fight\",\"calls\",\"stage\",\"getting\",\"lives\",\"responsibility\",\"reserve\",\"thursday\",\"comes\",\"management\",\"sent\",\"drop\",\"surrender\",\"allow\",\"soon\",\"afp\",\"tried\",\"post\",\"killing\",\"radical\",\"hewitt\",\"himself\",\"senator\",\"executive\",\"outside\",\"believes\",\"inquiry\",\"short\",\"caves\",\"different\",\"flights\",\"immigration\",\"tourists\",\"future\",\"inside\",\"bid\",\"energy\",\"clear\",\"trees\",\"thousands\",\"argentina\",\"militia\",\"suspected\",\"making\",\"bowling\",\"ariel\",\"went\",\"alleged\",\"rejected\",\"howard\",\"quickly\",\"wave\",\"harrison\",\"travel\",\"opening\",\"ansett\",\"kilometres\",\"declared\",\"running\",\"measures\",\"biggest\",\"list\",\"figures\",\"rise\",\"residents\",\"sea\",\"form\",\"annual\",\"anything\",\"attempt\",\"open\",\"parties\",\"available\",\"announced\",\"shortly\",\"among\",\"currently\",\"bombers\",\"circumstances\",\"accident\",\"donald\",\"ministers\",\"look\",\"brisbane\",\"decided\",\"ruddock\",\"changes\",\"yet\",\"issues\",\"address\",\"destroyed\",\"actually\",\"rights\",\"increase\",\"terms\",\"school\",\"rural\",\"fighter\",\"quite\",\"happened\",\"wounded\",\"victoria\",\"television\",\"nine\",\"something\",\"try\",\"parts\",\"white\",\"response\",\"done\",\"wickets\",\"witnesses\",\"refused\",\"karzai\",\"sentence\",\"ended\",\"tanks\",\"gunmen\",\"sources\",\"kallis\",\"agency\",\"july\",\"jewish\",\"warned\",\"directors\",\"understand\",\"meet\",\"means\",\"returned\",\"offices\",\"yacht\",\"source\",\"alexander\",\"ll\",\"fact\",\"difficult\",\"though\",\"period\",\"confidence\",\"wage\",\"airlines\",\"virus\",\"advice\",\"caused\",\"musharraf\",\"allan\",\"recession\",\"less\",\"ensure\",\"strike\",\"appeared\",\"islands\",\"crowd\",\"suharto\",\"highway\",\"afternoon\",\"step\",\"commanders\",\"began\",\"gave\",\"worst\",\"glenn\",\"bomb\",\"commissioner\",\"powell\",\"having\",\"beginning\",\"intelligence\",\"rafter\",\"prevent\",\"gives\",\"expressed\",\"huge\",\"ever\",\"big\",\"business\",\"ses\",\"media\",\"friday\",\"pacific\",\"robert\",\"expect\",\"blake\",\"runs\",\"involved\",\"followed\",\"deputy\",\"hobart\",\"whose\",\"market\",\"tour\",\"rather\",\"attorney\",\"elected\",\"beyond\",\"arrived\",\"away\",\"facility\",\"commander\",\"total\",\"law\",\"field\",\"supporters\",\"struck\",\"car\",\"cost\",\"sir\",\"negotiations\",\"nauru\",\"tennis\",\"massive\",\"entered\",\"threat\",\"plan\",\"explosives\",\"debt\",\"entitlements\",\"criticism\",\"decide\",\"quarter\",\"saturday\",\"assistance\",\"labour\",\"geoff\",\"together\",\"finished\",\"chance\",\"endeavour\",\"chairman\",\"main\",\"heavy\",\"base\",\"places\",\"tragedy\",\"sort\",\"vote\",\"giving\",\"jenin\",\"front\",\"powers\",\"anglican\",\"son\",\"zimbabwe\",\"themselves\",\"conflict\",\"yes\",\"muslim\",\"lockett\",\"daryl\",\"helicopter\",\"current\",\"fast\",\"complex\",\"terror\",\"smoke\",\"france\",\"anthony\",\"calling\",\"hearings\",\"population\",\"tasmania\",\"game\",\"jacques\",\"placed\",\"denied\",\"reid\",\"pakistani\",\"indonesia\",\"bring\",\"ballot\",\"played\",\"protect\",\"level\",\"conference\",\"organisations\",\"martin\",\"employees\",\"feel\",\"costs\",\"changed\",\"study\",\"survey\",\"brett\",\"potential\",\"macgill\",\"cannot\",\"crean\",\"lost\",\"storms\",\"round\",\"russian\",\"trip\",\"crisis\",\"nearly\",\"americans\",\"speaking\",\"ambush\",\"never\",\"significant\",\"boxing\",\"longer\",\"low\",\"tribal\",\"deadly\",\"record\",\"problem\",\"professor\",\"hayden\",\"fleeing\",\"absolutely\",\"continues\",\"fired\",\"rumsfeld\",\"claim\",\"ramallah\",\"hold\",\"anyone\",\"election\",\"construction\",\"technology\",\"doubles\",\"cities\",\"companies\",\"research\",\"whole\",\"efforts\",\"needed\",\"small\",\"moved\",\"confident\",\"land\",\"proposals\",\"sign\",\"little\",\"affected\",\"tape\",\"ruled\",\"environment\",\"everything\",\"severe\",\"led\",\"closed\",\"forecast\",\"pilot\",\"overall\",\"gillespie\",\"signed\",\"coming\",\"receive\",\"rival\",\"provide\",\"representation\",\"simon\",\"accept\",\"sides\",\"mountain\",\"receiving\",\"mean\",\"secret\",\"injuries\",\"dozens\",\"steve\",\"payment\",\"hope\",\"battle\",\"shuttle\",\"gun\",\"central\",\"bomber\",\"starting\",\"activity\",\"damaged\",\"bonn\",\"disaster\",\"problems\",\"verdict\",\"flames\",\"condition\",\"french\",\"tony\",\"resolution\",\"rest\",\"coalition\",\"richard\",\"treatment\",\"recorded\",\"grant\",\"stopped\",\"hotel\",\"insurance\",\"carry\",\"rain\",\"almost\",\"ice\",\"continued\",\"greater\",\"global\",\"share\",\"direct\",\"nation\",\"paid\",\"vaughan\",\"statistics\",\"fellow\",\"winner\",\"civil\",\"review\",\"private\",\"gas\",\"twice\",\"interlaken\",\"concern\",\"cars\",\"started\",\"red\",\"fell\",\"disappointed\",\"debate\",\"determined\",\"michael\",\"seles\",\"begin\",\"krishna\",\"didn\",\"refugees\",\"remaining\",\"tough\",\"ceremony\",\"property\",\"january\",\"qc\",\"stand\",\"operation\",\"territories\",\"above\",\"lower\",\"respond\",\"reduce\",\"resolve\",\"victims\",\"strategic\",\"asic\",\"alongside\",\"include\",\"revealed\",\"august\",\"season\",\"charge\",\"completed\",\"seeking\",\"bit\",\"park\",\"lines\",\"heritage\",\"traditional\",\"enter\",\"tuesday\",\"guard\",\"ray\",\"avoid\",\"markets\",\"visit\",\"europe\",\"winning\",\"playing\",\"self\",\"yachts\",\"met\",\"charges\",\"vice\",\"cease\",\"roads\",\"factory\",\"america\",\"itself\",\"created\",\"wake\",\"levels\",\"fall\",\"related\",\"outlook\",\"ministry\",\"lung\",\"hearing\",\"non\",\"volunteers\",\"civilians\",\"voted\",\"liquidation\",\"search\",\"provisional\",\"rescue\",\"victorian\",\"table\",\"successful\",\"track\",\"conducted\",\"heading\",\"spread\",\"accompanied\",\"delhi\",\"operating\",\"wanted\",\"expects\",\"leg\",\"ponting\",\"pulled\",\"knew\",\"heart\",\"coach\",\"confirm\",\"ball\",\"virgin\",\"press\",\"suffered\",\"illawarra\",\"approach\",\"manslaughter\",\"costello\",\"showed\",\"threatened\",\"warning\",\"helped\",\"resume\",\"japan\",\"individuals\",\"mayor\",\"giuliani\",\"friedli\",\"wind\",\"served\",\"andy\",\"range\",\"responsible\",\"unemployment\",\"mckenzie\",\"initial\",\"keep\",\"families\",\"lord\",\"incident\",\"october\",\"finance\",\"treated\",\"ian\",\"why\",\"solution\",\"apparently\",\"body\",\"club\",\"crackdown\",\"reach\",\"officer\",\"institute\",\"shaun\",\"pollock\",\"hopes\",\"structure\",\"data\",\"nice\",\"food\",\"seriously\",\"suspended\",\"attacked\",\"jason\",\"elections\",\"edge\",\"affairs\",\"nothing\",\"questions\",\"mid\",\"built\",\"negotiating\",\"peacekeepers\",\"saw\",\"issued\",\"spokeswoman\",\"assisting\",\"remains\",\"finding\",\"recovery\",\"woman\",\"gang\",\"kashmir\",\"farmers\",\"oil\",\"networks\",\"sheikh\",\"adequate\",\"doubt\",\"products\",\"secure\",\"beatle\",\"single\",\"options\",\"clearly\",\"blaze\",\"present\",\"ford\",\"cfmeu\",\"tailenders\",\"fatah\",\"scene\",\"co\",\"lording\",\"factions\",\"st\",\"raid\",\"career\",\"streets\",\"butterfly\",\"amin\",\"outcome\",\"traveland\",\"peres\",\"inappropriate\",\"austar\",\"scored\",\"champion\",\"races\",\"cave\",\"scheduled\",\"clean\",\"nearby\",\"philip\",\"shows\",\"invasion\",\"aboard\",\"coup\",\"senate\",\"doug\",\"solomon\",\"eve\",\"sarah\",\"holiday\",\"mohammad\",\"university\",\"murder\",\"whiting\",\"gorge\",\"tensions\",\"manufacturing\",\"wayne\",\"yallourn\",\"diplomatic\",\"drug\",\"promised\",\"cause\",\"natural\",\"afroz\",\"ethnic\",\"singles\",\"crews\",\"meetings\",\"toll\",\"apra\",\"administrators\",\"corporation\",\"leadership\",\"canberra\",\"exchange\",\"nuclear\",\"germany\",\"numbers\",\"attacking\",\"largest\",\"petrol\",\"customers\",\"prior\",\"internet\",\"awards\",\"extremists\",\"attempting\",\"personnel\",\"hand\",\"criminal\",\"mandate\",\"things\",\"deployed\",\"follows\",\"unrest\",\"dropped\",\"manager\",\"injury\",\"settlement\",\"roof\",\"honours\",\"appears\",\"metre\",\"boats\",\"often\",\"speech\",\"squad\",\"fair\",\"budget\",\"ready\",\"ask\",\"band\",\"proteas\",\"king\",\"grand\",\"recent\",\"happens\",\"classic\",\"suburbs\",\"resign\",\"swept\",\"collapsed\",\"true\",\"agreed\",\"batsmen\",\"presence\",\"felt\",\"billion\",\"resistance\",\"giant\",\"increased\",\"described\",\"unit\",\"create\",\"concerns\",\"protection\",\"targeted\",\"boys\",\"saudi\",\"leave\",\"unity\",\"planes\",\"halt\",\"read\",\"marine\",\"neil\",\"walk\",\"crossed\",\"fleet\",\"knowledge\",\"minute\",\"greatest\",\"extensive\",\"backed\",\"ocean\",\"assa\",\"ricky\",\"abloy\",\"light\",\"premier\",\"names\",\"explanation\",\"wall\",\"possibility\",\"real\",\"live\",\"switzerland\",\"japanese\",\"shopping\",\"reveal\",\"fierce\",\"tree\",\"elders\",\"blame\",\"tension\",\"employment\",\"detain\",\"positive\",\"income\",\"haifa\",\"jerusalem\",\"pre\",\"programs\",\"jets\",\"transport\",\"regional\",\"save\",\"hunt\",\"advance\",\"gone\",\"battling\",\"suspect\",\"representing\",\"investigating\",\"reduced\",\"acting\",\"projects\",\"investment\",\"spencer\",\"findings\",\"students\",\"nablus\",\"actions\",\"trial\",\"declaration\",\"handed\",\"custody\",\"growing\",\"system\",\"prisoners\",\"domestic\",\"education\",\"society\",\"summit\",\"assault\",\"langer\",\"matthew\",\"requested\",\"westpac\",\"doctor\",\"wing\",\"republic\",\"searching\",\"eliminated\",\"approval\",\"anz\",\"term\",\"bargaining\",\"various\",\"balls\",\"klusener\",\"boucher\",\"humanity\",\"suggested\",\"adding\",\"history\",\"normal\",\"cuts\",\"signs\",\"gunships\",\"blasted\",\"turn\",\"hare\",\"smaller\",\"guess\",\"benares\",\"ashes\",\"path\",\"terrorists\",\"blazes\",\"hijacked\",\"adam\",\"follow\",\"comment\",\"aware\",\"connection\",\"underway\",\"kieren\",\"rabbani\",\"completely\",\"tonight\",\"understanding\",\"infected\",\"masood\",\"treasurer\",\"crime\",\"gambier\",\"henderson\",\"returning\",\"results\",\"kingham\",\"question\",\"kissinger\",\"gerber\",\"stuart\",\"launceston\",\"sergeant\",\"flood\",\"committee\",\"hundred\",\"goshen\",\"handling\",\"church\",\"thing\",\"escaped\",\"injuring\",\"slightly\",\"francs\",\"hunter\",\"ahmed\",\"actor\",\"wednesday\",\"aged\",\"centrelink\",\"threatening\",\"sultan\",\"improve\",\"passed\",\"stability\",\"project\",\"dollars\",\"decades\",\"course\",\"ill\",\"faces\",\"chosen\",\"bob\",\"hamid\",\"passengers\",\"davis\",\"neville\",\"ways\",\"pace\",\"whatever\",\"headed\",\"launch\",\"replied\",\"hopefully\",\"determine\",\"archbishop\",\"unable\",\"throughout\",\"average\",\"unidentified\",\"survived\",\"approached\",\"convicted\",\"cooperation\",\"redundancy\",\"waiting\",\"request\",\"paying\",\"observers\",\"aboriginal\",\"procedures\",\"reject\",\"document\",\"improved\",\"holding\",\"mass\",\"unfortunately\",\"welcomed\",\"whereabouts\",\"appropriate\",\"lack\",\"delay\",\"trapped\",\"facilities\",\"decisions\",\"prepare\",\"medical\",\"necessary\",\"spinner\",\"examination\",\"losing\",\"channel\",\"occupation\",\"title\",\"consumers\",\"firm\",\"creditors\",\"fine\",\"vehicle\",\"staying\",\"relationship\",\"delivered\",\"begun\",\"hot\",\"coroner\",\"temperatures\",\"containment\",\"cross\",\"contested\",\"strongly\",\"experts\",\"celebrations\",\"focus\",\"named\",\"sometimes\",\"marines\",\"player\",\"jalalabad\",\"games\",\"breaking\",\"contained\",\"counts\",\"stay\",\"allowed\",\"temporary\",\"assembly\",\"draft\",\"understood\",\"toowoomba\",\"voice\",\"twenty\",\"strachan\",\"harris\",\"discussions\",\"hopman\",\"crashed\",\"farm\",\"violent\",\"communities\",\"kilometre\",\"doctors\",\"hoping\",\"ban\",\"colin\",\"effective\",\"success\",\"offered\",\"positions\",\"abu\",\"worked\",\"documents\",\"tell\",\"phillips\",\"retired\",\"choosing\",\"responding\",\"allegedly\",\"indonesian\",\"detail\",\"free\",\"bringing\",\"hiv\",\"proposal\",\"doesn\",\"mining\",\"embassy\",\"heights\",\"mt\",\"trading\",\"room\",\"fund\",\"impact\",\"male\",\"mohammed\",\"interests\",\"effort\",\"antarctic\",\"previous\",\"target\",\"words\",\"publicly\",\"walked\",\"credit\",\"provided\",\"investigate\",\"telephone\",\"eventually\",\"leaving\",\"banking\",\"interview\",\"headquarters\",\"clashes\",\"doing\",\"fear\",\"predicted\",\"picked\",\"happy\",\"visa\",\"tie\",\"putting\",\"escalating\",\"hoped\",\"landed\",\"sharing\",\"mind\",\"skipper\",\"gary\",\"soft\",\"became\",\"sending\",\"shoes\",\"paris\",\"required\",\"seemed\",\"cameron\",\"ability\",\"locked\",\"travelled\",\"finally\",\"separate\",\"owen\"],\"x\":[67.65857696533203,69.41801452636719,69.28298950195312,69.18158721923828,69.56907653808594,65.34490203857422,69.00169372558594,69.21319580078125,69.90988159179688,66.49942779541016,67.608154296875,69.91500091552734,69.12689208984375,67.43939208984375,68.92963409423828,65.96743774414062,66.21795654296875,69.21856689453125,69.63339233398438,68.7721176147461,69.84840393066406,67.57792663574219,69.47521209716797,69.59858703613281,68.4791259765625,65.23654174804688,68.73503875732422,68.94235229492188,66.15231323242188,68.57764434814453,68.34796905517578,68.0045394897461,69.94342041015625,69.41165161132812,67.8636245727539,65.39534759521484,68.7769546508789,68.27665710449219,65.99136352539062,67.38512420654297,68.36661529541016,67.00911712646484,65.73505401611328,68.60565948486328,65.2210693359375,69.87313079833984,67.6294937133789,68.85900115966797,66.65251922607422,68.06036376953125,67.94220733642578,64.6227035522461,66.9203109741211,67.97750854492188,66.74674224853516,65.91548919677734,67.44751739501953,67.8775405883789,66.85778045654297,68.64295196533203,66.8400650024414,66.38887786865234,66.56995391845703,65.67915344238281,67.0496597290039,68.15888977050781,63.817928314208984,67.11618041992188,63.671875,65.46185302734375,63.137062072753906,61.8315544128418,64.96726989746094,63.310699462890625,65.69857788085938,63.585723876953125,64.26396179199219,62.060760498046875,63.861148834228516,66.85871887207031,62.50386428833008,62.924800872802734,61.407814025878906,66.42230987548828,61.896888732910156,64.01353454589844,62.4271125793457,62.202369689941406,65.97733306884766,63.297115325927734,65.20219421386719,59.10179901123047,64.2501220703125,61.01020812988281,60.9886474609375,62.84935760498047,61.330875396728516,61.204139709472656,62.73065185546875,60.29288864135742,60.9763298034668,62.48002243041992,63.64748764038086,45.631553649902344,63.404850006103516,60.91730880737305,51.40855407714844,59.57094192504883,55.15463638305664,60.91593933105469,58.35748291015625,62.12459945678711,58.6619987487793,53.104949951171875,52.412254333496094,54.531150817871094,55.93544006347656,60.93291473388672,56.39421081542969,57.5955696105957,56.373348236083984,54.252899169921875,57.16511154174805,54.97438430786133,63.08226013183594,56.384952545166016,44.81596374511719,53.97922134399414,53.75196838378906,47.20368576049805,49.71965789794922,58.366905212402344,61.80777359008789,43.878440856933594,52.21343231201172,58.63371276855469,52.81483840942383,51.138519287109375,53.580787658691406,43.307769775390625,51.41278839111328,51.20579528808594,52.144508361816406,45.754356384277344,54.7103157043457,53.355899810791016,49.31318283081055,59.39595031738281,44.457366943359375,49.238616943359375,57.25065994262695,53.079002380371094,55.6600227355957,47.77387619018555,51.34758758544922,57.00776672363281,53.79071044921875,52.178916931152344,55.69327163696289,54.94974136352539,42.992958068847656,42.750553131103516,53.43333053588867,53.89359664916992,56.42259216308594,60.44979476928711,41.59615707397461,46.28202819824219,56.797908782958984,48.57189178466797,43.73933029174805,56.768341064453125,54.96548843383789,38.62677001953125,57.936302185058594,48.722415924072266,37.45716857910156,48.827796936035156,51.724365234375,47.2421875,43.09780502319336,50.768165588378906,47.96576690673828,47.28287124633789,48.41628646850586,53.940921783447266,42.47938919067383,47.68510818481445,40.28889465332031,46.277923583984375,48.13022994995117,42.74999237060547,57.16737365722656,57.445743560791016,45.151039123535156,43.47677993774414,36.44706344604492,42.31070327758789,38.68376922607422,40.09598922729492,52.82839584350586,39.64797592163086,49.19691848754883,42.728145599365234,48.23238754272461,38.146759033203125,35.91868209838867,38.544837951660156,44.96271514892578,34.20430374145508,42.49091720581055,41.07876968383789,38.96921920776367,39.2418212890625,43.355438232421875,48.24641418457031,46.19184494018555,37.52389144897461,35.743370056152344,43.08607482910156,45.68271255493164,49.48344039916992,40.01811981201172,40.25178527832031,39.88215255737305,40.03837966918945,43.14398193359375,41.932010650634766,37.92646026611328,36.782264709472656,35.65992736816406,42.866573333740234,43.51472854614258,38.500606536865234,37.3087043762207,37.68547439575195,38.26526641845703,39.62940216064453,39.904903411865234,34.24614334106445,34.27892303466797,39.07923126220703,40.7145881652832,35.40064239501953,36.569271087646484,38.03179168701172,42.678985595703125,41.46925354003906,35.32697677612305,40.10509490966797,49.41203308105469,37.31058883666992,38.415321350097656,30.433988571166992,25.89706802368164,36.979007720947266,31.01569175720215,39.23590850830078,36.90748977661133,33.1434326171875,36.81700134277344,39.128353118896484,32.82137680053711,40.047996520996094,39.39345169067383,39.83987808227539,34.2376708984375,25.451416015625,20.115211486816406,34.89943313598633,36.027549743652344,41.4539794921875,37.75992202758789,39.58719253540039,39.26803207397461,37.24285125732422,39.613189697265625,33.372074127197266,18.331342697143555,36.19339370727539,37.330657958984375,38.843055725097656,40.648536682128906,34.48033142089844,36.1769905090332,33.27797317504883,35.49149703979492,24.301767349243164,36.697906494140625,37.77021026611328,38.61442184448242,31.6514835357666,38.11375427246094,37.12770462036133,43.75642776489258,28.810182571411133,36.27546691894531,37.43312454223633,24.284242630004883,22.70795440673828,36.478424072265625,38.219974517822266,40.730613708496094,18.195682525634766,32.264251708984375,36.447322845458984,37.04276657104492,30.666305541992188,37.82242202758789,35.07819747924805,37.511024475097656,42.31081771850586,33.41542053222656,35.296173095703125,30.768077850341797,34.61726760864258,34.95724105834961,37.70716857910156,31.913009643554688,35.947540283203125,33.22536849975586,32.81599426269531,33.937129974365234,29.64031410217285,24.683225631713867,28.277145385742188,35.804447174072266,40.37668228149414,30.15863800048828,31.21994972229004,36.87995529174805,29.223369598388672,37.215232849121094,34.49623489379883,32.20793151855469,32.868431091308594,31.70220947265625,16.9000301361084,27.808513641357422,32.66632080078125,34.26603698730469,36.22337341308594,36.40064239501953,39.52726745605469,19.13834571838379,41.73567199707031,26.991680145263672,32.652400970458984,24.603607177734375,22.27198600769043,36.99824142456055,29.36699104309082,35.906410217285156,15.760576248168945,28.343372344970703,35.79465866088867,23.330730438232422,27.7097110748291,31.89649200439453,15.545424461364746,30.670063018798828,13.68550968170166,24.547073364257812,29.97968101501465,17.823196411132812,23.36410903930664,24.129920959472656,34.97950744628906,29.6569766998291,29.00554847717285,21.627086639404297,29.94904327392578,34.11544418334961,35.383209228515625,12.595866203308105,32.288230895996094,27.363452911376953,32.58688735961914,34.33414077758789,26.352352142333984,33.622825622558594,29.507566452026367,30.52251434326172,24.861034393310547,33.267845153808594,17.48291778564453,13.565025329589844,35.540653228759766,35.99111557006836,28.936342239379883,17.72136878967285,35.06293869018555,16.425504684448242,16.91645050048828,20.96615219116211,19.814971923828125,24.795917510986328,31.610029220581055,33.97526931762695,11.304296493530273,35.291099548339844,21.799442291259766,18.31340789794922,32.2122688293457,20.712160110473633,32.14900588989258,36.206703186035156,26.142301559448242,22.902795791625977,23.436717987060547,23.238739013671875,26.540895462036133,33.68393325805664,29.488872528076172,33.67339324951172,16.859113693237305,25.380041122436523,19.533151626586914,12.324974060058594,10.458066940307617,26.553760528564453,30.12016487121582,5.754475116729736,25.36762046813965,20.851442337036133,10.812211036682129,32.24503707885742,22.865726470947266,22.68768310546875,23.949363708496094,33.54878234863281,21.74312973022461,29.097501754760742,20.665592193603516,11.754862785339355,20.96481704711914,10.595219612121582,24.663280487060547,26.621814727783203,31.142595291137695,29.838178634643555,33.70991516113281,26.959434509277344,32.92836380004883,32.55264663696289,34.58679962158203,0.16165593266487122,25.303897857666016,11.676466941833496,36.45074462890625,40.72079086303711,16.147125244140625,23.641048431396484,20.716039657592773,23.45568084716797,20.218395233154297,20.97093963623047,13.879051208496094,12.401878356933594,27.674964904785156,31.705251693725586,22.152650833129883,14.403491020202637,19.146814346313477,12.404572486877441,20.55844497680664,13.290095329284668,34.8574104309082,20.528615951538086,17.382171630859375,19.725322723388672,25.271413803100586,12.250612258911133,10.915501594543457,15.620882034301758,29.344730377197266,31.15570831298828,35.4114990234375,24.956953048706055,32.675838470458984,22.978036880493164,9.02694320678711,-0.49645230174064636,28.660085678100586,19.82094955444336,22.537466049194336,21.782886505126953,23.063976287841797,21.021696090698242,21.814620971679688,26.109981536865234,23.24257469177246,14.089136123657227,11.027854919433594,24.79885482788086,23.359254837036133,14.821953773498535,18.074609756469727,12.60660457611084,12.77002239227295,33.431236267089844,12.960766792297363,12.515045166015625,12.311671257019043,22.59103775024414,27.17308807373047,22.763212203979492,15.464120864868164,21.71524429321289,21.0694637298584,6.468864917755127,18.804288864135742,21.94942855834961,12.051261901855469,8.685100555419922,-1.9503774642944336,0.28108373284339905,18.742881774902344,22.7410888671875,19.314163208007812,24.194232940673828,24.35923194885254,24.626134872436523,24.41219139099121,33.29401397705078,16.465126037597656,13.550790786743164,-2.5034830570220947,10.199614524841309,24.61451530456543,23.871057510375977,14.481918334960938,15.086348533630371,23.62676239013672,28.00084114074707,33.866981506347656,13.353367805480957,13.22236442565918,13.426778793334961,11.628037452697754,23.550268173217773,17.24923324584961,18.476478576660156,20.27250099182129,11.282509803771973,2.948634624481201,22.359949111938477,23.824111938476562,21.119306564331055,32.201297760009766,15.127443313598633,27.561153411865234,5.765256881713867,16.233394622802734,18.42274284362793,24.846853256225586,15.653467178344727,-2.2950143814086914,-0.12109670042991638,15.971956253051758,23.214799880981445,17.14533233642578,23.012954711914062,14.11180305480957,-0.07328221201896667,21.63100814819336,24.11087417602539,17.09432029724121,1.5888677835464478,23.62053871154785,3.0634539127349854,22.202260971069336,11.983317375183105,35.483516693115234,19.751325607299805,20.472585678100586,29.14080238342285,1.461008071899414,20.57353973388672,22.97945213317871,25.829652786254883,-0.6862329244613647,16.14777183532715,30.070457458496094,23.40882682800293,14.987621307373047,19.54904556274414,24.02044677734375,24.18573760986328,16.603378295898438,14.731316566467285,20.573894500732422,15.215981483459473,4.998029708862305,20.568187713623047,16.06791877746582,23.19717788696289,19.221595764160156,1.6002341508865356,3.6969451904296875,17.208194732666016,-27.442171096801758,4.608526706695557,2.7334177494049072,20.705791473388672,21.438879013061523,16.99664878845215,-0.8061845302581787,21.9985294342041,7.523796081542969,25.140060424804688,16.303586959838867,-2.605865001678467,2.6830878257751465,7.5016961097717285,24.385347366333008,21.752187728881836,21.665679931640625,10.350476264953613,-12.373699188232422,4.47782564163208,17.949365615844727,24.171825408935547,21.68124008178711,2.6927194595336914,16.38016128540039,18.01119613647461,16.664939880371094,15.114479064941406,10.625951766967773,12.484184265136719,24.491430282592773,13.106955528259277,-2.6909470558166504,19.88892364501953,-0.07167015224695206,12.160484313964844,13.757295608520508,-1.8877859115600586,18.316450119018555,15.348312377929688,15.519917488098145,16.65144920349121,-0.7519659996032715,10.354747772216797,9.068048477172852,-1.622620701789856,13.553485870361328,9.695343971252441,0.6446384191513062,2.4340662956237793,4.785726070404053,12.936891555786133,20.513700485229492,14.605892181396484,16.266738891601562,19.04477882385254,23.307649612426758,24.416101455688477,22.971664428710938,2.620291233062744,-10.01830768585205,22.01102066040039,-1.1635637283325195,18.04245376586914,11.99790096282959,1.181535005569458,17.433822631835938,11.272435188293457,19.411245346069336,17.60016441345215,10.782177925109863,2.8749289512634277,4.250439167022705,-2.220949649810791,-1.4976261854171753,13.909626007080078,-0.017795003950595856,-0.5510820150375366,6.742824077606201,10.634481430053711,-16.958786010742188,-1.4352028369903564,-5.501780033111572,2.5298712253570557,-3.4402923583984375,-0.5512891411781311,1.372578740119934,3.036069631576538,3.7166781425476074,7.73613977432251,0.3470982015132904,19.916519165039062,-1.3339474201202393,3.572627544403076,-0.4065278470516205,11.53523063659668,14.375981330871582,0.3562606871128082,-0.9828207492828369,23.192567825317383,-0.9168946743011475,22.77515983581543,17.38545036315918,0.09582705795764923,1.0792617797851562,22.288667678833008,0.8497012257575989,16.506309509277344,9.267069816589355,7.997431755065918,5.086019515991211,-26.275270462036133,11.91435432434082,-0.45650461316108704,19.54757308959961,0.006875417195260525,17.60126495361328,2.894109010696411,1.1970863342285156,-0.02528221532702446,0.09176052361726761,-0.37381237745285034,12.748536109924316,-2.996121883392334,-46.338558197021484,7.685907363891602,17.75615692138672,0.5434800982475281,0.9465302228927612,8.149006843566895,11.054094314575195,14.946979522705078,9.76899528503418,-1.4130569696426392,-0.4105776250362396,0.6427839994430542,0.12581758201122284,-0.7714679837226868,9.930194854736328,-2.0233356952667236,18.833959579467773,-1.3009518384933472,1.583733320236206,4.198923587799072,2.0162479877471924,4.517285346984863,-0.20539286732673645,2.007535219192505,21.935945510864258,-0.7255651950836182,-1.757766604423523,-1.612441062927246,4.498409271240234,14.070169448852539,5.052759170532227,8.110037803649902,0.5626576542854309,0.22518673539161682,18.383596420288086,-1.5397213697433472,0.24015873670578003,0.6350048780441284,-0.4986307621002197,-0.11325690895318985,3.6569156646728516,-22.786882400512695,0.6154741048812866,13.052702903747559,-32.958003997802734,0.6339464783668518,3.695513963699341,0.09068488329648972,-0.4086027443408966,17.125783920288086,-1.3784180879592896,14.603134155273438,-0.07373207807540894,-9.19187068939209,6.0870866775512695,-0.24561281502246857,-1.9888266324996948,3.1321778297424316,-25.113487243652344,-0.42640694975852966,-1.9431085586547852,10.372490882873535,-1.0717339515686035,1.210977554321289,-0.6191701889038086,0.29112058877944946,1.4678399562835693,3.127829074859619,-1.0645065307617188,0.6609445810317993,-19.931467056274414,-12.880985260009766,14.309842109680176,13.084365844726562,20.912025451660156,2.069477081298828,0.7603132724761963,22.464746475219727,13.89038372039795,-0.7174940705299377,-21.49727439880371,-2.667354106903076,2.4749016761779785,1.0487340688705444,-1.4086182117462158,0.4260198175907135,6.9516496658325195,2.880314350128174,-35.45818328857422,-24.720914840698242,-1.4722031354904175,4.073564529418945,-23.035160064697266,16.77804946899414,-1.5710129737854004,8.825155258178711,1.8759565353393555,1.8738787174224854,-24.022605895996094,14.72769832611084,-37.17506408691406,-2.9673960208892822,-1.9735547304153442,0.46193137764930725,0.7875659465789795,0.5775685906410217,1.7542649507522583,2.901862859725952,4.117784023284912,0.42871156334877014,-9.338611602783203,0.37277835607528687,1.1995606422424316,-1.2364777326583862,-5.821591377258301,9.549861907958984,-0.7863514423370361,10.618104934692383,-42.718143463134766,-2.6167895793914795,-23.89661407470703,-1.008531093597412,-1.6258127689361572,0.31403595209121704,-10.7280912399292,-1.717618465423584,-0.324166864156723,-4.069635391235352,-0.8328933119773865,-2.8788254261016846,-2.454281806945801,0.3882896304130554,-6.389466762542725,10.748140335083008,-17.414085388183594,-2.8035295009613037,-0.6700605750083923,-26.15566635131836,0.9938442707061768,-0.5680928826332092,-1.269790530204773,-0.5539544820785522,11.269700050354004,-25.881441116333008,-30.9453125,-3.0637731552124023,-2.2091352939605713,-12.130624771118164,1.0871202945709229,1.8798465728759766,0.6202957034111023,-1.1791183948516846,-0.6343761682510376,-26.98444938659668,1.1301249265670776,-8.816271781921387,-2.0753910541534424,4.284494400024414,0.26784345507621765,0.7214450240135193,6.327466011047363,-0.6166829466819763,10.913239479064941,0.07210475206375122,1.0132137537002563,-29.745288848876953,2.886021375656128,-33.33330154418945,-26.50958251953125,1.389282464981079,1.584256887435913,4.174391746520996,3.1139063835144043,0.9586948752403259,0.22836710512638092,2.2865169048309326,-19.03481101989746,-2.503551959991455,-1.9995874166488647,-36.8511848449707,-21.922697067260742,-0.45060527324676514,1.241760492324829,8.32847785949707,-0.05727584287524223,-2.469259023666382,0.909080982208252,0.16063587367534637,-54.67453384399414,-0.5971680879592896,-1.6837795972824097,-2.0004963874816895,-7.49148416519165,-0.6083599925041199,-0.5008938312530518,-2.307971477508545,0.6261478066444397,-24.874452590942383,-1.4342973232269287,1.064823031425476,-23.1982479095459,-1.2108852863311768,-1.4171918630599976,-9.85470962524414,2.515198230743408,7.07289457321167,-2.8790125846862793,-1.7717198133468628,3.7402682304382324,-22.902446746826172,-0.6877750754356384,0.4058285653591156,3.1319475173950195,-1.3453508615493774,-3.2570242881774902,0.26079854369163513,8.854660034179688,9.348898887634277,2.0274136066436768,-53.79924774169922,1.2129693031311035,-2.042005777359009,-19.75811004638672,-1.453749418258667,-2.2231109142303467,0.39753851294517517,-0.9365370869636536,0.4793567657470703,-0.5085709691047668,19.29265022277832,3.049375534057617,-35.729679107666016,5.019779205322266,-1.9136301279067993,-0.5376431345939636,-4.686492443084717,13.866445541381836,-3.1427483558654785,18.87527084350586,-0.9989634156227112,4.56913948059082,-25.369205474853516,-2.3683838844299316,-0.04435352236032486,1.2373453378677368,-3.0568788051605225,2.430976390838623,-15.592735290527344,-50.8720817565918,-0.616655707359314,-0.5044055581092834,-4.039966583251953,7.515359401702881,2.6763339042663574,-25.64974021911621,-19.96038055419922,0.5849405527114868,-6.198212146759033,-20.92503547668457,-7.094146728515625,-25.736948013305664,18.720382690429688,-24.08511734008789,-52.42533874511719,-14.967716217041016,-6.441539764404297,1.747381567955017,-25.59026527404785,-5.9089884757995605,-27.7392578125,1.8025691509246826,-35.55903244018555,3.560163736343384,-5.053398132324219,-10.773052215576172,-32.43452835083008,-13.709053039550781,-3.6364543437957764,-45.37288284301758,1.207119345664978,-20.55109977722168,-0.4012301564216614,-44.411380767822266,-27.412370681762695,-42.95516586303711,-18.024877548217773,-37.10759353637695,-2.6379785537719727,-0.9132502675056458,-0.3797546625137329,-18.261493682861328,-48.21326446533203,1.7963767051696777,-2.7892062664031982,-3.432079315185547,-20.03360366821289,2.963536262512207,2.135228157043457,4.756870746612549,16.608409881591797,-3.3471503257751465,-41.89371871948242,-17.38079071044922,-12.738906860351562,-8.632136344909668,0.011908767744898796,-0.2536747455596924,-14.456722259521484,-44.47749328613281,2.0268759727478027,2.692277193069458,1.0719261169433594,3.211848735809326,-30.66351318359375,-46.10020065307617,-0.4303567707538605,-31.03257179260254,-8.587963104248047,-8.222103118896484,-1.8154842853546143,-57.982975006103516,-2.120396852493286,1.177034616470337,0.4461278021335602,1.4151194095611572,-21.42406463623047,-35.126338958740234,-2.3014416694641113,-0.09361636638641357,-26.149124145507812,-2.61728572845459,-18.731264114379883,-2.946834087371826,-8.017702102661133,-1.4342470169067383,-12.210565567016602,-29.811647415161133,-7.688523292541504,-9.916804313659668,-17.321487426757812,0.049009595066308975,-14.3638334274292,-1.905029296875,-2.8807644844055176,-19.001256942749023,-22.77046012878418,-3.970376491546631,-0.6090938448905945,-2.438225269317627,1.2652531862258911,5.634211540222168,-42.3107795715332,-4.234745025634766,-15.780834197998047,-33.38306427001953,-32.71500015258789,0.2870785593986511,0.37358129024505615,1.6097303628921509,2.19494891166687,-25.05792808532715,-0.6969858407974243,-31.978561401367188,-0.33516860008239746,3.7717502117156982,1.906476378440857,-11.21977424621582,-32.85771560668945,-27.855998992919922,-10.910672187805176,-25.637052536010742,1.4110674858093262,-63.672569274902344,-6.2179718017578125,-1.4374382495880127,-25.95353126525879,3.28578782081604,-5.837827205657959,1.9495303630828857,-23.89106559753418,-42.01713943481445,-32.37677001953125,2.992386817932129,-51.394710540771484,-0.40026238560676575,-24.870346069335938,-28.15214729309082,-57.834022521972656,1.4672133922576904,-9.180253982543945,-27.75025749206543,-21.70440673828125,2.082453727722168,-28.29978370666504,-1.5919454097747803,-13.978432655334473,-14.216285705566406,-7.120874881744385,-6.276838302612305,-13.103572845458984,-6.902421951293945,-11.690674781799316,-42.151981353759766,-2.241472005844116,-47.312522888183594,-22.70661163330078,1.9443391561508179,-48.696800231933594,-39.95012664794922,-62.09553527832031,-12.698412895202637,-39.97919845581055,-0.8955720663070679,-26.452831268310547,0.07888421416282654,-28.586410522460938,-38.503936767578125,-21.866790771484375,-2.651876449584961,-43.47300720214844,-10.771071434020996,-25.380538940429688,-32.21110534667969,-1.4351036548614502,-9.794690132141113,-32.99147415161133,-8.818865776062012,-6.603468894958496,-11.266839981079102,-48.0175666809082,2.493595838546753,2.265089988708496,0.4923411011695862,-24.2969970703125,-33.51227569580078,0.2594844698905945,-31.15080451965332,-20.592620849609375,3.6584718227386475,1.1175175905227661,0.2919175326824188,-19.572307586669922,8.89061164855957,-27.5551815032959,9.017487525939941,-30.961198806762695,-1.4297730922698975,-51.03990936279297,1.817109227180481,-28.635833740234375,-36.64727783203125,0.05390259996056557,4.052408218383789,-10.277359008789062,-30.039138793945312,-8.081490516662598,1.4811055660247803,-12.576462745666504,0.16429056227207184,2.447619915008545,-29.973230361938477,-13.887894630432129,-11.190906524658203,-18.637277603149414,-4.301798343658447,-26.475215911865234,-18.460453033447266,2.5184266567230225,-17.690614700317383,-55.362911224365234,-10.022068977355957,-5.0934295654296875,0.33693984150886536,-23.081445693969727,-31.159704208374023,-23.684337615966797,1.0457583665847778,-37.470279693603516,-12.631122589111328,-24.539064407348633,-22.007179260253906,-54.22319793701172,2.905991315841675,-32.28556823730469,-41.43199920654297,-2.2889859676361084,-0.4890219569206238,-52.75661087036133,-1.4495803117752075,-0.35434484481811523,-25.723047256469727,-54.26279830932617,-35.64305877685547,-22.681297302246094,2.1607718467712402,-1.5820292234420776,-16.744779586791992,-33.55047607421875,-4.514831066131592,-34.430030822753906,-3.456413984298706,-20.521806716918945,-24.931936264038086,-21.09436798095703,-56.38657760620117,-27.441843032836914,-2.002441644668579,-0.19835828244686127,-0.1856309324502945,1.5945130586624146,-23.419113159179688,2.9884073734283447,-10.1318998336792,-51.02329635620117,-50.21891784667969,-31.633255004882812,-28.233015060424805,-30.185869216918945,0.29664069414138794,4.988540172576904,-16.702533721923828,-22.2579288482666,-47.36125564575195,-50.626522064208984,-24.224763870239258,-65.03779602050781,-4.125303745269775,-42.54180145263672,-61.253841400146484,-52.653717041015625,-13.32909107208252,1.8871525526046753,0.23349221050739288,-64.81019592285156,-0.7207417488098145,2.04205322265625,-1.7183579206466675,-44.591949462890625,-61.83828353881836,-44.18630599975586,-23.00359535217285,-9.679850578308105,-37.4226188659668,-18.01032257080078,-30.764598846435547,-29.810523986816406,-49.87955856323242,-56.87492370605469,-35.63783264160156,-27.5965576171875,-13.776752471923828,-18.979324340820312,-26.81977081298828,-1.9636764526367188,-54.1273307800293,-29.459102630615234,-55.101654052734375,-8.102020263671875,-50.1811637878418,-26.750850677490234,-48.98596954345703,-41.368160247802734,-23.938722610473633,-31.597883224487305,-28.95282554626465,-17.695878982543945,-53.313209533691406,-43.298980712890625,-37.01719665527344,-37.66227340698242,-3.900956869125366,1.2557992935180664,-5.197650909423828,-24.52781867980957,-24.812435150146484,-34.101253509521484,-53.21831130981445,-10.185728073120117,-27.629613876342773,-10.471442222595215,2.5960307121276855,-60.37038040161133,-57.780147552490234,-62.13126754760742,-1.1928861141204834,-34.67100143432617,-57.464962005615234,-0.8034327626228333,-44.69240188598633,-29.006664276123047,-47.90616226196289,-43.26520538330078,-30.788850784301758,-30.76947784423828,-48.36296844482422,-26.646484375,1.2569804191589355,-29.820833206176758,-28.821395874023438,-0.49743494391441345,-19.34469985961914,-14.249706268310547,-20.94467544555664,-7.0912089347839355,-50.224266052246094,-35.99131393432617,-63.2949333190918,-32.675254821777344,-31.074682235717773,-39.83286666870117,-46.9051399230957,-20.576696395874023,-53.63362503051758,-2.8762404918670654,-40.18208694458008,-38.92792510986328,-18.453628540039062,-32.44289779663086,-27.182514190673828,-47.003318786621094,-63.35349655151367,-17.218435287475586,3.3195888996124268,0.40243595838546753,-65.95415496826172,4.01845645904541,-38.84840774536133,-18.2460880279541,-60.95521545410156,-24.85597801208496,-52.87415313720703,-23.310176849365234,-27.372133255004883,-46.42497634887695,-26.009729385375977,-18.139005661010742,-0.1546400487422943,-26.91937828063965,-7.489840984344482,-23.344179153442383,-19.920183181762695,-21.524324417114258,-5.468709468841553,-31.2366943359375,-37.05009841918945,-29.616226196289062,-21.48485565185547,-49.624412536621094,-34.26053237915039,-56.14908981323242,-61.03622817993164,-46.86128616333008,-51.254310607910156,-65.20624542236328,-25.991689682006836,-53.16602325439453,-38.64210891723633,-20.59559440612793,-26.71941375732422,-61.089820861816406,-21.172117233276367,-33.938255310058594,-19.409128189086914,-33.936553955078125,-58.238319396972656,-41.866600036621094,-38.695674896240234,-27.942821502685547,-66.52279663085938,-0.10119383037090302,-50.10405731201172,-32.42317581176758,-4.073795318603516,-51.82756805419922,-64.58504486083984,-39.991329193115234,-55.45092010498047,-41.05253601074219,-54.69552993774414,-9.299616813659668,-57.91032028198242,-24.18267822265625,-23.196552276611328,-26.546600341796875,-20.853879928588867,1.0816631317138672,-16.102127075195312,-16.03643798828125,3.1804521083831787,-22.522180557250977,-30.280603408813477,-30.846410751342773,-16.762746810913086,-62.87126922607422,-1.8755916357040405,-6.97126579284668,3.969926357269287,-4.735994815826416,-37.59368133544922,-16.21868324279785,-33.792606353759766,-37.43174362182617,-16.955562591552734,-51.73018264770508,-59.00550842285156,-47.77365493774414,-29.785259246826172,-52.56675720214844,-27.391305923461914,-30.908634185791016,-0.4008956849575043,-15.962658882141113,-27.86629295349121,-26.370731353759766,-30.366178512573242,0.6082648634910583,-39.358707427978516,-34.71894454956055,-29.64044761657715,-12.289304733276367,-36.5148811340332,-22.263769149780273,-44.32335662841797,-20.200212478637695,-37.82971954345703,-12.718708992004395,-61.92010498046875,-32.11528396606445,-52.189579010009766,-33.413047790527344,-40.64430618286133,-15.775904655456543,-27.55355453491211,-29.033428192138672,-22.994979858398438,-21.934059143066406,-40.704715728759766,-27.3719482421875,-55.99309158325195,-64.27161407470703,-24.087373733520508,-48.17621612548828,-62.945831298828125,-49.6215705871582,-26.415969848632812,-53.572059631347656,-55.50391387939453,-24.861244201660156,-26.58673667907715,-39.51424026489258,-34.162906646728516,-10.808326721191406,-53.63995361328125,-27.231056213378906,1.3499854803085327,-5.151871204376221,-6.418097496032715,-19.67656898498535,-54.327396392822266,-23.562658309936523,-6.3375563621521,-29.11977195739746,-62.7512321472168,-22.114553451538086,-38.5377197265625,-27.567785263061523,-34.049373626708984,-26.614303588867188,-35.01185989379883,-52.95496368408203,-24.6245174407959,-20.72531509399414,-63.04983901977539,-19.168771743774414,-52.80248260498047,-54.67930221557617,-28.726085662841797,-7.397973537445068,-63.097591400146484,-33.93130111694336,-16.929832458496094,-57.23928451538086,-37.15330505371094,-60.846160888671875,-34.24761199951172,-50.74797058105469,-66.06937408447266,-21.358749389648438,-65.41246795654297,-58.65324020385742,-31.75824546813965,-14.555891036987305,-36.1912956237793,-61.549591064453125,-56.88228988647461,-64.04117584228516,-57.271976470947266,-38.44853973388672,-60.53999328613281,-46.776973724365234,-26.187576293945312,-28.57681655883789,-29.143674850463867,-27.093730926513672,-17.831771850585938,-43.31077575683594,-27.83889389038086,-21.99906349182129,-62.28582763671875,-42.32041549682617,-15.890235900878906,-59.58487319946289,-58.037784576416016,-56.09922790527344,2.39100980758667,-55.23739242553711,-9.288338661193848,-49.442623138427734,-29.71524429321289,-31.22238540649414,-29.087291717529297,-62.788238525390625,-66.59609985351562,-6.988204479217529,-60.99859619140625,-20.84716033935547,-45.396541595458984,-1.4046489000320435,-15.596888542175293,-17.822622299194336,-63.28293991088867,-65.61539459228516,-52.12105941772461,-6.093835353851318,-30.913097381591797,-35.69634246826172,-65.55376434326172,-35.132450103759766,-44.85443878173828,-42.50178146362305,-48.19870376586914,-63.63154983520508,-46.206661224365234,-28.76487159729004,-8.52045726776123,-29.296924591064453,-29.48387336730957,-44.69129180908203,-52.74003982543945,-9.372781753540039,-2.0279946327209473,-16.874202728271484,-0.4771023690700531,-19.468944549560547,-28.857954025268555,-11.15005874633789,-33.37112045288086,-19.244972229003906,-27.298614501953125,-43.139060974121094,-52.772647857666016,-24.65019989013672,-23.125959396362305,-52.0272216796875,-32.997230529785156,-51.37317657470703,-48.332481384277344,-53.38039016723633,-47.470863342285156,-55.441307067871094,-39.571895599365234,-64.29695129394531,-41.11383056640625,-1.2680079936981201,-51.74498748779297,-35.736488342285156,-7.962940216064453,-38.264461517333984,-51.80280303955078,-53.98884582519531,-59.42874526977539,-64.5079116821289,-44.80669403076172,-55.46623992919922,-35.70244598388672,-47.5301399230957,-49.85493850708008,-56.73971176147461,-55.439430236816406,-41.60988998413086,-58.19895553588867,-49.46501541137695,-8.364484786987305,-24.465599060058594,-47.63282775878906,-44.177860260009766,-65.24940490722656,-37.36215591430664,-55.541690826416016,-55.05917739868164,-59.089717864990234,-21.41656494140625,-65.51966857910156,-62.23854064941406,-27.855998992919922,-32.322025299072266,-54.19940948486328,-36.096771240234375,-63.22633743286133,-61.42945861816406,-23.914562225341797,-11.27316665649414,-56.558353424072266,-25.78115463256836,-45.587501525878906,-58.56957244873047,-44.89455032348633,-55.967105865478516,-30.703296661376953,-58.68805694580078,-52.012508392333984,-23.38524055480957,-66.2469711303711,-34.49683380126953,-63.5001106262207,-19.830307006835938,-24.65318489074707,-56.64393615722656,-24.055912017822266,-21.68225860595703,-6.992921829223633,-60.243812561035156,-38.45002746582031,-20.17288589477539,-59.892852783203125,-45.73798751831055,-27.503467559814453,-32.912261962890625,-21.000864028930664,-31.077823638916016,-51.43962097167969,-30.474964141845703,-55.3199462890625,-30.954662322998047,-48.989540100097656,-25.89114761352539,-13.781683921813965,-57.794368743896484,-27.743579864501953,-47.112403869628906,-42.07280349731445,-46.09733581542969,-59.46648406982422,-13.550910949707031,-62.55950164794922,-54.84550857543945,-63.392478942871094,-39.740665435791016,-26.363330841064453,-24.428319931030273,-31.539274215698242,-34.892730712890625,-58.625980377197266,-63.97700881958008,-46.392826080322266,-30.375957489013672,-59.94116973876953,-45.30947494506836,-11.852530479431152,-28.815534591674805,-37.220096588134766,-42.81981658935547,-42.13364028930664,-50.12867736816406,-59.11370849609375,-66.93099212646484,-29.507522583007812,-42.728721618652344,-61.87859344482422,-66.77777099609375,-28.08407211303711,-45.629180908203125,-41.242916107177734,-60.487335205078125,-28.303817749023438,-27.652740478515625,-53.31910705566406,-59.39405059814453,-61.98940658569336,-57.37356948852539,-35.328636169433594,-41.11159133911133,-52.08084487915039,-60.52226257324219,-28.391677856445312,-54.528709411621094,-63.09794235229492,-28.843841552734375,-10.791891098022461,-60.84964370727539,-66.24417877197266,-59.26331329345703,-60.580013275146484,-60.01472091674805,-64.16288757324219,-66.34117126464844,-25.988475799560547,-45.45164489746094,-61.442649841308594,-53.330604553222656,-46.783294677734375,-18.861309051513672,-47.710208892822266,-58.39929962158203,-63.44858932495117,-59.31199264526367,-64.58607482910156,-57.92015838623047,-11.7380952835083,-65.29116821289062,-46.53392791748047,-59.934932708740234,-48.43385696411133,-42.93384552001953,-1.717584490776062],\"y\":[1.735641360282898,7.182398319244385,5.349972724914551,5.19887638092041,6.6800947189331055,-2.6191365718841553,5.745700359344482,6.184183120727539,7.4797868728637695,0.39871975779533386,2.198091983795166,7.569417953491211,5.697879791259766,1.771393060684204,5.964029312133789,-1.2387527227401733,-0.7275226712226868,6.600334167480469,7.374517440795898,5.374703407287598,7.076833724975586,2.5325217247009277,6.946719169616699,7.394769668579102,5.531894683837891,-3.142343044281006,4.874432563781738,5.315820217132568,-0.9150426387786865,4.441558361053467,4.0280327796936035,3.8552825450897217,7.653477191925049,6.456045150756836,2.6470539569854736,-2.515205144882202,3.719376564025879,3.5265870094299316,-1.7412689924240112,1.4241008758544922,4.147469997406006,1.6978532075881958,-2.2780604362487793,4.841280937194824,-3.0754518508911133,7.069218635559082,2.1324098110198975,3.5564987659454346,-0.21931177377700806,3.0470595359802246,1.6680079698562622,-4.200329303741455,0.10684747993946075,2.9584171772003174,0.31372562050819397,-1.733917236328125,0.6793761849403381,2.619253635406494,-0.003017986658960581,4.697454452514648,0.43870753049850464,-1.14594304561615,-0.9138671159744263,-2.4373207092285156,1.0702697038650513,3.655911684036255,-6.241745948791504,0.6688761115074158,-5.798802375793457,-2.8010494709014893,-6.751121997833252,-9.4113187789917,-3.552686929702759,-6.384718418121338,-1.9999207258224487,-5.9595184326171875,-4.859402656555176,-8.226459503173828,-5.557089328765869,0.2279672920703888,-7.497984886169434,-6.991823673248291,-8.739903450012207,-0.42292630672454834,-9.07283878326416,-5.282426357269287,-7.570653915405273,-7.923629283905029,-1.6909780502319336,-6.434677600860596,-3.131195306777954,-10.854835510253906,-4.872349262237549,-9.907697677612305,-9.146927833557129,-7.960171222686768,-8.897527694702148,-8.888818740844727,-7.238419055938721,-9.817962646484375,-9.187539100646973,-7.470051288604736,-5.846661567687988,-11.052074432373047,-6.149162292480469,-9.267770767211914,-13.517753601074219,-10.468718528747559,-13.150712966918945,-9.58475112915039,-11.421069145202637,-8.022844314575195,-11.199295043945312,-12.75898551940918,-14.45858383178711,-13.332630157470703,-12.888928413391113,-9.324236869812012,-12.713699340820312,-12.039298057556152,-13.586457252502441,-12.855415344238281,-12.520817756652832,-14.096269607543945,-6.7598066329956055,-12.48674201965332,-10.415064811706543,-13.23083782196045,-14.390417098999023,-11.984434127807617,-13.323434829711914,-11.4190092086792,-8.34378719329834,-9.645219802856445,-13.383796691894531,-11.212273597717285,-13.509037017822266,-13.290119171142578,-13.527027130126953,-8.806547164916992,-13.348335266113281,-13.654779434204102,-13.443571090698242,-11.130791664123535,-13.287127494812012,-13.570125579833984,-13.039515495300293,-10.616053581237793,-10.030670166015625,-12.457239151000977,-12.173595428466797,-13.431922912597656,-12.645139694213867,-12.308797836303711,-13.259971618652344,-12.141483306884766,-13.710285186767578,-13.37851619720459,-12.871371269226074,-13.07669448852539,-8.252129554748535,-9.070691108703613,-13.384648323059082,-13.572379112243652,-12.63829231262207,-9.681622505187988,-7.002124786376953,-11.49135684967041,-12.361930847167969,-13.30583667755127,-9.166224479675293,-12.395033836364746,-13.12459659576416,2.731884717941284,-11.709555625915527,-12.715041160583496,1.1452736854553223,-12.829412460327148,-13.525339126586914,-12.174235343933105,-9.344234466552734,-13.235048294067383,-12.734953880310059,-12.093995094299316,-12.393857955932617,-13.259859085083008,-8.221565246582031,-12.430817604064941,-4.717762470245361,-11.48372745513916,-12.487975120544434,-8.279841423034668,-12.110169410705566,-11.991190910339355,-10.688116073608398,-9.040762901306152,7.963531970977783,-8.408764839172363,-0.803036630153656,-5.580637454986572,-13.458524703979492,-2.388577461242676,-12.9948091506958,-8.257889747619629,-12.513606071472168,0.8747462034225464,6.232028484344482,-0.0037797605618834496,-10.541990280151367,13.805891990661621,-8.71257495880127,-6.081099033355713,-1.7845336198806763,-1.9049322605133057,-8.803363800048828,-12.693157196044922,-11.437618255615234,2.2186715602874756,10.291152954101562,-8.392044067382812,-11.088629722595215,-12.992600440979004,-3.5424063205718994,-4.664063453674316,-4.754735946655273,-3.234058380126953,-9.085814476013184,-7.407098293304443,1.7985079288482666,5.314983367919922,7.215017318725586,-8.86277961730957,-10.15800666809082,-0.5461871027946472,0.4565531015396118,2.135197877883911,0.45766952633857727,-3.7813339233398438,-3.0734896659851074,14.452078819274902,13.998557090759277,-2.756359815597534,-5.370961666107178,11.306166648864746,5.529196739196777,0.9698668718338013,-9.404895782470703,-6.013034343719482,9.619644165039062,-4.110032081604004,-12.926542282104492,1.7397154569625854,-0.3368566036224365,23.474393844604492,28.321847915649414,4.840431213378906,19.983522415161133,-2.495558261871338,5.721330165863037,20.108299255371094,5.017350673675537,-3.200141429901123,16.74408531188965,-4.122570514678955,-3.3540561199188232,-4.159183502197266,14.324858665466309,29.390104293823242,30.074539184570312,10.976008415222168,9.111379623413086,-6.630013465881348,1.2832154035568237,-3.5230607986450195,-3.5853748321533203,7.702596664428711,-2.6529457569122314,17.468116760253906,30.722721099853516,8.304644584655762,3.4615652561187744,-2.6798064708709717,-5.076521396636963,13.445359230041504,7.344383716583252,16.557872772216797,7.933481693267822,28.219524383544922,6.1283769607543945,1.4372631311416626,-0.8675364255905151,20.88003921508789,1.044026255607605,3.745957612991333,-9.5623779296875,24.517114639282227,7.121443271636963,2.6805925369262695,29.25328254699707,-15.144668579101562,7.438107013702393,0.00805997010320425,-5.2765936851501465,31.919282913208008,17.826143264770508,6.542314052581787,4.253659248352051,21.22197723388672,1.760037899017334,10.439292907714844,2.7392001152038574,-7.855705261230469,15.944955825805664,10.335969924926758,22.8857364654541,10.898571014404297,11.65859317779541,1.9228403568267822,19.044933319091797,7.418882369995117,17.651758193969727,18.269702911376953,14.053025245666504,24.36391830444336,27.523040771484375,24.756261825561523,8.003626823425293,-4.380068302154541,22.175893783569336,19.976720809936523,4.691504001617432,23.506620407104492,3.4959487915039062,13.797696113586426,19.485929489135742,16.868947982788086,18.195064544677734,32.700904846191406,25.506513595581055,17.385679244995117,16.764284133911133,7.432416915893555,5.261027812957764,-2.702068567276001,31.415624618530273,-6.963833808898926,25.99310874938965,19.021137237548828,29.003196716308594,29.248727798461914,4.09567928314209,25.023672103881836,9.499035835266113,31.756805419921875,23.7816162109375,9.649519920349121,-17.05443572998047,26.386184692382812,20.44150161743164,33.044654846191406,20.363475799560547,30.87084197998047,29.464447021484375,22.290666580200195,32.64830017089844,-19.86457633972168,28.091402053833008,11.625324249267578,23.402822494506836,24.005035400390625,-20.1605167388916,23.004560470581055,14.989023208618164,9.074828147888184,33.83269119262695,18.17414665222168,26.96902847290039,17.27759552001953,13.690142631530762,28.57636833190918,14.970367431640625,24.29800796508789,22.465702056884766,28.069381713867188,18.724435806274414,31.50334930419922,33.97320556640625,8.991387367248535,7.957767963409424,25.744762420654297,31.24301528930664,10.318156242370605,31.251689910888672,30.85123634338379,-23.236513137817383,30.941574096679688,28.043527603149414,20.677988052368164,16.44373321533203,32.627952575683594,10.816603660583496,30.349061965942383,31.004310607910156,20.53606414794922,-25.403093338012695,17.845264434814453,6.742674350738525,27.369678497314453,-17.125022888183594,28.41766929626465,-20.915616989135742,27.65300941467285,15.611824035644531,23.344758987426758,16.770442962646484,31.20002555847168,28.708362579345703,-24.082956314086914,32.70413589477539,31.660058975219727,26.182247161865234,23.149036407470703,-28.21907615661621,26.867368698120117,-20.35051155090332,32.82589340209961,20.87135124206543,29.82638931274414,-16.15599250793457,-15.375040054321289,15.668071746826172,30.070070266723633,24.220184326171875,29.64978790283203,33.375492095947266,-24.629011154174805,32.66594314575195,-15.396551132202148,26.07636070251465,21.30912208557129,23.625667572021484,17.771703720092773,27.096328735351562,17.618806838989258,19.306354522705078,12.876686096191406,-20.44599151611328,28.39542007446289,31.81942367553711,5.956504821777344,-4.970758438110352,31.087055206298828,-15.743395805358887,30.193519592285156,-16.303667068481445,-24.434322357177734,-22.46613311767578,31.213829040527344,31.901411056518555,26.56974983215332,19.478071212768555,-16.731918334960938,33.109519958496094,30.622459411621094,31.965707778930664,31.55281639099121,-30.290328979492188,11.525778770446777,30.803756713867188,-26.660476684570312,-26.19445037841797,26.941843032836914,-30.50958251953125,-31.420591354370117,-29.165374755859375,24.96113395690918,21.611608505249023,8.799291610717773,27.891916275024414,18.605581283569336,-17.96385955810547,-30.031869888305664,-22.877473831176758,24.828691482543945,31.68728256225586,-20.96756362915039,-20.472702026367188,-16.410062789916992,29.82554817199707,29.061542510986328,27.245349884033203,-21.4649658203125,32.52738952636719,-31.308712005615234,29.03619384765625,-17.705730438232422,32.06355667114258,31.924518585205078,31.99809455871582,31.043529510498047,17.312829971313477,32.62882614135742,31.18124008178711,32.84440231323242,-17.44063949584961,26.71802520751953,-19.626384735107422,32.885780334472656,-22.5003662109375,-21.43885040283203,-28.63113784790039,-23.71935272216797,30.426185607910156,31.30183982849121,-31.455190658569336,-20.89138412475586,7.5643310546875,-24.77048683166504,-19.088632583618164,-26.896169662475586,-19.075912475585938,-16.293912887573242,-18.81972885131836,-14.936238288879395,18.387977600097656,-26.25588035583496,31.398170471191406,-9.67534065246582,-30.061471939086914,28.20980453491211,-17.89568328857422,31.898460388183594,32.83780288696289,-15.001946449279785,24.514890670776367,14.84166145324707,33.010616302490234,33.081817626953125,32.27922439575195,33.096622467041016,28.974884033203125,30.535614013671875,-25.994176864624023,30.55436897277832,32.39180374145508,-29.644716262817383,-19.57228660583496,-17.366731643676758,31.184579849243164,20.101966857910156,-27.54266357421875,25.569747924804688,-29.165367126464844,33.0778923034668,30.992839813232422,-16.75741195678711,-27.448169708251953,-21.308876037597656,-13.99035930633545,31.93610191345215,-18.07167625427246,32.202632904052734,-15.701116561889648,-29.213275909423828,-9.318072319030762,-20.37588882446289,-16.332027435302734,30.55159568786621,-23.472837448120117,-18.583765029907227,-28.61543846130371,-17.85529136657715,-28.370271682739258,10.874558448791504,-24.73692512512207,-21.20905303955078,24.173429489135742,-1.2593134641647339,30.72943115234375,-18.42303466796875,27.26650047302246,-23.197128295898438,-29.490520477294922,24.142505645751953,29.226369857788086,-29.952131271362305,30.608760833740234,-19.62969398498535,-17.41840171813965,-27.822568893432617,31.42001724243164,-22.40554428100586,-28.812969207763672,-30.391124725341797,-25.383438110351562,-28.740341186523438,-20.0793514251709,-23.24313735961914,-27.185422897338867,-27.666393280029297,-29.06728172302246,9.996942520141602,-29.855894088745117,-26.350154876708984,-20.916372299194336,-19.331037521362305,-25.909255981445312,-12.380099296569824,-22.306713104248047,-28.742530822753906,27.73493766784668,-27.389680862426758,-13.510350227355957,-25.42075538635254,-29.497934341430664,-17.47067642211914,-20.905771255493164,-19.180551528930664,-28.9679012298584,20.53605842590332,-28.638559341430664,-25.44788932800293,28.82526969909668,-21.62024688720703,-27.91364097595215,-28.569204330444336,-27.076683044433594,31.054460525512695,-28.801433563232422,31.861257553100586,-30.728418350219727,-16.897335052490234,32.154029846191406,-20.144987106323242,30.306941986083984,-8.405871391296387,-29.17523956298828,-28.892730712890625,-5.506521224975586,-25.47267723083496,31.882457733154297,-26.847980499267578,-27.362768173217773,-3.66603946685791,-31.229890823364258,-28.051008224487305,-16.936054229736328,32.31870651245117,-30.031497955322266,-23.32623863220215,6.084774971008301,-30.169755935668945,-28.619089126586914,-24.04109764099121,32.80069351196289,-28.068138122558594,-25.7181339263916,-19.0559024810791,-17.96834945678711,-18.639123916625977,-27.169063568115234,19.158721923828125,-17.989944458007812,-22.044832229614258,-26.818384170532227,-29.337793350219727,-25.939931869506836,31.698001861572266,-28.369115829467773,-22.957077026367188,-25.95400619506836,-29.579059600830078,-1.1425681114196777,-27.267488479614258,-15.01543140411377,-22.51764678955078,-27.876598358154297,-15.919997215270996,-19.38258934020996,-30.137338638305664,-30.08995819091797,15.187898635864258,-12.952849388122559,16.192773818969727,-25.677005767822266,-20.80837059020996,-7.1812262535095215,-3.61592698097229,-26.968578338623047,9.946601867675781,-31.515762329101562,-26.249950408935547,-23.52895736694336,-9.674466133117676,-28.205270767211914,-14.692170143127441,-28.262451171875,-27.827686309814453,-14.03217601776123,-10.931182861328125,-17.215002059936523,-23.471298217773438,-20.827808380126953,-26.963008880615234,-21.32710075378418,-3.5432937145233154,-21.344253540039062,-8.721151351928711,-28.94192123413086,-30.408950805664062,-28.233509063720703,-29.39112091064453,5.366730213165283,-30.459993362426758,-12.223764419555664,29.946996688842773,-3.0835981369018555,-28.26333999633789,-1.3537217378616333,9.035228729248047,-24.546918869018555,-1.8268433809280396,-15.954585075378418,-28.442514419555664,-11.603012084960938,-11.5103759765625,-30.822776794433594,-25.24367332458496,-6.011133670806885,-24.934499740600586,-30.034347534179688,-31.215368270874023,-28.122339248657227,-29.841590881347656,-15.328736305236816,-17.068655014038086,-27.199546813964844,2.7911648750305176,-11.0541410446167,-31.26322364807129,-11.440716743469238,-25.5772647857666,-13.605563163757324,-25.988162994384766,-27.753398895263672,1.7901997566223145,-27.07455825805664,-3.575500011444092,-0.0935896709561348,-19.979482650756836,-19.73668098449707,-14.393446922302246,10.521893501281738,-28.33072853088379,-29.24501609802246,-28.859872817993164,-29.10210609436035,2.2553725242614746,-15.537883758544922,-26.78216552734375,-16.221771240234375,-2.4438633918762207,-27.140932083129883,-11.99191951751709,-5.821395397186279,-1.817177176475525,8.649747848510742,-22.161142349243164,-29.918779373168945,-4.229680061340332,-25.61725425720215,-29.936546325683594,-10.012751579284668,-8.432439804077148,-25.20198631286621,-18.90831184387207,-28.25536346435547,-25.336605072021484,15.912932395935059,-28.439706802368164,-24.699100494384766,-21.059185028076172,7.6519293785095215,10.247003555297852,15.982287406921387,17.495847702026367,-30.31688690185547,-23.893299102783203,-25.73927879333496,9.127035140991211,-24.70124053955078,5.935776233673096,-0.7242749929428101,-7.927272319793701,-25.074560165405273,8.01701831817627,17.658226013183594,-29.98561668395996,31.781757354736328,-19.983652114868164,-29.10269546508789,-7.22918176651001,-17.22917366027832,-29.313535690307617,-9.939618110656738,13.657977104187012,-9.364885330200195,1.8913079500198364,-12.722254753112793,-24.793136596679688,-7.68479585647583,-29.774364471435547,-2.8102025985717773,-10.190690994262695,10.446944236755371,-19.253355026245117,-28.979347229003906,6.109312534332275,32.38117980957031,12.809752464294434,-30.072492599487305,9.212651252746582,-25.1507568359375,8.422215461730957,-30.251075744628906,-9.243515968322754,-19.25796890258789,-22.0965518951416,4.298635959625244,-12.092887878417969,-6.859236717224121,4.0791544914245605,-29.7412166595459,-29.83360481262207,-9.93264389038086,19.83002281188965,-1.020037055015564,-24.837907791137695,14.99825668334961,18.76936912536621,-28.4210147857666,-9.880537033081055,32.58967971801758,-8.466654777526855,-21.873254776000977,12.180092811584473,-14.0172758102417,-10.89797592163086,-1.3530665636062622,16.188295364379883,-7.467169761657715,0.5269630551338196,15.264205932617188,3.574150800704956,14.550435066223145,-12.566797256469727,-12.234539985656738,20.125337600708008,-28.48406219482422,10.981051445007324,-16.274620056152344,-8.03364372253418,2.6837832927703857,8.570662498474121,7.070242881774902,-23.792949676513672,-5.133358001708984,32.315670013427734,6.35216760635376,-3.2116997241973877,-9.107884407043457,-10.599565505981445,18.324872970581055,-9.060760498046875,4.0427727699279785,-12.31342887878418,-17.068431854248047,-20.180967330932617,9.55820083618164,10.7279634475708,14.996768951416016,12.6881103515625,5.150139331817627,4.345326900482178,-1.832120418548584,-29.71876335144043,-16.863340377807617,-30.205284118652344,-25.534318923950195,-24.465328216552734,-2.648829221725464,-2.475494384765625,-2.0928268432617188,7.775960922241211,11.272541999816895,-11.286895751953125,5.196899890899658,-0.26311174035072327,1.7704241275787354,1.650128722190857,0.8574631810188293,14.680523872375488,-17.046777725219727,-21.03080940246582,-7.304313659667969,10.346055030822754,-10.342813491821289,-10.02628231048584,-30.07730484008789,10.254145622253418,-19.593183517456055,3.9271514415740967,-19.670177459716797,-6.177830696105957,5.0862531661987305,-19.32229232788086,-18.002010345458984,18.14251708984375,-21.252408981323242,-18.386798858642578,-10.157184600830078,-2.7027368545532227,6.851766109466553,11.490328788757324,3.3745875358581543,6.586488723754883,-8.74865436553955,-10.32693099975586,16.624359130859375,12.504788398742676,-28.070241928100586,-17.753997802734375,8.831262588500977,3.6736531257629395,11.177635192871094,-25.241363525390625,10.80714225769043,7.422320365905762,-19.909530639648438,15.720442771911621,-10.78830623626709,-31.5447998046875,-29.089189529418945,-3.128173351287842,-4.233945369720459,-7.336618423461914,-8.56334114074707,12.496079444885254,-17.733047485351562,-6.1550517082214355,-22.729902267456055,-6.389270782470703,-4.606468677520752,-3.5375025272369385,-26.09827995300293,4.1515326499938965,-9.066004753112793,-28.770265579223633,-5.324825286865234,-7.233496189117432,17.43854522705078,-30.123764038085938,14.903369903564453,-24.74650764465332,-20.144033432006836,-28.18085289001465,12.543378829956055,-12.770752906799316,15.000421524047852,3.364081621170044,15.695708274841309,6.484275817871094,16.574350357055664,-6.863672256469727,2.3085474967956543,-21.728439331054688,14.561519622802734,-30.807125091552734,6.418302536010742,4.660369396209717,14.416434288024902,12.854944229125977,14.252376556396484,12.406790733337402,17.710262298583984,9.722150802612305,-25.85719871520996,5.630206108093262,-8.46196460723877,17.817703247070312,15.40408992767334,-8.246891975402832,1.191173791885376,13.48697280883789,3.2988076210021973,8.774523735046387,-8.041666984558105,-28.843204498291016,17.368528366088867,21.052471160888672,-7.1507673263549805,18.896942138671875,16.197689056396484,-9.387308120727539,7.1812520027160645,13.953465461730957,11.565773963928223,-7.938084602355957,-0.08088063448667526,-12.958375930786133,13.016139030456543,-6.434439182281494,16.35396385192871,-9.178550720214844,10.229949951171875,12.79198932647705,-8.057771682739258,8.559324264526367,10.229228973388672,17.320945739746094,13.123831748962402,8.08818244934082,10.446688652038574,-30.4165096282959,-28.406192779541016,13.038477897644043,-10.035426139831543,15.636959075927734,20.455707550048828,19.02963638305664,-6.5972771644592285,-14.415245056152344,14.219542503356934,-11.003541946411133,2.8819057941436768,3.66770339012146,1.9273595809936523,4.934467315673828,-1.809154748916626,-10.931357383728027,-25.85857582092285,-9.446808815002441,20.605514526367188,18.043132781982422,7.629074573516846,-2.1960396766662598,14.906732559204102,0.9235325455665588,5.585403919219971,-5.282473087310791,13.758034706115723,-6.530067443847656,-15.445625305175781,3.3765909671783447,-2.763425827026367,-16.126638412475586,16.934246063232422,14.008330345153809,16.46647071838379,12.53818416595459,19.005538940429688,-5.009090423583984,20.243160247802734,15.281058311462402,12.729381561279297,7.670867443084717,17.1082820892334,9.813109397888184,-15.213857650756836,12.038390159606934,10.589621543884277,13.157872200012207,12.845795631408691,-16.408262252807617,0.7350339293479919,-29.474821090698242,-11.718507766723633,15.48658275604248,16.91604995727539,-7.044911861419678,-9.04479694366455,-0.3428201973438263,14.081622123718262,-1.0352833271026611,-2.400451898574829,-3.223658561706543,8.000752449035645,-1.3196779489517212,-9.005880355834961,-27.473661422729492,1.9389020204544067,18.805335998535156,-8.033381462097168,1.6611183881759644,21.075946807861328,-0.17636793851852417,9.692421913146973,2.975482702255249,18.29659080505371,15.180672645568848,8.90335464477539,10.255383491516113,16.927642822265625,2.587768793106079,8.44845199584961,-11.950289726257324,-2.5299572944641113,2.586890697479248,-6.249433517456055,-18.363643646240234,8.489839553833008,-0.048271264880895615,-2.637840509414673,4.6243133544921875,16.895124435424805,-0.15827873349189758,12.186981201171875,-1.8525350093841553,7.74022102355957,-7.247063636779785,17.996885299682617,16.03249168395996,19.65786361694336,18.030031204223633,16.113975524902344,16.19017219543457,19.47186279296875,-7.792626857757568,13.35338306427002,-12.723688125610352,14.884377479553223,5.4722490310668945,-8.215906143188477,-11.60930061340332,0.6000919342041016,17.639484405517578,-11.253679275512695,-22.247644424438477,7.862364292144775,11.769451141357422,-2.6449685096740723,-8.59389591217041,9.230488777160645,12.354130744934082,-10.58874797821045,17.953432083129883,7.999058723449707,-3.8517518043518066,13.633068084716797,18.024295806884766,-6.460742473602295,17.1133975982666,16.322566986083984,17.856115341186523,-12.287131309509277,9.869866371154785,-4.414822578430176,-11.546417236328125,11.130188941955566,-5.65168571472168,13.741731643676758,-5.074069023132324,15.068650245666504,3.8756263256073,10.632871627807617,-23.28560447692871,9.189112663269043,-29.056764602661133,-3.1218862533569336,-29.328105926513672,0.04897941276431084,-6.644769191741943,-8.588356971740723,-5.9267258644104,-3.3088936805725098,-9.777528762817383,8.161184310913086,1.6542452573776245,19.627443313598633,-0.4570651650428772,18.919004440307617,7.038595676422119,17.966318130493164,-23.603408813476562,2.235623836517334,-3.930405616760254,19.456871032714844,19.69580841064453,13.530729293823242,17.11013412475586,7.216124534606934,10.49123764038086,8.905542373657227,14.2090425491333,-5.033754825592041,19.91672706604004,18.269989013671875,9.558331489562988,10.526613235473633,-7.759783744812012,9.643060684204102,7.811359882354736,-8.04407787322998,19.86263656616211,11.444540977478027,7.663875102996826,-4.0683064460754395,0.7225781083106995,-1.7160305976867676,-11.278511047363281,-12.056344032287598,9.062745094299316,-8.59330940246582,7.334203243255615,-22.14989471435547,-1.8610068559646606,-8.039210319519043,-10.040494918823242,12.733755111694336,11.222646713256836,10.153867721557617,14.3572416305542,-6.192142963409424,14.316709518432617,-6.628612041473389,13.123394012451172,9.679086685180664,13.634101867675781,12.155390739440918,-3.320855140686035,-3.8829345703125,-20.200027465820312,5.968723297119141,-6.155409812927246,-5.69950008392334,6.115879535675049,1.7124388217926025,18.51012420654297,-4.680210590362549,-8.513611793518066,-3.3767127990722656,0.016715215519070625,2.003873586654663,-16.999107360839844,4.140839099884033,15.293700218200684,14.621776580810547,-8.470364570617676,-9.30115032196045,4.238299369812012,6.50708532333374,11.851863861083984,-11.563215255737305,0.3131040930747986,-3.4490408897399902,18.574167251586914,0.20636306703090668,-6.064156532287598,5.120077133178711,15.172467231750488,8.197235107421875,15.148300170898438,-11.947823524475098,2.449552297592163,-12.389097213745117,12.671080589294434,18.079391479492188,-10.567025184631348,11.130126953125,-4.130402088165283,-6.3521294593811035,-7.726385116577148,-2.763244867324829,-11.231351852416992,7.8517656326293945,18.537975311279297,13.608415603637695,0.8695192337036133,-15.486300468444824,-7.954296588897705,-3.3677780628204346,-7.2785725593566895,16.678537368774414,-11.564949035644531,1.3002521991729736,-6.79778528213501,-12.627767562866211,9.612163543701172,-3.618194103240967,3.1498825550079346,15.395407676696777,-7.5964035987854,-10.717901229858398,-9.195384979248047,-9.560256004333496,15.104300498962402,9.928762435913086,15.928909301757812,7.649730682373047,11.705695152282715,-10.39688491821289,-2.808406114578247,18.045454025268555,6.471303939819336,17.03453254699707,12.461481094360352,0.9140745401382446,-0.5817347168922424,5.152626037597656,-16.766782760620117,-5.865133285522461,0.8378266096115112,12.87220573425293,-13.715971946716309,1.2292044162750244,-12.406059265136719,-11.577040672302246,-4.727160930633545,-3.226412057876587,-8.99348258972168,0.4810429811477661,7.037015914916992,0.27867192029953003,-4.811863422393799,9.174407005310059,14.019140243530273,17.296823501586914,9.032203674316406,18.357227325439453,-10.259580612182617,-7.15833044052124,4.7794671058654785,-8.61828899383545,-6.139187335968018,-11.706964492797852,-10.40929889678955,13.030158996582031,-5.51170539855957,10.33674144744873,-9.947155952453613,-11.360279083251953,14.911725997924805,-6.0206122398376465,1.6487371921539307,-10.349498748779297,5.397541522979736,17.6856689453125,2.385141611099243,8.789698600769043,6.966601848602295,3.0491533279418945,-10.573698043823242,11.049549102783203,1.270965814590454,13.547670364379883,-6.231499671936035,5.462351322174072,9.897124290466309,-13.068432807922363,-3.087031602859497,15.770827293395996,-2.4285922050476074,-4.2058305740356445,14.988302230834961,13.696999549865723,10.81096363067627,10.529365539550781,16.31368637084961,-7.008412837982178,-8.745302200317383,-1.6039915084838867,12.62464427947998,-8.151501655578613,-4.181075096130371,-5.7697577476501465,1.0399903059005737,-11.656743049621582,-5.097140789031982,6.06613826751709,-1.339036464691162,-6.5703444480896,-6.476625442504883,10.369129180908203,10.6033935546875,2.6037144660949707,14.176546096801758,-8.022924423217773,16.682498931884766,-3.675039052963257,-2.0664851665496826,-8.7634859085083,-8.912681579589844,-1.7934261560440063,7.526803016662598,2.090129852294922,-5.171795845031738,-6.050704479217529,19.630998611450195,-8.103646278381348,3.796490430831909,-9.287589073181152,-3.745117664337158,-13.185900688171387,-6.750227451324463,17.201452255249023,-1.4890369176864624,9.874855995178223,12.136228561401367,4.928591728210449,9.148083686828613,-9.049237251281738,14.01098346710205,12.640750885009766,10.439215660095215,11.260611534118652,-2.274075508117676,-3.123100519180298,14.60676097869873,4.4021992683410645,17.407257080078125,16.87938690185547,5.254757881164551,18.60306739807129,-10.633279800415039,16.200586318969727,-6.849496841430664,-8.588987350463867,13.784758567810059,-5.359262466430664,0.6353601813316345,-11.598578453063965,4.422555923461914,-6.33329439163208,-1.6930935382843018,-4.789739608764648,11.270730972290039,15.41317367553711,-0.5294869542121887,-5.470694541931152,-7.34291934967041,12.459693908691406,-8.56721305847168,-7.780171871185303,-1.390990138053894,15.084861755371094,-8.718332290649414,7.38089656829834,-12.612783432006836,15.795747756958008,-11.05583667755127,16.684541702270508,4.800833702087402,-4.886940002441406,-5.882748126983643,-5.091859340667725,-12.22791576385498,14.37110710144043,5.21095609664917,-6.9626383781433105,9.34056568145752,12.193835258483887,-8.02704906463623,-1.3837432861328125,-4.497095584869385,4.089738368988037,4.345913410186768,-9.230588912963867,3.4182779788970947,-10.284414291381836,6.121289253234863,-3.8330445289611816,-2.588992118835449,5.888871669769287,10.99128532409668,-9.40084457397461,-10.790745735168457,17.818307876586914,-7.654120445251465,7.848167896270752,-0.339521199464798,18.074111938476562,14.87211799621582,9.125638008117676,-3.9802074432373047,7.607451915740967,19.903152465820312,-0.8620360493659973,1.805676817893982,12.624170303344727,-10.369573593139648,-2.4939005374908447,-4.978275775909424,6.656164646148682,-5.5371317863464355,-7.500277519226074,2.1927883625030518,15.385416030883789,3.1474056243896484,16.435420989990234,-4.8877129554748535,-5.969909191131592,1.589290976524353,14.982165336608887,4.517645835876465,-8.569204330444336,17.685144424438477,0.6585708856582642,-12.142658233642578,4.20700216293335,-8.771297454833984,-9.156856536865234,7.405279159545898,11.368929862976074,6.926969528198242,-2.9511687755584717,-1.181413173675537,18.28303337097168,-5.931913375854492,3.489035129547119,-1.8000340461730957,5.4276533126831055,-2.787590265274048,-12.375359535217285,-0.3464111089706421,-9.387301445007324,-1.0878448486328125,-5.677570819854736,1.233275055885315,-2.426344871520996,14.96544361114502,-9.508048057556152,2.979623556137085,8.068782806396484,3.9068424701690674,-8.750682830810547,16.556793212890625,0.12230447679758072,-0.20081600546836853,-3.277921676635742,-0.855522096157074,-3.4780242443084717,18.024030685424805,-6.578836917877197,-4.449005126953125,1.8309165239334106,-3.966339111328125,5.060880184173584,7.717019081115723,18.765003204345703,3.0220794677734375,12.377551078796387,-8.145630836486816,-5.662277698516846,19.320640563964844,11.992688179016113,5.468421936035156,6.440549373626709,-3.6470558643341064,16.98076820373535,-9.388823509216309,-7.302094459533691,6.627552509307861,-7.992072582244873,-10.055009841918945,-7.699041366577148,-12.354296684265137,4.100208282470703,-13.43835735321045,-2.3902511596679688,14.320380210876465,-0.4363109767436981,1.2045772075653076,-10.744460105895996,-3.6464896202087402,15.528726577758789,-9.82917308807373,16.63888931274414,9.633413314819336,15.725608825683594,-3.4912967681884766,18.162567138671875,-9.416522979736328,11.938117980957031,9.684212684631348,-9.03542423248291,-4.778174877166748,5.34044075012207,8.546277046203613,-7.206191062927246,-9.444153785705566,-8.202540397644043,-9.515714645385742,-4.146864414215088,-7.592575550079346,-3.858961582183838,-8.526620864868164,3.821094274520874,-10.001967430114746,12.861048698425293,-7.136057376861572,-11.097457885742188,15.885682106018066,-7.874370574951172,-5.8837809562683105,-4.979372501373291,-1.7288713455200195,5.976747512817383,-10.844013214111328,-1.2556605339050293,-9.030580520629883,-11.122174263000488,-6.529136657714844,-0.17430362105369568,-1.389836072921753,-9.674698829650879,2.17258620262146,-8.8948974609375,20.21411895751953,8.431112289428711,-10.947418212890625,-9.874539375305176,5.299598217010498,-12.264266967773438,-7.1093339920043945,-2.840860366821289,1.5384970903396606,10.460433959960938,5.906365394592285,3.583160638809204,-4.1736602783203125,-7.142764091491699,-3.3661177158355713,-7.8798370361328125,3.956028461456299,2.0266013145446777,3.3078603744506836,15.444939613342285,-4.194111347198486,8.008017539978027,-7.952826499938965,0.996685802936554,-13.61886215209961,-6.633680820465088,-0.9256466031074524,-0.06400114297866821,-7.142338275909424,8.945508003234863,7.35276985168457,-9.366840362548828,5.40056037902832,11.229658126831055,6.663877487182617,-1.2774065732955933,12.398787498474121,6.450845241546631,19.11446762084961,-0.40970632433891296,-7.4484405517578125,10.663776397705078,3.4421510696411133,-7.740541934967041,-2.9848055839538574,-8.065303802490234,15.27479076385498,1.8144760131835938,-3.926269292831421,-2.46978759765625,-4.965546607971191,-1.8529564142227173,-10.278128623962402,11.718366622924805,17.10973358154297,-4.267834663391113,-5.229687690734863,-8.066085815429688,-10.152583122253418,-10.918437004089355,2.599374771118164,15.90294361114502,1.8638449907302856,-3.032684087753296,2.58538556098938,-11.020291328430176,1.9112653732299805,6.632382869720459,-2.599011182785034,-9.872811317443848,-0.639639675617218,3.6661109924316406,-8.861452102661133,-5.651010990142822,2.2228918075561523,-9.151947021484375,16.48920440673828,-1.4935204982757568,-10.058372497558594,-12.453620910644531,-11.302836418151855,-8.449735641479492,0.849470317363739,7.991910457611084,-6.0898332595825195,-10.362504005432129,3.625548839569092,7.869830131530762,-5.995707035064697,-10.635302543640137,-8.95701789855957,4.120894908905029,-1.512418270111084,5.24622917175293,-3.1122121810913086,0.6010280847549438,1.29890775680542,-1.6297346353530884,-8.80595874786377,-11.417948722839355,-5.301873207092285,2.8476405143737793,-4.402142524719238,-5.402554035186768,3.2659525871276855,-1.7544447183609009,18.770225524902344,1.9494585990905762,7.3985161781311035,1.4299373626708984,4.455219268798828,-0.9136273264884949,6.219705581665039,6.943734645843506,8.870448112487793,-11.966331481933594,2.318817138671875,-6.1107964515686035,-9.48292064666748,8.852065086364746,-10.306638717651367,1.3085702657699585,4.512131214141846,-0.4018937945365906,4.353875160217285,-0.43589428067207336,16.616785049438477,6.155932903289795,-11.799840927124023,3.1050405502319336,-10.339310646057129,-13.068232536315918,11.666439056396484],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5a4de08b-deab-4477-aa0b-a380d1b05534');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    # extract the words & their vectors, as numpy arrays\n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  # fixed-width numpy strings\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(model)\n",
    "\n",
    "def plot_with_plotly(x_vals, y_vals, labels, plot_in_notebook=True):\n",
    "    from plotly.offline import init_notebook_mode, iplot, plot\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    trace = go.Scatter(x=x_vals, y=y_vals, mode='text', text=labels)\n",
    "    data = [trace]\n",
    "\n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')\n",
    "\n",
    "\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "\n",
    "    #\n",
    "    # Label randomly subsampled 25 data points\n",
    "    #\n",
    "    indices = list(range(len(labels)))\n",
    "    selected_indices = random.sample(indices, 25)\n",
    "    for i in selected_indices:\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "except Exception:\n",
    "    plot_function = plot_with_matplotlib\n",
    "else:\n",
    "    plot_function = plot_with_plotly\n",
    "\n",
    "plot_function(x_vals, y_vals, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpacyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
