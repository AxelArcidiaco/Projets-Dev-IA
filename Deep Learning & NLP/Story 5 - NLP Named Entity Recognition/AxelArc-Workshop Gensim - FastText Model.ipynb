{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 15:00:52,631 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2023-04-04 15:00:52,633 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
      "2023-04-04 15:00:52,636 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2023-04-04T15:00:52.635640', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 15:00:52,968 : INFO : FastText lifecycle event {'params': 'FastText<vocab=0, vector_size=100, alpha=0.025>', 'datetime': '2023-04-04T15:00:52.968193', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-04-04 15:00:52,972 : INFO : collecting all words and their counts\n",
      "2023-04-04 15:00:52,978 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-04 15:00:53,069 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2023-04-04 15:00:53,070 : INFO : Creating a fresh vocabulary\n",
      "2023-04-04 15:00:53,115 : INFO : FastText lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.34% of original 10781, drops 9019)', 'datetime': '2023-04-04T15:00:53.115683', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 15:00:53,118 : INFO : FastText lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.95% of original 59890, drops 13806)', 'datetime': '2023-04-04T15:00:53.118689', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 15:00:53,168 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2023-04-04 15:00:53,172 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2023-04-04 15:00:53,174 : INFO : FastText lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2023-04-04T15:00:53.174015', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-04 15:00:53,300 : INFO : estimated required memory for 1762 words, 2000000 buckets and 100 dimensions: 802597824 bytes\n",
      "2023-04-04 15:00:53,301 : INFO : resetting layer weights\n",
      "2023-04-04 15:00:56,415 : INFO : FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-04T15:00:56.415055', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-04 15:00:56,417 : INFO : FastText lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-04T15:00:56.417056', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-04 15:00:56,713 : INFO : EPOCH 0: training on 60387 raw words (32890 effective words) took 0.3s, 117525 effective words/s\n",
      "2023-04-04 15:00:57,074 : INFO : EPOCH 1: training on 60387 raw words (32931 effective words) took 0.3s, 95632 effective words/s\n",
      "2023-04-04 15:00:57,401 : INFO : EPOCH 2: training on 60387 raw words (32850 effective words) took 0.3s, 105593 effective words/s\n",
      "2023-04-04 15:00:57,730 : INFO : EPOCH 3: training on 60387 raw words (32802 effective words) took 0.3s, 104487 effective words/s\n",
      "2023-04-04 15:00:58,020 : INFO : EPOCH 4: training on 60387 raw words (32856 effective words) took 0.3s, 122363 effective words/s\n",
      "2023-04-04 15:00:58,022 : INFO : FastText lifecycle event {'msg': 'training on 301935 raw words (164329 effective words) took 1.6s, 102502 effective words/s', 'datetime': '2023-04-04T15:00:58.022037', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastText object at 0x000002DD1E1410D0>\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as print\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "# Set file names for train and test data\n",
    "corpus_file = datapath('lee_background.cor')\n",
    "\n",
    "model = FastText(vector_size=100)\n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(corpus_file=corpus_file)\n",
    "\n",
    "# train the model\n",
    "model.train(\n",
    "    corpus_file=corpus_file, epochs=model.epochs,\n",
    "    total_examples=model.corpus_count, total_words=model.corpus_total_words,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving/loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 15:01:17,348 : INFO : FastText lifecycle event {'fname_or_handle': 'C:\\\\Users\\\\AxelArcidiaco\\\\AppData\\\\Local\\\\Temp\\\\saved_model_gensim-q0ka8l3l', 'separately': '[]', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-04T15:01:17.348278', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'saving'}\n",
      "2023-04-04 15:01:17,350 : INFO : storing np array 'vectors_ngrams' to C:\\Users\\AxelArcidiaco\\AppData\\Local\\Temp\\saved_model_gensim-q0ka8l3l.wv.vectors_ngrams.npy\n",
      "2023-04-04 15:01:19,505 : INFO : not storing attribute buckets_word\n",
      "2023-04-04 15:01:19,506 : INFO : not storing attribute vectors\n",
      "2023-04-04 15:01:19,509 : INFO : not storing attribute cum_table\n",
      "2023-04-04 15:01:19,518 : INFO : saved C:\\Users\\AxelArcidiaco\\AppData\\Local\\Temp\\saved_model_gensim-q0ka8l3l\n",
      "2023-04-04 15:01:19,520 : INFO : loading FastText object from C:\\Users\\AxelArcidiaco\\AppData\\Local\\Temp\\saved_model_gensim-q0ka8l3l\n",
      "2023-04-04 15:01:19,539 : INFO : loading wv recursively from C:\\Users\\AxelArcidiaco\\AppData\\Local\\Temp\\saved_model_gensim-q0ka8l3l.wv.* with mmap=None\n",
      "2023-04-04 15:01:19,541 : INFO : loading vectors_ngrams from C:\\Users\\AxelArcidiaco\\AppData\\Local\\Temp\\saved_model_gensim-q0ka8l3l.wv.vectors_ngrams.npy with mmap=None\n",
      "2023-04-04 15:01:20,410 : INFO : setting ignored attribute buckets_word to None\n",
      "2023-04-04 15:01:20,412 : INFO : setting ignored attribute vectors to None\n",
      "2023-04-04 15:01:20,569 : INFO : setting ignored attribute cum_table to None\n",
      "2023-04-04 15:01:20,591 : INFO : FastText lifecycle event {'fname': 'C:\\\\Users\\\\AxelArcidiaco\\\\AppData\\\\Local\\\\Temp\\\\saved_model_gensim-q0ka8l3l', 'datetime': '2023-04-04T15:01:20.591757', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastText object at 0x000002DD2EC4C130>\n"
     ]
    }
   ],
   "source": [
    "# Save a model trained via Gensim's fastText implementation to temp.\n",
    "import tempfile\n",
    "import os\n",
    "with tempfile.NamedTemporaryFile(prefix='saved_model_gensim-', delete=False) as tmp:\n",
    "    model.save(tmp.name, separately=[])\n",
    "\n",
    "# Load back the same model.\n",
    "loaded_model = FastText.load(tmp.name)\n",
    "print(loaded_model)\n",
    "\n",
    "os.unlink(tmp.name)  # demonstration complete, don't need the temp file anymore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word vector lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastTextKeyedVectors object at 0x000002DD1E141400>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "wv = model.wv\n",
    "print(wv)\n",
    "\n",
    "#\n",
    "# FastText models support vector lookups for out-of-vocabulary words by summing up character ngrams belonging to the word.\n",
    "#\n",
    "print('night' in wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print('nights' in wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([-0.16486326,  0.13170786, -0.25996584, -0.09558579,  0.05301844,\n",
      "        0.37700224,  0.28572264,  0.52917683,  0.27456078, -0.20208956,\n",
      "        0.02990697, -0.14047895, -0.22274669,  0.5838353 , -0.39185223,\n",
      "       -0.58972156,  0.1920398 , -0.2308735 , -0.49477252, -0.5629791 ,\n",
      "       -0.50117314, -0.02018334, -0.502249  , -0.11196041, -0.13157889,\n",
      "       -0.29609406, -0.6553267 , -0.09967615, -0.31026295,  0.2649233 ,\n",
      "       -0.34264475,  0.32188314,  0.8136607 , -0.29243678,  0.18573925,\n",
      "        0.32878488,  0.35876936, -0.11037865, -0.4102512 , -0.3027385 ,\n",
      "        0.46218187, -0.45188645,  0.03345847, -0.39535823, -0.53306264,\n",
      "       -0.35503432, -0.08606107,  0.16408224,  0.35535842,  0.01490612,\n",
      "        0.36518428, -0.4993883 ,  0.30531123, -0.39880216, -0.17576866,\n",
      "       -0.20381944, -0.19917205, -0.19154863,  0.05843408, -0.32309493,\n",
      "       -0.33911535, -0.40221113, -0.16612582,  0.3202992 , -0.06200859,\n",
      "        0.6695492 ,  0.03227623,  0.0621837 ,  0.47355634,  0.27131882,\n",
      "       -0.27780646,  0.43445057,  0.54082096, -0.64071846,  0.30843055,\n",
      "       -0.14571999,  0.25970998, -0.03241316,  0.0773463 ,  0.38539696,\n",
      "        0.17547901, -0.49100298, -0.7526835 , -0.11705875, -0.10657647,\n",
      "       -0.8547863 ,  0.48072883,  0.21099591, -0.05289904, -0.25132367,\n",
      "       -0.03250076,  0.39469355, -0.14377315,  0.01681862, -0.19145936,\n",
      "        0.55976987, -0.17166218, -0.24588485,  0.02383496, -0.2474868 ],\n",
      "      dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(wv['night'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([-0.14328378,  0.11492597, -0.22516447, -0.0824601 ,  0.04469592,\n",
      "        0.32516178,  0.24854523,  0.4596679 ,  0.23820755, -0.17666438,\n",
      "        0.02767511, -0.12000947, -0.19394472,  0.5032246 , -0.34057686,\n",
      "       -0.5108788 ,  0.16554886, -0.19928062, -0.42703536, -0.48793808,\n",
      "       -0.43073958, -0.0186529 , -0.43467772, -0.09833384, -0.11253047,\n",
      "       -0.25489897, -0.56595165, -0.08392761, -0.26834813,  0.2306978 ,\n",
      "       -0.29466927,  0.27804974,  0.70230687, -0.25275812,  0.16091175,\n",
      "        0.2839972 ,  0.31172648, -0.09546613, -0.35508126, -0.26252434,\n",
      "        0.39922836, -0.38993633,  0.02853139, -0.341561  , -0.46216   ,\n",
      "       -0.30603343, -0.07153537,  0.1425913 ,  0.30897653,  0.01407885,\n",
      "        0.31751734, -0.43235323,  0.26489508, -0.34491524, -0.15173377,\n",
      "       -0.17515151, -0.17413944, -0.1639372 ,  0.05188529, -0.27698585,\n",
      "       -0.29228833, -0.3483383 , -0.14332771,  0.276501  , -0.05306455,\n",
      "        0.5803583 ,  0.02811984,  0.05130509,  0.4093889 ,  0.2360319 ,\n",
      "       -0.2407138 ,  0.37403294,  0.46895483, -0.55423015,  0.26838624,\n",
      "       -0.12514216,  0.22414494, -0.02884187,  0.06676629,  0.33339986,\n",
      "        0.15246938, -0.4251867 , -0.65053725, -0.10222828, -0.09124731,\n",
      "       -0.7407879 ,  0.41590297,  0.18269993, -0.0437373 , -0.21803567,\n",
      "       -0.02805092,  0.34042943, -0.12467667,  0.01528403, -0.16609979,\n",
      "        0.48461893, -0.1499198 , -0.20915449,  0.02076406, -0.21507509],\n",
      "      dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(wv['nights'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"nights\" in wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"night\" in wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999213\n"
     ]
    }
   ],
   "source": [
    "print(wv.similarity(\"night\", \"nights\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other similarity operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('night', 0.9999920725822449),\n",
      " ('rights', 0.9999875426292419),\n",
      " ('flights', 0.9999875426292419),\n",
      " ('overnight', 0.9999872446060181),\n",
      " ('fighting', 0.9999858736991882),\n",
      " ('entered', 0.9999855756759644),\n",
      " ('fight', 0.9999853372573853),\n",
      " ('fighters', 0.9999850988388062),\n",
      " ('treated', 0.999984622001648),\n",
      " ('fighter', 0.9999845027923584)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(\"nights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999407\n"
     ]
    }
   ],
   "source": [
    "print(wv.n_similarity(['sushi', 'shop'], ['japanese', 'restaurant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'lunch'\n"
     ]
    }
   ],
   "source": [
    "print(wv.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('find', 0.9996632933616638),\n",
      " ('capital,', 0.999660849571228),\n",
      " ('field', 0.9996559023857117),\n",
      " ('findings', 0.9996548891067505),\n",
      " ('finding', 0.999653697013855),\n",
      " ('storm', 0.9996536374092102),\n",
      " ('seekers.', 0.999652624130249),\n",
      " ('had', 0.9996517896652222),\n",
      " ('abuse', 0.9996517300605774),\n",
      " ('playing', 0.9996488690376282)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=['baghdad', 'england'], negative=['london']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 15:03:55,933 : INFO : Evaluating word analogies for top 300000 words in the model on c:\\Users\\AxelArcidiaco\\anaconda3\\envs\\SpacyEnv\\lib\\site-packages\\gensim\\test\\test_data\\questions-words.txt\n",
      "2023-04-04 15:03:55,992 : INFO : family: 0.0% (0/2)\n",
      "2023-04-04 15:03:56,022 : INFO : gram3-comparative: 8.3% (1/12)\n",
      "2023-04-04 15:03:56,037 : INFO : gram4-superlative: 33.3% (4/12)\n",
      "2023-04-04 15:03:56,061 : INFO : gram5-present-participle: 45.0% (9/20)\n",
      "2023-04-04 15:03:56,092 : INFO : gram6-nationality-adjective: 25.0% (5/20)\n",
      "2023-04-04 15:03:56,122 : INFO : gram7-past-tense: 5.0% (1/20)\n",
      "2023-04-04 15:03:56,140 : INFO : gram8-plural: 33.3% (4/12)\n",
      "2023-04-04 15:03:56,149 : INFO : Quadruplets with out-of-vocabulary words: 99.5%\n",
      "2023-04-04 15:03:56,150 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2023-04-04 15:03:56,152 : INFO : Total accuracy: 24.5% (24/98)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.24489795918367346,\n",
      " [{'correct': [], 'incorrect': [], 'section': 'capital-common-countries'},\n",
      "  {'correct': [], 'incorrect': [], 'section': 'capital-world'},\n",
      "  {'correct': [], 'incorrect': [], 'section': 'currency'},\n",
      "  {'correct': [], 'incorrect': [], 'section': 'city-in-state'},\n",
      "  {'correct': [],\n",
      "   'incorrect': [('HE', 'SHE', 'HIS', 'HER'), ('HIS', 'HER', 'HE', 'SHE')],\n",
      "   'section': 'family'},\n",
      "  {'correct': [], 'incorrect': [], 'section': 'gram1-adjective-to-adverb'},\n",
      "  {'correct': [], 'incorrect': [], 'section': 'gram2-opposite'},\n",
      "  {'correct': [('LONG', 'LONGER', 'GREAT', 'GREATER')],\n",
      "   'incorrect': [('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
      "                 ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
      "                 ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
      "                 ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
      "                 ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
      "                 ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
      "                 ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
      "                 ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
      "                 ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
      "                 ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
      "                 ('LOW', 'LOWER', 'LONG', 'LONGER')],\n",
      "   'section': 'gram3-comparative'},\n",
      "  {'correct': [('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
      "               ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
      "               ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
      "               ('LARGE', 'LARGEST', 'BIG', 'BIGGEST')],\n",
      "   'incorrect': [('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
      "                 ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
      "                 ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
      "                 ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
      "                 ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
      "                 ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
      "                 ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
      "                 ('LARGE', 'LARGEST', 'GREAT', 'GREATEST')],\n",
      "   'section': 'gram4-superlative'},\n",
      "  {'correct': [('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
      "               ('GO', 'GOING', 'SAY', 'SAYING'),\n",
      "               ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
      "               ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
      "               ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
      "               ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
      "               ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
      "               ('SAY', 'SAYING', 'GO', 'GOING'),\n",
      "               ('SAY', 'SAYING', 'PLAY', 'PLAYING')],\n",
      "   'incorrect': [('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
      "                 ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
      "                 ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
      "                 ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
      "                 ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
      "                 ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
      "                 ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
      "                 ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
      "                 ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
      "                 ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
      "                 ('SAY', 'SAYING', 'RUN', 'RUNNING')],\n",
      "   'section': 'gram5-present-participle'},\n",
      "  {'correct': [('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
      "               ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
      "               ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
      "               ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "               ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN')],\n",
      "   'incorrect': [('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
      "                 ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
      "                 ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
      "                 ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
      "                 ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
      "                 ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                 ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
      "                 ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
      "                 ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
      "                 ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                 ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
      "                 ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                 ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
      "                 ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
      "                 ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI')],\n",
      "   'section': 'gram6-nationality-adjective'},\n",
      "  {'correct': [('PAYING', 'PAID', 'SAYING', 'SAID')],\n",
      "   'incorrect': [('GOING', 'WENT', 'PAYING', 'PAID'),\n",
      "                 ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
      "                 ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
      "                 ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
      "                 ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
      "                 ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
      "                 ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
      "                 ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
      "                 ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
      "                 ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
      "                 ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
      "                 ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
      "                 ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
      "                 ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
      "                 ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
      "                 ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
      "                 ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
      "                 ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
      "                 ('TAKING', 'TOOK', 'SAYING', 'SAID')],\n",
      "   'section': 'gram7-past-tense'},\n",
      "  {'correct': [('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
      "               ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
      "               ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
      "               ('MAN', 'MEN', 'CHILD', 'CHILDREN')],\n",
      "   'incorrect': [('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
      "                 ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
      "                 ('CAR', 'CARS', 'MAN', 'MEN'),\n",
      "                 ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
      "                 ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
      "                 ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
      "                 ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
      "                 ('MAN', 'MEN', 'CAR', 'CARS')],\n",
      "   'section': 'gram8-plural'},\n",
      "  {'correct': [], 'incorrect': [], 'section': 'gram9-plural-verbs'},\n",
      "  {'correct': [('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
      "               ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
      "               ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
      "               ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
      "               ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
      "               ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
      "               ('GO', 'GOING', 'SAY', 'SAYING'),\n",
      "               ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
      "               ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
      "               ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
      "               ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
      "               ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
      "               ('SAY', 'SAYING', 'GO', 'GOING'),\n",
      "               ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
      "               ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
      "               ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
      "               ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
      "               ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "               ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
      "               ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
      "               ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
      "               ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
      "               ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
      "               ('MAN', 'MEN', 'CHILD', 'CHILDREN')],\n",
      "   'incorrect': [('HE', 'SHE', 'HIS', 'HER'),\n",
      "                 ('HIS', 'HER', 'HE', 'SHE'),\n",
      "                 ('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
      "                 ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
      "                 ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
      "                 ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
      "                 ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
      "                 ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
      "                 ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
      "                 ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
      "                 ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
      "                 ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
      "                 ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
      "                 ('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
      "                 ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
      "                 ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
      "                 ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
      "                 ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
      "                 ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
      "                 ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
      "                 ('LARGE', 'LARGEST', 'GREAT', 'GREATEST'),\n",
      "                 ('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
      "                 ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
      "                 ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
      "                 ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
      "                 ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
      "                 ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
      "                 ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
      "                 ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
      "                 ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
      "                 ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
      "                 ('SAY', 'SAYING', 'RUN', 'RUNNING'),\n",
      "                 ('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
      "                 ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
      "                 ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
      "                 ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
      "                 ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
      "                 ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                 ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
      "                 ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
      "                 ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
      "                 ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                 ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
      "                 ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
      "                 ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
      "                 ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
      "                 ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
      "                 ('GOING', 'WENT', 'PAYING', 'PAID'),\n",
      "                 ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
      "                 ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
      "                 ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
      "                 ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
      "                 ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
      "                 ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
      "                 ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
      "                 ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
      "                 ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
      "                 ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
      "                 ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
      "                 ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
      "                 ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
      "                 ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
      "                 ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
      "                 ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
      "                 ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
      "                 ('TAKING', 'TOOK', 'SAYING', 'SAID'),\n",
      "                 ('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
      "                 ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
      "                 ('CAR', 'CARS', 'MAN', 'MEN'),\n",
      "                 ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
      "                 ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
      "                 ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
      "                 ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
      "                 ('MAN', 'MEN', 'CAR', 'CARS')],\n",
      "   'section': 'Total accuracy'}])\n"
     ]
    }
   ],
   "source": [
    "print(wv.evaluate_word_analogies(datapath('questions-words.txt')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Movers distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
    "sentence_president = 'The president greets the press in Chicago'.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "sentence_obama = [w for w in sentence_obama if w not in STOPWORDS]\n",
    "sentence_president = [w for w in sentence_president if w not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 15:14:40,124 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2023-04-04 15:14:40,125 : INFO : built Dictionary<8 unique tokens: ['illinois', 'media', 'obama', 'speaks', 'chicago']...> from 2 documents (total 8 corpus positions)\n",
      "2023-04-04 15:14:40,127 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<8 unique tokens: ['illinois', 'media', 'obama', 'speaks', 'chicago']...> from 2 documents (total 8 corpus positions)\", 'datetime': '2023-04-04T15:14:40.127118', 'gensim': '4.3.1', 'python': '3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Word Movers Distance is 0.01587736816265295 (lower means closer)'\n"
     ]
    }
   ],
   "source": [
    "distance = wv.wmdistance(sentence_obama, sentence_president)\n",
    "print(f\"Word Movers Distance is {distance} (lower means closer)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpacyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
